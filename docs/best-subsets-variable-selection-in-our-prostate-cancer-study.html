<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Data Science for Biological, Medical and Health Research: Notes for 432</title>
  <meta name="description" content="These are the Course Notes for 432.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Data Science for Biological, Medical and Health Research: Notes for 432" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are the Course Notes for 432." />
  <meta name="github-repo" content="thomaselove/432-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Science for Biological, Medical and Health Research: Notes for 432" />
  
  <meta name="twitter:description" content="These are the Course Notes for 432." />
  

<meta name="author" content="Thomas E. Love, Ph.D.">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="stepwise-variable-selection.html">
<link rel="next" href="adding-non-linear-terms-to-a-linear-regression-model.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">432 Course Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="r-packages-used-in-these-notes.html"><a href="r-packages-used-in-these-notes.html"><i class="fa fa-check"></i>R Packages used in these notes</a></li>
<li class="chapter" data-level="" data-path="data-used-in-these-notes.html"><a href="data-used-in-these-notes.html"><i class="fa fa-check"></i>Data used in these notes</a></li>
<li class="chapter" data-level="" data-path="special-functions-used-in-these-notes.html"><a href="special-functions-used-in-these-notes.html"><i class="fa fa-check"></i>Special Functions used in these notes</a></li>
<li class="chapter" data-level="1" data-path="building-table-1.html"><a href="building-table-1.html"><i class="fa fa-check"></i><b>1</b> Building Table 1</a><ul>
<li class="chapter" data-level="1.1" data-path="building-table-1.html"><a href="building-table-1.html#two-examples-from-the-new-england-journal-of-medicine"><i class="fa fa-check"></i><b>1.1</b> Two examples from the <em>New England Journal of Medicine</em></a><ul>
<li class="chapter" data-level="1.1.1" data-path="building-table-1.html"><a href="building-table-1.html#a-simple-table-1"><i class="fa fa-check"></i><b>1.1.1</b> A simple Table 1</a></li>
<li class="chapter" data-level="1.1.2" data-path="building-table-1.html"><a href="building-table-1.html#a-group-comparison"><i class="fa fa-check"></i><b>1.1.2</b> A group comparison</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="building-table-1.html"><a href="building-table-1.html#the-mr-clean-trial"><i class="fa fa-check"></i><b>1.2</b> The MR CLEAN trial</a></li>
<li class="chapter" data-level="1.3" data-path="building-table-1.html"><a href="building-table-1.html#simulated-fakestroke-data"><i class="fa fa-check"></i><b>1.3</b> Simulated <code>fakestroke</code> data</a></li>
<li class="chapter" data-level="1.4" data-path="building-table-1.html"><a href="building-table-1.html#building-table-1-for-fakestroke-attempt-1"><i class="fa fa-check"></i><b>1.4</b> Building Table 1 for <code>fakestroke</code>: Attempt 1</a><ul>
<li class="chapter" data-level="1.4.1" data-path="building-table-1.html"><a href="building-table-1.html#some-of-this-is-very-useful-and-other-parts-need-to-be-fixed."><i class="fa fa-check"></i><b>1.4.1</b> Some of this is very useful, and other parts need to be fixed.</a></li>
<li class="chapter" data-level="1.4.2" data-path="building-table-1.html"><a href="building-table-1.html#fakestroke-cleaning-up-categorical-variables"><i class="fa fa-check"></i><b>1.4.2</b> <code>fakestroke</code> Cleaning Up Categorical Variables</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="building-table-1.html"><a href="building-table-1.html#fakestroke-table-1-attempt-2"><i class="fa fa-check"></i><b>1.5</b> <code>fakestroke</code> Table 1: Attempt 2</a><ul>
<li class="chapter" data-level="1.5.1" data-path="building-table-1.html"><a href="building-table-1.html#what-summaries-should-we-show"><i class="fa fa-check"></i><b>1.5.1</b> What summaries should we show?</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="building-table-1.html"><a href="building-table-1.html#obtaining-a-more-detailed-summary"><i class="fa fa-check"></i><b>1.6</b> Obtaining a more detailed Summary</a></li>
<li class="chapter" data-level="1.7" data-path="building-table-1.html"><a href="building-table-1.html#exporting-the-completed-table-1-from-r-to-excel-or-word"><i class="fa fa-check"></i><b>1.7</b> Exporting the Completed Table 1 from R to Excel or Word</a><ul>
<li class="chapter" data-level="1.7.1" data-path="building-table-1.html"><a href="building-table-1.html#approach-a-save-and-open-in-excel"><i class="fa fa-check"></i><b>1.7.1</b> Approach A: Save and open in Excel</a></li>
<li class="chapter" data-level="1.7.2" data-path="building-table-1.html"><a href="building-table-1.html#approach-b-produce-the-table-so-you-can-cut-and-paste-it"><i class="fa fa-check"></i><b>1.7.2</b> Approach B: Produce the Table so you can cut and paste it</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="building-table-1.html"><a href="building-table-1.html#a-controlled-biological-experiment---the-blood-brain-barrier"><i class="fa fa-check"></i><b>1.8</b> A Controlled Biological Experiment - The Blood-Brain Barrier</a></li>
<li class="chapter" data-level="1.9" data-path="building-table-1.html"><a href="building-table-1.html#the-bloodbrain.csv-file"><i class="fa fa-check"></i><b>1.9</b> The <code>bloodbrain.csv</code> file</a></li>
<li class="chapter" data-level="1.10" data-path="building-table-1.html"><a href="building-table-1.html#a-table-1-for-bloodbrain"><i class="fa fa-check"></i><b>1.10</b> A Table 1 for <code>bloodbrain</code></a><ul>
<li class="chapter" data-level="1.10.1" data-path="building-table-1.html"><a href="building-table-1.html#generate-final-table-1-for-bloodbrain"><i class="fa fa-check"></i><b>1.10.1</b> Generate final Table 1 for <code>bloodbrain</code></a></li>
<li class="chapter" data-level="1.10.2" data-path="building-table-1.html"><a href="building-table-1.html#a-more-finished-version-after-cleanup-in-word"><i class="fa fa-check"></i><b>1.10.2</b> A More Finished Version (after Cleanup in Word)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html"><i class="fa fa-check"></i><b>2</b> Linear Regression on a small SMART data set</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#brfss-and-smart"><i class="fa fa-check"></i><b>2.1</b> BRFSS and SMART</a><ul>
<li class="chapter" data-level="2.1.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#key-resources"><i class="fa fa-check"></i><b>2.1.1</b> Key resources</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-smartcle1-data-cookbook"><i class="fa fa-check"></i><b>2.2</b> The <code>smartcle1</code> data: Cookbook</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#smartcle2-omitting-missing-observations-complete-case-analyses"><i class="fa fa-check"></i><b>2.3</b> <code>smartcle2</code>: Omitting Missing Observations: Complete-Case Analyses</a></li>
<li class="chapter" data-level="2.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#summarizing-the-smartcle2-data-numerically"><i class="fa fa-check"></i><b>2.4</b> Summarizing the <code>smartcle2</code> data numerically</a><ul>
<li class="chapter" data-level="2.4.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-new-toy-the-skim-function"><i class="fa fa-check"></i><b>2.4.1</b> The New Toy: The <code>skim</code> function</a></li>
<li class="chapter" data-level="2.4.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-usual-summary-for-a-data-frame"><i class="fa fa-check"></i><b>2.4.2</b> The usual <code>summary</code> for a data frame</a></li>
<li class="chapter" data-level="2.4.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-describe-function-in-hmisc"><i class="fa fa-check"></i><b>2.4.3</b> The <code>describe</code> function in <code>Hmisc</code></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#counting-as-exploratory-data-analysis"><i class="fa fa-check"></i><b>2.5</b> Counting as exploratory data analysis</a><ul>
<li class="chapter" data-level="2.5.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-respondents-had-exercised-in-the-past-30-days-did-this-vary-by-sex"><i class="fa fa-check"></i><b>2.5.1</b> How many respondents had exercised in the past 30 days? Did this vary by sex?</a></li>
<li class="chapter" data-level="2.5.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#whats-the-distribution-of-sleephrs"><i class="fa fa-check"></i><b>2.5.2</b> What’s the distribution of <code>sleephrs</code>?</a></li>
<li class="chapter" data-level="2.5.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#whats-the-distribution-of-bmi"><i class="fa fa-check"></i><b>2.5.3</b> What’s the distribution of <code>BMI</code>?</a></li>
<li class="chapter" data-level="2.5.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-of-the-respondents-have-a-bmi-below-30"><i class="fa fa-check"></i><b>2.5.4</b> How many of the respondents have a BMI below 30?</a></li>
<li class="chapter" data-level="2.5.5" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-of-the-respondents-who-have-a-bmi-30-exercised"><i class="fa fa-check"></i><b>2.5.5</b> How many of the respondents who have a BMI &lt; 30 exercised?</a></li>
<li class="chapter" data-level="2.5.6" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#is-obesity-associated-with-sex-in-these-data"><i class="fa fa-check"></i><b>2.5.6</b> Is obesity associated with sex, in these data?</a></li>
<li class="chapter" data-level="2.5.7" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#comparing-sleephrs-summaries-by-obesity-status"><i class="fa fa-check"></i><b>2.5.7</b> Comparing <code>sleephrs</code> summaries by obesity status</a></li>
<li class="chapter" data-level="2.5.8" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-skim-function-within-a-pipe"><i class="fa fa-check"></i><b>2.5.8</b> The <code>skim</code> function within a pipe</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#first-modeling-attempt-can-bmi-predict-physhealth"><i class="fa fa-check"></i><b>2.6</b> First Modeling Attempt: Can <code>bmi</code> predict <code>physhealth</code>?</a><ul>
<li class="chapter" data-level="2.6.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-a-simple-regression-model"><i class="fa fa-check"></i><b>2.6.1</b> Fitting a Simple Regression Model</a></li>
<li class="chapter" data-level="2.6.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#model-summary-for-a-simple-one-predictor-regression"><i class="fa fa-check"></i><b>2.6.2</b> Model Summary for a Simple (One-Predictor) Regression</a></li>
<li class="chapter" data-level="2.6.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#using-the-broom-package"><i class="fa fa-check"></i><b>2.6.3</b> Using the <code>broom</code> package</a></li>
<li class="chapter" data-level="2.6.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-does-the-model-do-residuals-vs.fitted-values"><i class="fa fa-check"></i><b>2.6.4</b> How does the model do? (Residuals vs. Fitted Values)</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#a-new-small-study-predicting-bmi"><i class="fa fa-check"></i><b>2.7</b> A New Small Study: Predicting BMI</a><ul>
<li class="chapter" data-level="2.7.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#does-female-predict-bmi-well"><i class="fa fa-check"></i><b>2.7.1</b> Does <code>female</code> predict <code>bmi</code> well?</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m1-a-simple-t-test-model"><i class="fa fa-check"></i><b>2.8</b> <code>c2_m1</code>: A simple t-test model</a></li>
<li class="chapter" data-level="2.9" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m2-adding-another-predictor-two-way-anova-without-interaction"><i class="fa fa-check"></i><b>2.9</b> <code>c2_m2</code>: Adding another predictor (two-way ANOVA without interaction)</a></li>
<li class="chapter" data-level="2.10" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m3-adding-the-interaction-term-two-way-anova-with-interaction"><i class="fa fa-check"></i><b>2.10</b> <code>c2_m3</code>: Adding the interaction term (Two-way ANOVA with interaction)</a></li>
<li class="chapter" data-level="2.11" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m4-using-female-and-sleephrs-in-a-model-for-bmi"><i class="fa fa-check"></i><b>2.11</b> <code>c2_m4</code>: Using <code>female</code> and <code>sleephrs</code> in a model for <code>bmi</code></a></li>
<li class="chapter" data-level="2.12" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#making-predictions-with-a-linear-regression-model"><i class="fa fa-check"></i><b>2.12</b> Making Predictions with a Linear Regression Model</a><ul>
<li class="chapter" data-level="2.12.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-an-individual-prediction-and-95-prediction-interval"><i class="fa fa-check"></i><b>2.12.1</b> Fitting an Individual Prediction and 95% Prediction Interval</a></li>
<li class="chapter" data-level="2.12.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#confidence-interval-for-an-average-prediction"><i class="fa fa-check"></i><b>2.12.2</b> Confidence Interval for an Average Prediction</a></li>
<li class="chapter" data-level="2.12.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-multiple-individual-predictions-to-new-data"><i class="fa fa-check"></i><b>2.12.3</b> Fitting Multiple Individual Predictions to New Data</a></li>
<li class="chapter" data-level="2.12.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#simulation-to-represent-predictive-uncertainty-in-model-4"><i class="fa fa-check"></i><b>2.12.4</b> Simulation to represent predictive uncertainty in Model 4</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#centering-the-model"><i class="fa fa-check"></i><b>2.13</b> Centering the model</a><ul>
<li class="chapter" data-level="2.13.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#plot-of-model-4-on-centered-sleephrs-c2_m4_c"><i class="fa fa-check"></i><b>2.13.1</b> Plot of Model 4 on Centered <code>sleephrs</code>: <code>c2_m4_c</code></a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#rescaling-an-input-by-subtracting-the-mean-and-dividing-by-2-standard-deviations"><i class="fa fa-check"></i><b>2.14</b> Rescaling an input by subtracting the mean and dividing by 2 standard deviations</a><ul>
<li class="chapter" data-level="2.14.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#refitting-model-c2_m4-to-the-rescaled-data"><i class="fa fa-check"></i><b>2.14.1</b> Refitting model <code>c2_m4</code> to the rescaled data</a></li>
<li class="chapter" data-level="2.14.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#interpreting-the-model-on-rescaled-data"><i class="fa fa-check"></i><b>2.14.2</b> Interpreting the model on rescaled data</a></li>
<li class="chapter" data-level="2.14.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#plot-of-model-on-rescaled-data"><i class="fa fa-check"></i><b>2.14.3</b> Plot of model on rescaled data</a></li>
</ul></li>
<li class="chapter" data-level="2.15" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m5-what-if-we-add-more-variables"><i class="fa fa-check"></i><b>2.15</b> <code>c2_m5</code>: What if we add more variables?</a></li>
<li class="chapter" data-level="2.16" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m6-would-adding-self-reported-health-help"><i class="fa fa-check"></i><b>2.16</b> <code>c2_m6</code>: Would adding self-reported health help?</a></li>
<li class="chapter" data-level="2.17" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m7-what-if-we-added-the-menthealth-variable"><i class="fa fa-check"></i><b>2.17</b> <code>c2_m7</code>: What if we added the <code>menthealth</code> variable?</a></li>
<li class="chapter" data-level="2.18" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#key-regression-assumptions-for-building-effective-prediction-models"><i class="fa fa-check"></i><b>2.18</b> Key Regression Assumptions for Building Effective Prediction Models</a><ul>
<li class="chapter" data-level="2.18.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#checking-assumptions-in-model-c2_m7"><i class="fa fa-check"></i><b>2.18.1</b> Checking Assumptions in model <code>c2_m7</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>3</b> Analysis of Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-bonding-data-a-designed-dental-experiment"><i class="fa fa-check"></i><b>3.1</b> The <code>bonding</code> data: A Designed Dental Experiment</a></li>
<li class="chapter" data-level="3.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-one-factor-analysis-of-variance"><i class="fa fa-check"></i><b>3.2</b> A One-Factor Analysis of Variance</a><ul>
<li class="chapter" data-level="3.2.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#look-at-the-data"><i class="fa fa-check"></i><b>3.2.1</b> Look at the Data!</a></li>
<li class="chapter" data-level="3.2.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#table-of-summary-statistics"><i class="fa fa-check"></i><b>3.2.2</b> Table of Summary Statistics</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-two-way-anova-looking-at-two-factors"><i class="fa fa-check"></i><b>3.3</b> A Two-Way ANOVA: Looking at Two Factors</a></li>
<li class="chapter" data-level="3.4" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-means-plot-with-standard-deviations-to-check-for-interaction"><i class="fa fa-check"></i><b>3.4</b> A Means Plot (with standard deviations) to check for interaction</a><ul>
<li class="chapter" data-level="3.4.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#skimming-the-data-after-grouping-by-resin-and-light"><i class="fa fa-check"></i><b>3.4.1</b> Skimming the data after grouping by <code>resin</code> and <code>light</code></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#fitting-the-two-way-anova-model-with-interaction"><i class="fa fa-check"></i><b>3.5</b> Fitting the Two-Way ANOVA model with Interaction</a><ul>
<li class="chapter" data-level="3.5.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-anova-table-for-our-model"><i class="fa fa-check"></i><b>3.5.1</b> The ANOVA table for our model</a></li>
<li class="chapter" data-level="3.5.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#is-the-interaction-important"><i class="fa fa-check"></i><b>3.5.2</b> Is the interaction important?</a></li>
<li class="chapter" data-level="3.5.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#interpreting-the-interaction"><i class="fa fa-check"></i><b>3.5.3</b> Interpreting the Interaction</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#comparing-individual-combinations-of-resin-and-light"><i class="fa fa-check"></i><b>3.6</b> Comparing Individual Combinations of <code>resin</code> and <code>light</code></a></li>
<li class="chapter" data-level="3.7" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-bonding-model-without-interaction"><i class="fa fa-check"></i><b>3.7</b> The <code>bonding</code> model without Interaction</a></li>
<li class="chapter" data-level="3.8" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#cortisol-a-hypothetical-clinical-trial"><i class="fa fa-check"></i><b>3.8</b> <code>cortisol</code>: A Hypothetical Clinical Trial</a><ul>
<li class="chapter" data-level="3.8.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#codebook-and-raw-data-for-cortisol"><i class="fa fa-check"></i><b>3.8.1</b> Codebook and Raw Data for <code>cortisol</code></a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#creating-a-factor-combining-sex-and-waist"><i class="fa fa-check"></i><b>3.9</b> Creating a factor combining sex and waist</a></li>
<li class="chapter" data-level="3.10" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-means-plot-for-the-cortisol-trial-with-standard-errors"><i class="fa fa-check"></i><b>3.10</b> A Means Plot for the <code>cortisol</code> trial (with standard errors)</a></li>
<li class="chapter" data-level="3.11" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-two-way-anova-model-for-cortisol-with-interaction"><i class="fa fa-check"></i><b>3.11</b> A Two-Way ANOVA model for <code>cortisol</code> with Interaction</a></li>
<li class="chapter" data-level="3.12" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-two-way-anova-model-for-cortisol-without-interaction"><i class="fa fa-check"></i><b>3.12</b> A Two-Way ANOVA model for <code>cortisol</code> without Interaction</a><ul>
<li class="chapter" data-level="3.12.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-graph"><i class="fa fa-check"></i><b>3.12.1</b> The Graph</a></li>
<li class="chapter" data-level="3.12.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-anova-model"><i class="fa fa-check"></i><b>3.12.2</b> The ANOVA Model</a></li>
<li class="chapter" data-level="3.12.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-regression-summary"><i class="fa fa-check"></i><b>3.12.3</b> The Regression Summary</a></li>
<li class="chapter" data-level="3.12.4" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#tukey-hsd-comparisons"><i class="fa fa-check"></i><b>3.12.4</b> Tukey HSD Comparisons</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html"><i class="fa fa-check"></i><b>4</b> Analysis of Covariance</a><ul>
<li class="chapter" data-level="4.1" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#an-emphysema-study"><i class="fa fa-check"></i><b>4.1</b> An Emphysema Study</a><ul>
<li class="chapter" data-level="4.1.1" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#codebook"><i class="fa fa-check"></i><b>4.1.1</b> Codebook</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#does-sex-affect-the-mean-change-in-theophylline"><i class="fa fa-check"></i><b>4.2</b> Does <code>sex</code> affect the mean change in theophylline?</a></li>
<li class="chapter" data-level="4.3" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#is-there-an-association-between-age-and-sex-in-this-study"><i class="fa fa-check"></i><b>4.3</b> Is there an association between <code>age</code> and <code>sex</code> in this study?</a></li>
<li class="chapter" data-level="4.4" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#adding-a-quantitative-covariate-age-to-the-model"><i class="fa fa-check"></i><b>4.4</b> Adding a quantitative covariate, <code>age</code>, to the model</a><ul>
<li class="chapter" data-level="4.4.1" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#the-ancova-model"><i class="fa fa-check"></i><b>4.4.1</b> The ANCOVA model</a></li>
<li class="chapter" data-level="4.4.2" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#the-ancova-table"><i class="fa fa-check"></i><b>4.4.2</b> The ANCOVA Table</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#rerunning-the-ancova-model-after-simple-imputation"><i class="fa fa-check"></i><b>4.5</b> Rerunning the ANCOVA model after simple imputation</a></li>
<li class="chapter" data-level="4.6" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#looking-at-a-factor-covariate-interaction"><i class="fa fa-check"></i><b>4.6</b> Looking at a factor-covariate interaction</a></li>
<li class="chapter" data-level="4.7" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#centering-the-covariate-to-facilitate-ancova-interpretation"><i class="fa fa-check"></i><b>4.7</b> Centering the Covariate to Facilitate ANCOVA Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html"><i class="fa fa-check"></i><b>5</b> Missing Data Mechanisms and Single Imputation</a><ul>
<li class="chapter" data-level="5.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#a-toy-example"><i class="fa fa-check"></i><b>5.1</b> A Toy Example</a><ul>
<li class="chapter" data-level="5.1.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#how-many-missing-values-do-we-have-in-each-column"><i class="fa fa-check"></i><b>5.1.1</b> How many missing values do we have in each column?</a></li>
<li class="chapter" data-level="5.1.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#what-is-the-pattern-of-missing-data"><i class="fa fa-check"></i><b>5.1.2</b> What is the pattern of missing data?</a></li>
<li class="chapter" data-level="5.1.3" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#how-can-we-identify-the-subjects-with-missing-data"><i class="fa fa-check"></i><b>5.1.3</b> How can we identify the subjects with missing data?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#missing-data-mechanisms"><i class="fa fa-check"></i><b>5.2</b> Missing-data mechanisms</a></li>
<li class="chapter" data-level="5.3" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#options-for-dealing-with-missingness"><i class="fa fa-check"></i><b>5.3</b> Options for Dealing with Missingness</a></li>
<li class="chapter" data-level="5.4" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#complete-case-and-available-case-analyses"><i class="fa fa-check"></i><b>5.4</b> Complete Case (and Available Case) analyses</a></li>
<li class="chapter" data-level="5.5" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#single-imputation"><i class="fa fa-check"></i><b>5.5</b> Single Imputation</a></li>
<li class="chapter" data-level="5.6" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#multiple-imputation"><i class="fa fa-check"></i><b>5.6</b> Multiple Imputation</a></li>
<li class="chapter" data-level="5.7" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#building-a-complete-case-analysis"><i class="fa fa-check"></i><b>5.7</b> Building a Complete Case Analysis</a></li>
<li class="chapter" data-level="5.8" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#single-imputation-with-the-mean-or-mode"><i class="fa fa-check"></i><b>5.8</b> Single Imputation with the Mean or Mode</a></li>
<li class="chapter" data-level="5.9" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#doing-single-imputation-with-simputation"><i class="fa fa-check"></i><b>5.9</b> Doing Single Imputation with <code>simputation</code></a><ul>
<li class="chapter" data-level="5.9.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#mirroring-our-prior-approach-imputing-meansmediansmodes"><i class="fa fa-check"></i><b>5.9.1</b> Mirroring Our Prior Approach (imputing means/medians/modes)</a></li>
<li class="chapter" data-level="5.9.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#using-a-model-to-impute-sbp.before-and-diabetes"><i class="fa fa-check"></i><b>5.9.2</b> Using a model to impute <code>sbp.before</code> and <code>diabetes</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html"><i class="fa fa-check"></i><b>6</b> A Study of Prostate Cancer</a><ul>
<li class="chapter" data-level="6.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#data-load-and-background"><i class="fa fa-check"></i><b>6.1</b> Data Load and Background</a></li>
<li class="chapter" data-level="6.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#code-book"><i class="fa fa-check"></i><b>6.2</b> Code Book</a></li>
<li class="chapter" data-level="6.3" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#additions-for-later-use"><i class="fa fa-check"></i><b>6.3</b> Additions for Later Use</a></li>
<li class="chapter" data-level="6.4" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#fitting-and-evaluating-a-two-predictor-model"><i class="fa fa-check"></i><b>6.4</b> Fitting and Evaluating a Two-Predictor Model</a><ul>
<li class="chapter" data-level="6.4.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#using-tidy"><i class="fa fa-check"></i><b>6.4.1</b> Using <code>tidy</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#interpretation"><i class="fa fa-check"></i><b>6.4.2</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#exploring-model-c5_prost_a"><i class="fa fa-check"></i><b>6.5</b> Exploring Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="6.5.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#summary-for-model-c5_prost_a"><i class="fa fa-check"></i><b>6.5.1</b> <code>summary</code> for Model <code>c5_prost_A</code></a></li>
<li class="chapter" data-level="6.5.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#adjusted-r2"><i class="fa fa-check"></i><b>6.5.2</b> Adjusted R<sup>2</sup></a></li>
<li class="chapter" data-level="6.5.3" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#coefficient-confidence-intervals"><i class="fa fa-check"></i><b>6.5.3</b> Coefficient Confidence Intervals</a></li>
<li class="chapter" data-level="6.5.4" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#anova-for-model-c5_prost_a"><i class="fa fa-check"></i><b>6.5.4</b> ANOVA for Model <code>c5_prost_A</code></a></li>
<li class="chapter" data-level="6.5.5" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#residuals-fitted-values-and-standard-errors-with-augment"><i class="fa fa-check"></i><b>6.5.5</b> Residuals, Fitted Values and Standard Errors with <code>augment</code></a></li>
<li class="chapter" data-level="6.5.6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#making-predictions-with-c5_prost_a"><i class="fa fa-check"></i><b>6.5.6</b> Making Predictions with <code>c5_prost_A</code></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#plotting-model-c5_prost_a"><i class="fa fa-check"></i><b>6.6</b> Plotting Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="6.6.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#residual-plots-of-c5_prost_a"><i class="fa fa-check"></i><b>6.6.1</b> Residual Plots of <code>c5_prost_A</code></a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#cross-validation-of-model-c5_prost_a"><i class="fa fa-check"></i><b>6.7</b> Cross-Validation of Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="6.7.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#cross-validated-summaries-of-prediction-quality"><i class="fa fa-check"></i><b>6.7.1</b> Cross-Validated Summaries of Prediction Quality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html"><i class="fa fa-check"></i><b>7</b> Stepwise Variable Selection</a><ul>
<li class="chapter" data-level="7.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#strategy-for-model-selection"><i class="fa fa-check"></i><b>7.1</b> Strategy for Model Selection</a><ul>
<li class="chapter" data-level="7.1.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#how-do-we-choose-potential-subsets-of-predictors"><i class="fa fa-check"></i><b>7.1.1</b> How Do We Choose Potential Subsets of Predictors?</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#a-kitchen-sink-model-model-c5_prost_ks"><i class="fa fa-check"></i><b>7.2</b> A “Kitchen Sink” Model (Model <code>c5_prost_ks</code>)</a></li>
<li class="chapter" data-level="7.3" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#sequential-variable-selection-stepwise-approaches"><i class="fa fa-check"></i><b>7.3</b> Sequential Variable Selection: Stepwise Approaches</a><ul>
<li class="chapter" data-level="7.3.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#the-big-problems-with-stepwise-regression"><i class="fa fa-check"></i><b>7.3.1</b> The Big Problems with Stepwise Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#forward-selection-with-the-step-function"><i class="fa fa-check"></i><b>7.4</b> Forward Selection with the <code>step</code> function</a></li>
<li class="chapter" data-level="7.5" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#backward-elimination-using-the-step-function"><i class="fa fa-check"></i><b>7.5</b> Backward Elimination using the <code>step</code> function</a></li>
<li class="chapter" data-level="7.6" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#allen-cady-modified-backward-elimination"><i class="fa fa-check"></i><b>7.6</b> Allen-Cady Modified Backward Elimination</a><ul>
<li class="chapter" data-level="7.6.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#demonstration-of-the-allen-cady-approach"><i class="fa fa-check"></i><b>7.6.1</b> Demonstration of the Allen-Cady approach</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#summarizing-the-results"><i class="fa fa-check"></i><b>7.7</b> Summarizing the Results</a><ul>
<li class="chapter" data-level="7.7.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#in-sample-testing-and-summaries"><i class="fa fa-check"></i><b>7.7.1</b> In-Sample Testing and Summaries</a></li>
<li class="chapter" data-level="7.7.2" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#validating-the-results-of-the-various-models"><i class="fa fa-check"></i><b>7.7.2</b> Validating the Results of the Various Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><i class="fa fa-check"></i><b>8</b> “Best Subsets” Variable Selection in our Prostate Cancer Study</a><ul>
<li class="chapter" data-level="8.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#four-key-summaries-well-use-to-evaluate-potential-models"><i class="fa fa-check"></i><b>8.1</b> Four Key Summaries We’ll Use to Evaluate Potential Models</a></li>
<li class="chapter" data-level="8.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#using-regsubsets-in-the-leaps-package"><i class="fa fa-check"></i><b>8.2</b> Using <code>regsubsets</code> in the <code>leaps</code> package</a><ul>
<li class="chapter" data-level="8.2.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#identifying-the-models-with-which-and-outmat"><i class="fa fa-check"></i><b>8.2.1</b> Identifying the models with <code>which</code> and <code>outmat</code></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#calculating-bias-corrected-aic"><i class="fa fa-check"></i><b>8.3</b> Calculating bias-corrected AIC</a><ul>
<li class="chapter" data-level="8.3.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#calculation-of-aic.c-in-our-setting"><i class="fa fa-check"></i><b>8.3.1</b> Calculation of aic.c in our setting</a></li>
<li class="chapter" data-level="8.3.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-uncorrected-aic-provides-no-more-useful-information-here"><i class="fa fa-check"></i><b>8.3.2</b> The Uncorrected AIC provides no more useful information here</a></li>
<li class="chapter" data-level="8.3.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#building-a-tibble-containing-the-necessary-information"><i class="fa fa-check"></i><b>8.3.3</b> Building a Tibble containing the necessary information</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#plotting-the-best-subsets-results-using-ggplot2"><i class="fa fa-check"></i><b>8.4</b> Plotting the Best Subsets Results using <code>ggplot2</code></a><ul>
<li class="chapter" data-level="8.4.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-adjusted-r2-plot"><i class="fa fa-check"></i><b>8.4.1</b> The Adjusted R<sup>2</sup> Plot</a></li>
<li class="chapter" data-level="8.4.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#mallows-c_p"><i class="fa fa-check"></i><b>8.4.2</b> Mallows’ <span class="math inline">\(C_p\)</span></a></li>
<li class="chapter" data-level="8.4.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-c_p-plot"><i class="fa fa-check"></i><b>8.4.3</b> The <span class="math inline">\(C_p\)</span> Plot</a></li>
<li class="chapter" data-level="8.4.4" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#all-subsets-regression-and-information-criteria"><i class="fa fa-check"></i><b>8.4.4</b> “All Subsets” Regression and Information Criteria</a></li>
<li class="chapter" data-level="8.4.5" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-bias-corrected-aic-plot"><i class="fa fa-check"></i><b>8.4.5</b> The bias-corrected AIC plot</a></li>
<li class="chapter" data-level="8.4.6" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-bic-plot"><i class="fa fa-check"></i><b>8.4.6</b> The BIC plot</a></li>
<li class="chapter" data-level="8.4.7" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#all-four-plots-in-one-figure-via-ggplot2"><i class="fa fa-check"></i><b>8.4.7</b> All Four Plots in One Figure (via ggplot2)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#table-of-key-results"><i class="fa fa-check"></i><b>8.5</b> Table of Key Results</a></li>
<li class="chapter" data-level="8.6" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#models-worth-considering"><i class="fa fa-check"></i><b>8.6</b> Models Worth Considering?</a></li>
<li class="chapter" data-level="8.7" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#compare-these-candidate-models-in-sample"><i class="fa fa-check"></i><b>8.7</b> Compare these candidate models in-sample?</a><ul>
<li class="chapter" data-level="8.7.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#using-anova-to-compare-nested-models"><i class="fa fa-check"></i><b>8.7.1</b> Using <code>anova</code> to compare nested models</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#aic-and-bic-comparisons-within-the-training-sample"><i class="fa fa-check"></i><b>8.8</b> AIC and BIC comparisons, within the training sample</a></li>
<li class="chapter" data-level="8.9" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#cross-validation-of-candidate-models-out-of-sample"><i class="fa fa-check"></i><b>8.9</b> Cross-Validation of Candidate Models out of Sample</a><ul>
<li class="chapter" data-level="8.9.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#fold-cross-validation-of-model-m04"><i class="fa fa-check"></i><b>8.9.1</b> 20-fold Cross-Validation of model <code>m04</code></a></li>
<li class="chapter" data-level="8.9.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#fold-cross-validation-of-model-m07"><i class="fa fa-check"></i><b>8.9.2</b> 20-fold Cross-Validation of model <code>m07</code></a></li>
<li class="chapter" data-level="8.9.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#fold-cross-validation-of-model-m08"><i class="fa fa-check"></i><b>8.9.3</b> 20-fold Cross-Validation of model <code>m08</code></a></li>
<li class="chapter" data-level="8.9.4" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#comparing-the-results-of-the-cross-validations"><i class="fa fa-check"></i><b>8.9.4</b> Comparing the Results of the Cross-Validations</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#what-about-interaction-terms"><i class="fa fa-check"></i><b>8.10</b> What about Interaction Terms?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html"><i class="fa fa-check"></i><b>9</b> Adding Non-linear Terms to a Linear Regression Model</a><ul>
<li class="chapter" data-level="9.1" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#the-pollution-data"><i class="fa fa-check"></i><b>9.1</b> The <code>pollution</code> data</a></li>
<li class="chapter" data-level="9.2" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#fitting-a-straight-line-model-to-predict-y-from-x2"><i class="fa fa-check"></i><b>9.2</b> Fitting a straight line model to predict <code>y</code> from <code>x2</code></a></li>
<li class="chapter" data-level="9.3" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#quadratic-polynomial-model-to-predict-y-using-x2"><i class="fa fa-check"></i><b>9.3</b> Quadratic polynomial model to predict <code>y</code> using <code>x2</code></a><ul>
<li class="chapter" data-level="9.3.1" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#the-raw-quadratic-model"><i class="fa fa-check"></i><b>9.3.1</b> The raw quadratic model</a></li>
<li class="chapter" data-level="9.3.2" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#raw-quadratic-fit-after-centering-x2"><i class="fa fa-check"></i><b>9.3.2</b> Raw quadratic fit after centering <code>x2</code></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#orthogonal-polynomials"><i class="fa fa-check"></i><b>9.4</b> Orthogonal Polynomials</a></li>
<li class="chapter" data-level="9.5" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#fit-a-cubic-polynomial-to-predict-y-from-x3"><i class="fa fa-check"></i><b>9.5</b> Fit a cubic polynomial to predict <code>y</code> from <code>x3</code></a></li>
<li class="chapter" data-level="9.6" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#fitting-a-restricted-cubic-spline-in-a-linear-regression"><i class="fa fa-check"></i><b>9.6</b> Fitting a restricted cubic spline in a linear regression</a></li>
<li class="chapter" data-level="9.7" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#spending-degrees-of-freedom"><i class="fa fa-check"></i><b>9.7</b> “Spending” Degrees of Freedom</a><ul>
<li class="chapter" data-level="9.7.1" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#overfitting-and-limits-on-the-of-predictors"><i class="fa fa-check"></i><b>9.7.1</b> Overfitting and Limits on the # of Predictors</a></li>
<li class="chapter" data-level="9.7.2" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#the-importance-of-collinearity"><i class="fa fa-check"></i><b>9.7.2</b> The Importance of Collinearity</a></li>
<li class="chapter" data-level="9.7.3" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#collinearity-in-an-explanatory-model"><i class="fa fa-check"></i><b>9.7.3</b> Collinearity in an Explanatory Model</a></li>
<li class="chapter" data-level="9.7.4" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#collinearity-in-a-prediction-model"><i class="fa fa-check"></i><b>9.7.4</b> Collinearity in a Prediction Model</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#spending-df-on-non-linearity-the-spearman-rho2-plot"><i class="fa fa-check"></i><b>9.8</b> Spending DF on Non-Linearity: The Spearman <span class="math inline">\(\rho^2\)</span> Plot</a><ul>
<li class="chapter" data-level="9.8.1" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#fitting-a-big-model-to-the-pollution-data"><i class="fa fa-check"></i><b>9.8.1</b> Fitting a Big Model to the <code>pollution</code> data</a></li>
<li class="chapter" data-level="9.8.2" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#limitations-of-lm-for-fitting-complex-linear-regression-models"><i class="fa fa-check"></i><b>9.8.2</b> Limitations of <code>lm</code> for fitting complex linear regression models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html"><i class="fa fa-check"></i><b>10</b> Using <code>ols</code> from the <code>rms</code> package to fit linear models</a><ul>
<li class="chapter" data-level="10.1" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#fitting-a-model-with-ols"><i class="fa fa-check"></i><b>10.1</b> Fitting a model with <code>ols</code></a><ul>
<li class="chapter" data-level="10.1.1" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#the-model-likelihood-ratio-test"><i class="fa fa-check"></i><b>10.1.1</b> The Model Likelihood Ratio Test</a></li>
<li class="chapter" data-level="10.1.2" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#the-g-statistic"><i class="fa fa-check"></i><b>10.1.2</b> The g statistic</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#anova-for-an-ols-model"><i class="fa fa-check"></i><b>10.2</b> ANOVA for an <code>ols</code> model</a></li>
<li class="chapter" data-level="10.3" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#effect-estimates"><i class="fa fa-check"></i><b>10.3</b> Effect Estimates</a><ul>
<li class="chapter" data-level="10.3.1" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#simultaneous-confidence-intervals"><i class="fa fa-check"></i><b>10.3.1</b> Simultaneous Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#the-predict-function-for-an-ols-model"><i class="fa fa-check"></i><b>10.4</b> The <code>Predict</code> function for an <code>ols</code> model</a></li>
<li class="chapter" data-level="10.5" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#checking-influence-via-dfbeta"><i class="fa fa-check"></i><b>10.5</b> Checking Influence via <code>dfbeta</code></a><ul>
<li class="chapter" data-level="10.5.1" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#using-the-residuals-command-for-dfbetas"><i class="fa fa-check"></i><b>10.5.1</b> Using the <code>residuals</code> command for <code>dfbetas</code></a></li>
<li class="chapter" data-level="10.5.2" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#using-the-residuals-command-for-other-summaries"><i class="fa fa-check"></i><b>10.5.2</b> Using the <code>residuals</code> command for other summaries</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#model-validation-and-correcting-for-optimism"><i class="fa fa-check"></i><b>10.6</b> Model Validation and Correcting for Optimism</a></li>
<li class="chapter" data-level="10.7" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#building-a-nomogram-for-our-model"><i class="fa fa-check"></i><b>10.7</b> Building a Nomogram for Our Model</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html"><i class="fa fa-check"></i><b>11</b> Other Variable Selection Strategies</a><ul>
<li class="chapter" data-level="11.1" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#why-not-use-stepwise-procedures"><i class="fa fa-check"></i><b>11.1</b> Why not use stepwise procedures?</a></li>
<li class="chapter" data-level="11.2" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#ridge-regression"><i class="fa fa-check"></i><b>11.2</b> Ridge Regression</a><ul>
<li class="chapter" data-level="11.2.1" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#assessing-a-ridge-regression-approach"><i class="fa fa-check"></i><b>11.2.1</b> Assessing a Ridge Regression Approach</a></li>
<li class="chapter" data-level="11.2.2" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#the-lm.ridge-plot---where-do-coefficients-stabilize"><i class="fa fa-check"></i><b>11.2.2</b> The <code>lm.ridge</code> plot - where do coefficients stabilize?</a></li>
<li class="chapter" data-level="11.2.3" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#ridge-regression-the-bottom-line"><i class="fa fa-check"></i><b>11.2.3</b> Ridge Regression: The Bottom Line</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#the-lasso"><i class="fa fa-check"></i><b>11.3</b> The Lasso</a><ul>
<li class="chapter" data-level="11.3.1" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#consequences-of-the-lasso-approach"><i class="fa fa-check"></i><b>11.3.1</b> Consequences of the Lasso Approach</a></li>
<li class="chapter" data-level="11.3.2" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#how-the-lasso-works"><i class="fa fa-check"></i><b>11.3.2</b> How The Lasso Works</a></li>
<li class="chapter" data-level="11.3.3" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#cross-validation-with-the-lasso"><i class="fa fa-check"></i><b>11.3.3</b> Cross-Validation with the Lasso</a></li>
<li class="chapter" data-level="11.3.4" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#what-value-of-the-key-fraction-minimizes-cross-validated-mse"><i class="fa fa-check"></i><b>11.3.4</b> What value of the key fraction minimizes cross-validated MSE?</a></li>
<li class="chapter" data-level="11.3.5" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#coefficients-for-the-model-identified-by-the-cross-validation"><i class="fa fa-check"></i><b>11.3.5</b> Coefficients for the Model Identified by the Cross-Validation</a></li>
<li class="chapter" data-level="11.3.6" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#obtaining-fitted-values-from-lasso"><i class="fa fa-check"></i><b>11.3.6</b> Obtaining Fitted Values from Lasso</a></li>
<li class="chapter" data-level="11.3.7" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#complete-set-of-fitted-values-from-the-lasso"><i class="fa fa-check"></i><b>11.3.7</b> Complete Set of Fitted Values from the Lasso</a></li>
<li class="chapter" data-level="11.3.8" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#when-is-the-lasso-most-useful"><i class="fa fa-check"></i><b>11.3.8</b> When is the Lasso Most Useful?</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#applying-the-lasso-to-the-pollution-data"><i class="fa fa-check"></i><b>11.4</b> Applying the Lasso to the <code>pollution</code> data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html"><i class="fa fa-check"></i><b>12</b> Logistic Regression: The Foundations</a><ul>
<li class="chapter" data-level="12.1" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#a-first-attempt-a-linear-probability-model"><i class="fa fa-check"></i><b>12.1</b> A First Attempt: A Linear Probability Model</a></li>
<li class="chapter" data-level="12.2" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#logistic-regression"><i class="fa fa-check"></i><b>12.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="12.3" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#the-logistic-regression-model"><i class="fa fa-check"></i><b>12.3</b> The Logistic Regression Model</a></li>
<li class="chapter" data-level="12.4" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#the-link-function"><i class="fa fa-check"></i><b>12.4</b> The Link Function</a></li>
<li class="chapter" data-level="12.5" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#the-logit-or-log-odds"><i class="fa fa-check"></i><b>12.5</b> The logit or log odds</a></li>
<li class="chapter" data-level="12.6" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#interpreting-the-coefficients-of-a-logistic-regression-model"><i class="fa fa-check"></i><b>12.6</b> Interpreting the Coefficients of a Logistic Regression Model</a></li>
<li class="chapter" data-level="12.7" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#the-logistic-regression-has-non-constant-variance"><i class="fa fa-check"></i><b>12.7</b> The Logistic Regression has non-constant variance</a></li>
<li class="chapter" data-level="12.8" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#fitting-a-logistic-regression-model-to-our-simulated-data"><i class="fa fa-check"></i><b>12.8</b> Fitting a Logistic Regression Model to our Simulated Data</a></li>
<li class="chapter" data-level="12.9" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#plotting-the-logistic-regression-model"><i class="fa fa-check"></i><b>12.9</b> Plotting the Logistic Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html"><i class="fa fa-check"></i><b>13</b> Logistic Regression and the <code>resect</code> data</a><ul>
<li class="chapter" data-level="13.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#the-resect-data"><i class="fa fa-check"></i><b>13.1</b> The <code>resect</code> data</a></li>
<li class="chapter" data-level="13.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#running-a-simple-logistic-regression-model"><i class="fa fa-check"></i><b>13.2</b> Running A Simple Logistic Regression Model</a><ul>
<li class="chapter" data-level="13.2.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#logistic-regression-can-be-harder-than-linear-regression"><i class="fa fa-check"></i><b>13.2.1</b> Logistic Regression Can Be Harder than Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#logistic-regression-using-glm"><i class="fa fa-check"></i><b>13.3</b> Logistic Regression using <code>glm</code></a><ul>
<li class="chapter" data-level="13.3.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-coefficients-of-a-logistic-regression-model-1"><i class="fa fa-check"></i><b>13.3.1</b> Interpreting the Coefficients of a Logistic Regression Model</a></li>
<li class="chapter" data-level="13.3.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#using-predict-to-describe-the-models-fits"><i class="fa fa-check"></i><b>13.3.2</b> Using <code>predict</code> to describe the model’s fits</a></li>
<li class="chapter" data-level="13.3.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#odds-ratio-interpretation-of-coefficients"><i class="fa fa-check"></i><b>13.3.3</b> Odds Ratio interpretation of Coefficients</a></li>
<li class="chapter" data-level="13.3.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-rest-of-the-model-output-from-glm"><i class="fa fa-check"></i><b>13.3.4</b> Interpreting the rest of the model output from <code>glm</code></a></li>
<li class="chapter" data-level="13.3.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#deviance-and-comparing-our-model-to-the-null-model"><i class="fa fa-check"></i><b>13.3.5</b> Deviance and Comparing Our Model to the Null Model</a></li>
<li class="chapter" data-level="13.3.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#using-glance-with-a-logistic-regression-model"><i class="fa fa-check"></i><b>13.3.6</b> Using <code>glance</code> with a logistic regression model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-model-summary"><i class="fa fa-check"></i><b>13.4</b> Interpreting the Model Summary</a><ul>
<li class="chapter" data-level="13.4.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#wald-z-tests-for-coefficients-in-a-logistic-regression"><i class="fa fa-check"></i><b>13.4.1</b> Wald Z tests for Coefficients in a Logistic Regression</a></li>
<li class="chapter" data-level="13.4.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#confidence-intervals-for-the-coefficients"><i class="fa fa-check"></i><b>13.4.2</b> Confidence Intervals for the Coefficients</a></li>
<li class="chapter" data-level="13.4.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#deviance-residuals"><i class="fa fa-check"></i><b>13.4.3</b> Deviance Residuals</a></li>
<li class="chapter" data-level="13.4.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#dispersion-parameter"><i class="fa fa-check"></i><b>13.4.4</b> Dispersion Parameter</a></li>
<li class="chapter" data-level="13.4.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#fisher-scoring-iterations"><i class="fa fa-check"></i><b>13.4.5</b> Fisher Scoring iterations</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-a-simple-logistic-regression-model"><i class="fa fa-check"></i><b>13.5</b> Plotting a Simple Logistic Regression Model</a><ul>
<li class="chapter" data-level="13.5.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#using-augment-to-capture-the-fitted-probabilities"><i class="fa fa-check"></i><b>13.5.1</b> Using <code>augment</code> to capture the fitted probabilities</a></li>
<li class="chapter" data-level="13.5.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-a-logistic-regression-models-fitted-values"><i class="fa fa-check"></i><b>13.5.2</b> Plotting a Logistic Regression Model’s Fitted Values</a></li>
<li class="chapter" data-level="13.5.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-a-simple-logistic-model-using-binomial_smooth"><i class="fa fa-check"></i><b>13.5.3</b> Plotting a Simple Logistic Model using <code>binomial_smooth</code></a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#how-well-does-model-a-classify-subjects"><i class="fa fa-check"></i><b>13.6</b> How well does Model A classify subjects?</a></li>
<li class="chapter" data-level="13.7" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#receiver-operating-characteristic-curve-analysis"><i class="fa fa-check"></i><b>13.7</b> Receiver Operating Characteristic Curve Analysis</a><ul>
<li class="chapter" data-level="13.7.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-area-under-the-roc-curve"><i class="fa fa-check"></i><b>13.7.1</b> Interpreting the Area under the ROC curve</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#the-roc-plot-for-res_moda"><i class="fa fa-check"></i><b>13.8</b> The ROC Plot for <code>res_modA</code></a><ul>
<li class="chapter" data-level="13.8.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#another-way-to-plot-the-roc-curve"><i class="fa fa-check"></i><b>13.8.1</b> Another way to plot the ROC Curve</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#assessing-residual-plots-from-model-a"><i class="fa fa-check"></i><b>13.9</b> Assessing Residual Plots from Model A</a></li>
<li class="chapter" data-level="13.10" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#model-b-a-kitchen-sink-logistic-regression-model"><i class="fa fa-check"></i><b>13.10</b> Model B: A “Kitchen Sink” Logistic Regression Model</a><ul>
<li class="chapter" data-level="13.10.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#comparing-model-a-to-model-b"><i class="fa fa-check"></i><b>13.10.1</b> Comparing Model A to Model B</a></li>
<li class="chapter" data-level="13.10.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-model-b"><i class="fa fa-check"></i><b>13.10.2</b> Interpreting Model B</a></li>
</ul></li>
<li class="chapter" data-level="13.11" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-model-b"><i class="fa fa-check"></i><b>13.11</b> Plotting Model B</a><ul>
<li class="chapter" data-level="13.11.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#using-augment-to-capture-the-fitted-probabilities-1"><i class="fa fa-check"></i><b>13.11.1</b> Using <code>augment</code> to capture the fitted probabilities</a></li>
<li class="chapter" data-level="13.11.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-model-b-fits-by-observed-mortality"><i class="fa fa-check"></i><b>13.11.2</b> Plotting Model B Fits by Observed Mortality</a></li>
<li class="chapter" data-level="13.11.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#the-roc-curve-for-model-b"><i class="fa fa-check"></i><b>13.11.3</b> The ROC curve for Model B</a></li>
<li class="chapter" data-level="13.11.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#residuals-leverage-and-influence"><i class="fa fa-check"></i><b>13.11.4</b> Residuals, Leverage and Influence</a></li>
</ul></li>
<li class="chapter" data-level="13.12" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#logistic-regression-using-lrm"><i class="fa fa-check"></i><b>13.12</b> Logistic Regression using <code>lrm</code></a><ul>
<li class="chapter" data-level="13.12.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-nagelkerke-r2"><i class="fa fa-check"></i><b>13.12.1</b> Interpreting Nagelkerke R<sup>2</sup></a></li>
<li class="chapter" data-level="13.12.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-c-statistic-and-plotting-the-roc-curve"><i class="fa fa-check"></i><b>13.12.2</b> Interpreting the C statistic and Plotting the ROC Curve</a></li>
<li class="chapter" data-level="13.12.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#the-c-statistic-and-somers-d"><i class="fa fa-check"></i><b>13.12.3</b> The C statistic and Somers’ D</a></li>
<li class="chapter" data-level="13.12.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#validating-the-logistic-regression-model-summary-statistics"><i class="fa fa-check"></i><b>13.12.4</b> Validating the Logistic Regression Model Summary Statistics</a></li>
<li class="chapter" data-level="13.12.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-the-summary-of-the-lrm-approach"><i class="fa fa-check"></i><b>13.12.5</b> Plotting the Summary of the <code>lrm</code> approach</a></li>
<li class="chapter" data-level="13.12.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plot-in-sample-predictions-for-model-c"><i class="fa fa-check"></i><b>13.12.6</b> Plot In-Sample Predictions for Model C</a></li>
<li class="chapter" data-level="13.12.7" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#anova-from-the-lrm-approach"><i class="fa fa-check"></i><b>13.12.7</b> ANOVA from the <code>lrm</code> approach</a></li>
<li class="chapter" data-level="13.12.8" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#are-any-points-particularly-influential"><i class="fa fa-check"></i><b>13.12.8</b> Are any points particularly influential?</a></li>
<li class="chapter" data-level="13.12.9" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#a-nomogram-for-model-c"><i class="fa fa-check"></i><b>13.12.9</b> A Nomogram for Model C</a></li>
</ul></li>
<li class="chapter" data-level="13.13" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#model-d-an-augmented-kitchen-sink-model"><i class="fa fa-check"></i><b>13.13</b> Model D: An Augmented Kitchen Sink Model</a><ul>
<li class="chapter" data-level="13.13.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#spearman-rho2-plot"><i class="fa fa-check"></i><b>13.13.1</b> Spearman <span class="math inline">\(\rho^2\)</span> Plot</a></li>
<li class="chapter" data-level="13.13.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#fitting-model-d-using-lrm"><i class="fa fa-check"></i><b>13.13.2</b> Fitting Model D using <code>lrm</code></a></li>
<li class="chapter" data-level="13.13.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#assessing-model-d-using-lrms-tools"><i class="fa fa-check"></i><b>13.13.3</b> Assessing Model D using <code>lrm</code>’s tools</a></li>
<li class="chapter" data-level="13.13.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#anova-and-wald-tests-for-model-d"><i class="fa fa-check"></i><b>13.13.4</b> ANOVA and Wald Tests for Model D</a></li>
<li class="chapter" data-level="13.13.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#effect-sizes-in-model-d"><i class="fa fa-check"></i><b>13.13.5</b> Effect Sizes in Model D</a></li>
<li class="chapter" data-level="13.13.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plot-in-sample-predictions-for-model-d"><i class="fa fa-check"></i><b>13.13.6</b> Plot In-Sample Predictions for Model D</a></li>
<li class="chapter" data-level="13.13.7" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-the-roc-curve-for-model-d"><i class="fa fa-check"></i><b>13.13.7</b> Plotting the ROC curve for Model D</a></li>
<li class="chapter" data-level="13.13.8" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#validation-of-model-d-summaries"><i class="fa fa-check"></i><b>13.13.8</b> Validation of Model D summaries</a></li>
</ul></li>
<li class="chapter" data-level="13.14" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#model-e-fitting-a-reduced-model-in-light-of-model-d"><i class="fa fa-check"></i><b>13.14</b> Model E: Fitting a Reduced Model in light of Model D</a><ul>
<li class="chapter" data-level="13.14.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#a-plot-comparing-the-two-intubation-groups"><i class="fa fa-check"></i><b>13.14.1</b> A Plot comparing the two intubation groups</a></li>
<li class="chapter" data-level="13.14.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#nomogram-for-model-e"><i class="fa fa-check"></i><b>13.14.2</b> Nomogram for Model E</a></li>
<li class="chapter" data-level="13.14.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#effect-sizes-from-model-e"><i class="fa fa-check"></i><b>13.14.3</b> Effect Sizes from Model E</a></li>
<li class="chapter" data-level="13.14.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plot-in-sample-predictions-for-model-e"><i class="fa fa-check"></i><b>13.14.4</b> Plot In-Sample Predictions for Model E</a></li>
<li class="chapter" data-level="13.14.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#anova-for-model-e"><i class="fa fa-check"></i><b>13.14.5</b> ANOVA for Model E</a></li>
<li class="chapter" data-level="13.14.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#validation-of-model-e"><i class="fa fa-check"></i><b>13.14.6</b> Validation of Model E</a></li>
<li class="chapter" data-level="13.14.7" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#do-any-points-seem-particularly-influential"><i class="fa fa-check"></i><b>13.14.7</b> Do any points seem particularly influential?</a></li>
<li class="chapter" data-level="13.14.8" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#fitting-model-e-using-glm-to-get-plots-about-influence"><i class="fa fa-check"></i><b>13.14.8</b> Fitting Model E using <code>glm</code> to get plots about influence</a></li>
</ul></li>
<li class="chapter" data-level="13.15" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#concordance-comparing-model-c-d-and-es-predictions"><i class="fa fa-check"></i><b>13.15</b> Concordance: Comparing Model C, D and E’s predictions</a></li>
<li class="chapter" data-level="13.16" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#conclusions"><i class="fa fa-check"></i><b>13.16</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html"><i class="fa fa-check"></i><b>14</b> Logistic Regression and the <code>smartcle1</code> data</a><ul>
<li class="chapter" data-level="14.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#the-smartcle1-data"><i class="fa fa-check"></i><b>14.1</b> The <code>smartcle1</code> data</a></li>
<li class="chapter" data-level="14.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#thinking-about-non-linear-terms"><i class="fa fa-check"></i><b>14.2</b> Thinking About Non-Linear Terms</a></li>
<li class="chapter" data-level="14.3" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#a-first-model-for-exerany-complete-case-analysis"><i class="fa fa-check"></i><b>14.3</b> A First Model for <code>exerany</code> (Complete Case Analysis)</a></li>
<li class="chapter" data-level="14.4" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#building-a-larger-model-spearman-rho2-plot"><i class="fa fa-check"></i><b>14.4</b> Building a Larger Model: Spearman <span class="math inline">\(\rho^2\)</span> Plot</a></li>
<li class="chapter" data-level="14.5" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#a-second-model-for-exerany-complete-cases"><i class="fa fa-check"></i><b>14.5</b> A Second Model for <code>exerany</code> (Complete Cases)</a></li>
<li class="chapter" data-level="14.6" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#dealing-with-missing-data-via-simple-imputation"><i class="fa fa-check"></i><b>14.6</b> Dealing with Missing Data via Simple Imputation</a><ul>
<li class="chapter" data-level="14.6.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#omit-cases-where-the-outcome-is-missing"><i class="fa fa-check"></i><b>14.6.1</b> Omit cases where the outcome is missing</a></li>
<li class="chapter" data-level="14.6.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plot-the-remaining-missingness"><i class="fa fa-check"></i><b>14.6.2</b> Plot the remaining missingness</a></li>
<li class="chapter" data-level="14.6.3" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#use-simple-imputation-build-a-new-data-set"><i class="fa fa-check"></i><b>14.6.3</b> Use simple imputation, build a new data set</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#refitting-model-1-with-simply-imputed-data"><i class="fa fa-check"></i><b>14.7</b> Refitting Model 1 with simply imputed data</a><ul>
<li class="chapter" data-level="14.7.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#validating-summary-statistics"><i class="fa fa-check"></i><b>14.7.1</b> Validating Summary Statistics</a></li>
<li class="chapter" data-level="14.7.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#anova-for-the-model"><i class="fa fa-check"></i><b>14.7.2</b> ANOVA for the model</a></li>
<li class="chapter" data-level="14.7.3" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#summarizing-effect-size"><i class="fa fa-check"></i><b>14.7.3</b> Summarizing Effect Size</a></li>
<li class="chapter" data-level="14.7.4" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plotting-the-model-with-ggplot-and-predict"><i class="fa fa-check"></i><b>14.7.4</b> Plotting the Model with <code>ggplot</code> and <code>Predict</code></a></li>
<li class="chapter" data-level="14.7.5" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plotting-the-model-with-a-nomogram"><i class="fa fa-check"></i><b>14.7.5</b> Plotting the model with a nomogram</a></li>
<li class="chapter" data-level="14.7.6" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#checking-the-goodness-of-fit-of-our-model"><i class="fa fa-check"></i><b>14.7.6</b> Checking the Goodness of Fit of our model</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#refitting-model-2-with-simply-imputed-data"><i class="fa fa-check"></i><b>14.8</b> Refitting Model 2 with simply imputed data</a><ul>
<li class="chapter" data-level="14.8.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#validating-summary-statistics-1"><i class="fa fa-check"></i><b>14.8.1</b> Validating Summary Statistics</a></li>
<li class="chapter" data-level="14.8.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#anova-for-the-model-1"><i class="fa fa-check"></i><b>14.8.2</b> ANOVA for the model</a></li>
<li class="chapter" data-level="14.8.3" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#summarizing-effect-size-1"><i class="fa fa-check"></i><b>14.8.3</b> Summarizing Effect Size</a></li>
<li class="chapter" data-level="14.8.4" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plotting-the-model-with-ggplot-and-predict-1"><i class="fa fa-check"></i><b>14.8.4</b> Plotting the Model with <code>ggplot</code> and <code>Predict</code></a></li>
<li class="chapter" data-level="14.8.5" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plotting-the-model-with-a-nomogram-1"><i class="fa fa-check"></i><b>14.8.5</b> Plotting the model with a nomogram</a></li>
<li class="chapter" data-level="14.8.6" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#checking-the-goodness-of-fit-of-our-model-1"><i class="fa fa-check"></i><b>14.8.6</b> Checking the Goodness of Fit of our model</a></li>
</ul></li>
<li class="chapter" data-level="14.9" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#comparing-model-2-to-model-1-after-simple-imputation"><i class="fa fa-check"></i><b>14.9</b> Comparing Model 2 to Model 1 after simple imputation</a><ul>
<li class="chapter" data-level="14.9.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#comparison-by-analysis-of-deviance"><i class="fa fa-check"></i><b>14.9.1</b> Comparison by Analysis of Deviance</a></li>
<li class="chapter" data-level="14.9.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#comparing-aic-and-bic"><i class="fa fa-check"></i><b>14.9.2</b> Comparing AIC and BIC</a></li>
</ul></li>
<li class="chapter" data-level="14.10" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#dealing-with-missing-data-via-multiple-imputation"><i class="fa fa-check"></i><b>14.10</b> Dealing with Missing Data via Multiple Imputation</a><ul>
<li class="chapter" data-level="14.10.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#using-aregimpute-to-fit-a-multiple-imputation-model"><i class="fa fa-check"></i><b>14.10.1</b> Using <code>aregImpute</code> to fit a multiple imputation model</a></li>
</ul></li>
<li class="chapter" data-level="14.11" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#combining-the-imputation-and-outcome-models"><i class="fa fa-check"></i><b>14.11</b> Combining the Imputation and Outcome Models</a><ul>
<li class="chapter" data-level="14.11.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#model-1-with-multiple-imputation"><i class="fa fa-check"></i><b>14.11.1</b> Model 1 with Multiple Imputation</a></li>
<li class="chapter" data-level="14.11.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#model-2-with-multiple-imputation"><i class="fa fa-check"></i><b>14.11.2</b> Model 2 with Multiple Imputation</a></li>
</ul></li>
<li class="chapter" data-level="14.12" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#models-with-and-without-imputation"><i class="fa fa-check"></i><b>14.12</b> Models with and without Imputation</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html"><i class="fa fa-check"></i><b>15</b> Linear Regression and the <code>smartcle1</code> data</a><ul>
<li class="chapter" data-level="15.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#the-smartcle1-data-1"><i class="fa fa-check"></i><b>15.1</b> The <code>smartcle1</code> data</a></li>
<li class="chapter" data-level="15.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#thinking-about-non-linear-terms-1"><i class="fa fa-check"></i><b>15.2</b> Thinking About Non-Linear Terms</a></li>
<li class="chapter" data-level="15.3" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#a-first-model-for-sleephrs-complete-case-analysis"><i class="fa fa-check"></i><b>15.3</b> A First Model for <code>sleephrs</code> (Complete Case Analysis)</a></li>
<li class="chapter" data-level="15.4" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#building-a-larger-model-spearman-rho2-plot-1"><i class="fa fa-check"></i><b>15.4</b> Building a Larger Model: Spearman <span class="math inline">\(\rho^2\)</span> Plot</a></li>
<li class="chapter" data-level="15.5" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#a-second-model-for-sleephrs-complete-cases"><i class="fa fa-check"></i><b>15.5</b> A Second Model for <code>sleephrs</code> (Complete Cases)</a></li>
<li class="chapter" data-level="15.6" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#dealing-with-missing-data-via-simple-imputation-1"><i class="fa fa-check"></i><b>15.6</b> Dealing with Missing Data via Simple Imputation</a><ul>
<li class="chapter" data-level="15.6.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#omit-cases-where-the-outcome-is-missing-1"><i class="fa fa-check"></i><b>15.6.1</b> Omit cases where the outcome is missing</a></li>
<li class="chapter" data-level="15.6.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#plot-the-remaining-missingness-1"><i class="fa fa-check"></i><b>15.6.2</b> Plot the remaining missingness</a></li>
<li class="chapter" data-level="15.6.3" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#use-simple-imputation-build-a-new-data-set-1"><i class="fa fa-check"></i><b>15.6.3</b> Use simple imputation, build a new data set</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#refitting-model-a-with-simply-imputed-data"><i class="fa fa-check"></i><b>15.7</b> Refitting Model A with simply imputed data</a><ul>
<li class="chapter" data-level="15.7.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#validating-summary-statistics-2"><i class="fa fa-check"></i><b>15.7.1</b> Validating Summary Statistics</a></li>
<li class="chapter" data-level="15.7.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#anova-for-the-model-2"><i class="fa fa-check"></i><b>15.7.2</b> ANOVA for the model</a></li>
<li class="chapter" data-level="15.7.3" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#summarizing-effect-size-2"><i class="fa fa-check"></i><b>15.7.3</b> Summarizing Effect Size</a></li>
<li class="chapter" data-level="15.7.4" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#plotting-the-model-with-ggplot-and-predict-2"><i class="fa fa-check"></i><b>15.7.4</b> Plotting the Model with <code>ggplot</code> and <code>Predict</code></a></li>
<li class="chapter" data-level="15.7.5" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#plotting-the-model-with-a-nomogram-2"><i class="fa fa-check"></i><b>15.7.5</b> Plotting the model with a nomogram</a></li>
<li class="chapter" data-level="15.7.6" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#residual-plots-for-mod.a2"><i class="fa fa-check"></i><b>15.7.6</b> Residual Plots for mod.A2</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#refitting-model-b-with-simply-imputed-data"><i class="fa fa-check"></i><b>15.8</b> Refitting Model B with simply imputed data</a><ul>
<li class="chapter" data-level="15.8.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#validating-summary-statistics-3"><i class="fa fa-check"></i><b>15.8.1</b> Validating Summary Statistics</a></li>
<li class="chapter" data-level="15.8.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#anova-for-the-model-3"><i class="fa fa-check"></i><b>15.8.2</b> ANOVA for the model</a></li>
<li class="chapter" data-level="15.8.3" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#summarizing-effect-size-3"><i class="fa fa-check"></i><b>15.8.3</b> Summarizing Effect Size</a></li>
<li class="chapter" data-level="15.8.4" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#plotting-the-model-with-ggplot-and-predict-3"><i class="fa fa-check"></i><b>15.8.4</b> Plotting the Model with <code>ggplot</code> and <code>Predict</code></a></li>
</ul></li>
<li class="chapter" data-level="15.9" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#comparing-model-b.2-to-model-a.2-after-simple-imputation"><i class="fa fa-check"></i><b>15.9</b> Comparing Model B.2 to Model A.2 after simple imputation</a><ul>
<li class="chapter" data-level="15.9.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#comparison-by-analysis-of-variance"><i class="fa fa-check"></i><b>15.9.1</b> Comparison by Analysis of Variance</a></li>
<li class="chapter" data-level="15.9.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#comparing-aic-and-bic-1"><i class="fa fa-check"></i><b>15.9.2</b> Comparing AIC and BIC</a></li>
</ul></li>
<li class="chapter" data-level="15.10" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#dealing-with-missing-data-via-multiple-imputation-1"><i class="fa fa-check"></i><b>15.10</b> Dealing with Missing Data via Multiple Imputation</a><ul>
<li class="chapter" data-level="15.10.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#using-aregimpute-to-fit-a-multiple-imputation-model-1"><i class="fa fa-check"></i><b>15.10.1</b> Using <code>aregImpute</code> to fit a multiple imputation model</a></li>
</ul></li>
<li class="chapter" data-level="15.11" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#combining-the-imputation-and-outcome-models-1"><i class="fa fa-check"></i><b>15.11</b> Combining the Imputation and Outcome Models</a><ul>
<li class="chapter" data-level="15.11.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#model-a-with-multiple-imputation"><i class="fa fa-check"></i><b>15.11.1</b> Model A with Multiple Imputation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html"><i class="fa fa-check"></i><b>16</b> Colorectal Cancer Screening and Some Special Cases</a><ul>
<li class="chapter" data-level="16.1" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#logistic-regression-for-aggregated-data"><i class="fa fa-check"></i><b>16.1</b> Logistic Regression for Aggregated Data</a><ul>
<li class="chapter" data-level="16.1.1" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#colorectal-cancer-screening-data"><i class="fa fa-check"></i><b>16.1.1</b> Colorectal Cancer Screening Data</a></li>
<li class="chapter" data-level="16.1.2" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#fitting-a-logistic-regression-model-to-proportion-data"><i class="fa fa-check"></i><b>16.1.2</b> Fitting a Logistic Regression Model to Proportion Data</a></li>
<li class="chapter" data-level="16.1.3" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#fitting-a-logistic-regression-model-to-counts-of-successes-and-failures"><i class="fa fa-check"></i><b>16.1.3</b> Fitting a Logistic Regression Model to Counts of Successes and Failures</a></li>
<li class="chapter" data-level="16.1.4" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#how-does-one-address-this-problem-in-rms"><i class="fa fa-check"></i><b>16.1.4</b> How does one address this problem in <code>rms</code>?</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#probit-regression"><i class="fa fa-check"></i><b>16.2</b> Probit Regression</a><ul>
<li class="chapter" data-level="16.2.1" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#colorectal-cancer-screening-data-on-individuals"><i class="fa fa-check"></i><b>16.2.1</b> Colorectal Cancer Screening Data on Individuals</a></li>
<li class="chapter" data-level="16.2.2" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#a-logistic-regression-model"><i class="fa fa-check"></i><b>16.2.2</b> A logistic regression model</a></li>
<li class="chapter" data-level="16.2.3" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#predicting-status-for-harry-and-sally"><i class="fa fa-check"></i><b>16.2.3</b> Predicting status for Harry and Sally</a></li>
<li class="chapter" data-level="16.2.4" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#a-probit-regression-model"><i class="fa fa-check"></i><b>16.2.4</b> A probit regression model</a></li>
<li class="chapter" data-level="16.2.5" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#interpreting-the-probit-models-coefficients"><i class="fa fa-check"></i><b>16.2.5</b> Interpreting the Probit Model’s Coefficients</a></li>
<li class="chapter" data-level="16.2.6" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#what-about-harry-and-sally"><i class="fa fa-check"></i><b>16.2.6</b> What about Harry and Sally?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html"><i class="fa fa-check"></i><b>17</b> Cleaning the BRFSS SMART Data</a><ul>
<li class="chapter" data-level="17.1" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#key-resources-1"><i class="fa fa-check"></i><b>17.1</b> Key resources</a></li>
<li class="chapter" data-level="17.2" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#ingesting-the-raw-data"><i class="fa fa-check"></i><b>17.2</b> Ingesting The Raw Data</a></li>
<li class="chapter" data-level="17.3" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#the-national-data"><i class="fa fa-check"></i><b>17.3</b> The National Data</a></li>
<li class="chapter" data-level="17.4" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#cleaning-the-brfss-data"><i class="fa fa-check"></i><b>17.4</b> Cleaning the BRFSS Data</a><ul>
<li class="chapter" data-level="17.4.1" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#health-status-1-item"><i class="fa fa-check"></i><b>17.4.1</b> Health Status (1 item)</a></li>
<li class="chapter" data-level="17.4.2" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#healthy-days---health-related-quality-of-life-3-items"><i class="fa fa-check"></i><b>17.4.2</b> Healthy Days - Health-Related Quality of Life (3 items)</a></li>
<li class="chapter" data-level="17.4.3" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#health-care-access-4-items"><i class="fa fa-check"></i><b>17.4.3</b> Health Care Access (4 items)</a></li>
<li class="chapter" data-level="17.4.4" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#exercise-1-item"><i class="fa fa-check"></i><b>17.4.4</b> Exercise (1 item)</a></li>
<li class="chapter" data-level="17.4.5" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#inadequate-sleep-1-item"><i class="fa fa-check"></i><b>17.4.5</b> Inadequate Sleep (1 item)</a></li>
<li class="chapter" data-level="17.4.6" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#chronic-health-conditions-13-items"><i class="fa fa-check"></i><b>17.4.6</b> Chronic Health Conditions (13 items)</a></li>
<li class="chapter" data-level="17.4.7" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#oral-health-2-items"><i class="fa fa-check"></i><b>17.4.7</b> Oral Health (2 items)</a></li>
<li class="chapter" data-level="17.4.8" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#demographics-23-items"><i class="fa fa-check"></i><b>17.4.8</b> Demographics (23 items)</a></li>
<li class="chapter" data-level="17.4.9" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#tobacco-use-5-items"><i class="fa fa-check"></i><b>17.4.9</b> Tobacco Use (5 items)</a></li>
<li class="chapter" data-level="17.4.10" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#e-cigarettes-2-items"><i class="fa fa-check"></i><b>17.4.10</b> E-Cigarettes (2 items)</a></li>
<li class="chapter" data-level="17.4.11" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#alcohol-consumption-4-items"><i class="fa fa-check"></i><b>17.4.11</b> Alcohol Consumption (4 items)</a></li>
<li class="chapter" data-level="17.4.12" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#immunization-4-items"><i class="fa fa-check"></i><b>17.4.12</b> Immunization (4 items)</a></li>
<li class="chapter" data-level="17.4.13" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#falls-2-items"><i class="fa fa-check"></i><b>17.4.13</b> Falls (2 items)</a></li>
<li class="chapter" data-level="17.4.14" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#seatbelt-use-1-item"><i class="fa fa-check"></i><b>17.4.14</b> Seatbelt Use (1 item)</a></li>
<li class="chapter" data-level="17.4.15" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#drinking-and-driving-1-item"><i class="fa fa-check"></i><b>17.4.15</b> Drinking and Driving (1 item)</a></li>
<li class="chapter" data-level="17.4.16" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#breast-and-cervical-cancer-screening-7-items"><i class="fa fa-check"></i><b>17.4.16</b> Breast and Cervical Cancer Screening (7 items)</a></li>
<li class="chapter" data-level="17.4.17" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#prostate-cancer-screening-6-items"><i class="fa fa-check"></i><b>17.4.17</b> Prostate Cancer Screening (6 items)</a></li>
<li class="chapter" data-level="17.4.18" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#colorectal-cancer-screening-5-items"><i class="fa fa-check"></i><b>17.4.18</b> Colorectal Cancer Screening (5 items)</a></li>
<li class="chapter" data-level="17.4.19" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#hivaids-3-items"><i class="fa fa-check"></i><b>17.4.19</b> HIV/AIDS (3 items)</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#creating-some-quantitative-variables-from-thin-air"><i class="fa fa-check"></i><b>17.5</b> Creating Some Quantitative Variables from Thin Air</a><ul>
<li class="chapter" data-level="17.5.1" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#age_imp-creating-age-data-out-of-thin-air"><i class="fa fa-check"></i><b>17.5.1</b> <code>age_imp</code>: Creating Age Data out of Thin Air</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#clean-data-in-the-state-of-ohio"><i class="fa fa-check"></i><b>17.6</b> Clean Data in the State of Ohio</a></li>
<li class="chapter" data-level="17.7" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#clean-cleveland-elyria-data"><i class="fa fa-check"></i><b>17.7</b> Clean Cleveland-Elyria Data</a><ul>
<li class="chapter" data-level="17.7.1" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#cleveland---elyria-raw-data"><i class="fa fa-check"></i><b>17.7.1</b> Cleveland - Elyria Raw Data</a></li>
<li class="chapter" data-level="17.7.2" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#clean-data---larger"><i class="fa fa-check"></i><b>17.7.2</b> Clean Data - Larger</a></li>
<li class="chapter" data-level="17.7.3" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#creation-of-the-smartcle1.csv-data"><i class="fa fa-check"></i><b>17.7.3</b> Creation of the <code>smartcle1.csv</code> data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html"><i class="fa fa-check"></i><b>18</b> Modeling a Count Outcome in Ohio SMART</a><ul>
<li class="chapter" data-level="18.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#preliminaries"><i class="fa fa-check"></i><b>18.1</b> Preliminaries</a></li>
<li class="chapter" data-level="18.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-subset-of-the-ohio-smart-data"><i class="fa fa-check"></i><b>18.2</b> A subset of the Ohio SMART data</a><ul>
<li class="chapter" data-level="18.2.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#is-age-group-associated-with-physhealth"><i class="fa fa-check"></i><b>18.2.1</b> Is age group associated with <code>physhealth</code>?</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#exploratory-data-analysis-in-the-18-49-group"><i class="fa fa-check"></i><b>18.3</b> Exploratory Data Analysis (in the 18-49 group)</a><ul>
<li class="chapter" data-level="18.3.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#build-a-subset-of-those-ages-18-49"><i class="fa fa-check"></i><b>18.3.1</b> Build a subset of those ages 18-49</a></li>
<li class="chapter" data-level="18.3.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#distribution-of-the-outcome"><i class="fa fa-check"></i><b>18.3.2</b> Distribution of the Outcome</a></li>
<li class="chapter" data-level="18.3.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#initial-scatterplot-matrix"><i class="fa fa-check"></i><b>18.3.3</b> Initial Scatterplot Matrix</a></li>
<li class="chapter" data-level="18.3.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#dropping-the-subject-with-an-unreasonably-large-bmi"><i class="fa fa-check"></i><b>18.3.4</b> Dropping the subject with an unreasonably large <code>bmi</code></a></li>
<li class="chapter" data-level="18.3.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#revised-final-scatterplot-matrix"><i class="fa fa-check"></i><b>18.3.5</b> Revised (Final) Scatterplot Matrix</a></li>
<li class="chapter" data-level="18.3.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#summary-of-the-final-subset-of-data"><i class="fa fa-check"></i><b>18.3.6</b> Summary of the final subset of data</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#modeling-strategies-explored-here"><i class="fa fa-check"></i><b>18.4</b> Modeling Strategies Explored Here</a><ul>
<li class="chapter" data-level="18.4.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#what-will-we-demonstrate"><i class="fa fa-check"></i><b>18.4.1</b> What Will We Demonstrate?</a></li>
<li class="chapter" data-level="18.4.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#extra-data-file-for-harry-and-sally"><i class="fa fa-check"></i><b>18.4.2</b> Extra Data File for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-ols-approach"><i class="fa fa-check"></i><b>18.5</b> The OLS Approach</a><ul>
<li class="chapter" data-level="18.5.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation"><i class="fa fa-check"></i><b>18.5.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.5.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients"><i class="fa fa-check"></i><b>18.5.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.5.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors"><i class="fa fa-check"></i><b>18.5.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.5.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals"><i class="fa fa-check"></i><b>18.5.4</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.5.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values"><i class="fa fa-check"></i><b>18.5.5</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.5.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions"><i class="fa fa-check"></i><b>18.5.6</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.5.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally"><i class="fa fa-check"></i><b>18.5.7</b> Predictions for Harry and Sally</a></li>
<li class="chapter" data-level="18.5.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#notes"><i class="fa fa-check"></i><b>18.5.8</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#ols-model-on-logphyshealth-1-days"><i class="fa fa-check"></i><b>18.6</b> OLS model on log(<code>physhealth</code> + 1) days</a><ul>
<li class="chapter" data-level="18.6.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-1"><i class="fa fa-check"></i><b>18.6.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.6.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-1"><i class="fa fa-check"></i><b>18.6.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.6.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-1"><i class="fa fa-check"></i><b>18.6.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.6.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-1"><i class="fa fa-check"></i><b>18.6.4</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.6.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values-1"><i class="fa fa-check"></i><b>18.6.5</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.6.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#getting-r2-on-the-scale-of-physhealth"><i class="fa fa-check"></i><b>18.6.6</b> Getting R<sup>2</sup> on the scale of <code>physhealth</code></a></li>
<li class="chapter" data-level="18.6.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-1"><i class="fa fa-check"></i><b>18.6.7</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.6.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-1"><i class="fa fa-check"></i><b>18.6.8</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-poisson-regression-model"><i class="fa fa-check"></i><b>18.7</b> A Poisson Regression Model</a><ul>
<li class="chapter" data-level="18.7.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-2"><i class="fa fa-check"></i><b>18.7.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.7.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-2"><i class="fa fa-check"></i><b>18.7.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.7.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-2"><i class="fa fa-check"></i><b>18.7.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.7.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#correcting-for-overdispersion-with-coeftestcoefci"><i class="fa fa-check"></i><b>18.7.4</b> Correcting for Overdispersion with <code>coeftest</code>/<code>coefci</code></a></li>
<li class="chapter" data-level="18.7.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-2"><i class="fa fa-check"></i><b>18.7.5</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.7.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-see-the-fit-of-a-count-regression-model"><i class="fa fa-check"></i><b>18.7.6</b> Rootogram: see the fit of a count regression model</a></li>
<li class="chapter" data-level="18.7.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values-2"><i class="fa fa-check"></i><b>18.7.7</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.7.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-2"><i class="fa fa-check"></i><b>18.7.8</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.7.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#using-glm.diag.plots-from-the-boot-package"><i class="fa fa-check"></i><b>18.7.9</b> Using <code>glm.diag.plots</code> from the <code>boot</code> package</a></li>
<li class="chapter" data-level="18.7.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-2"><i class="fa fa-check"></i><b>18.7.10</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#overdispersion-in-a-poisson-model"><i class="fa fa-check"></i><b>18.8</b> Overdispersion in a Poisson Model</a><ul>
<li class="chapter" data-level="18.8.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-for-overdispersion"><i class="fa fa-check"></i><b>18.8.1</b> Testing for Overdispersion?</a></li>
</ul></li>
<li class="chapter" data-level="18.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#fitting-the-quasi-poisson-model"><i class="fa fa-check"></i><b>18.9</b> Fitting the Quasi-Poisson Model</a><ul>
<li class="chapter" data-level="18.9.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-3"><i class="fa fa-check"></i><b>18.9.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.9.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-3"><i class="fa fa-check"></i><b>18.9.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.9.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-3"><i class="fa fa-check"></i><b>18.9.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.9.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-3"><i class="fa fa-check"></i><b>18.9.4</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.9.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values-3"><i class="fa fa-check"></i><b>18.9.5</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.9.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-3"><i class="fa fa-check"></i><b>18.9.6</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.9.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-3"><i class="fa fa-check"></i><b>18.9.7</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#poisson-and-quasi-poisson-models-using-glm-from-the-rms-package"><i class="fa fa-check"></i><b>18.10</b> Poisson and Quasi-Poisson models using <code>Glm</code> from the <code>rms</code> package</a><ul>
<li class="chapter" data-level="18.10.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#refitting-the-original-poisson-regression-with-glm"><i class="fa fa-check"></i><b>18.10.1</b> Refitting the original Poisson regression with <code>Glm</code></a></li>
<li class="chapter" data-level="18.10.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#refitting-the-overdispersed-poisson-regression-with-glm"><i class="fa fa-check"></i><b>18.10.2</b> Refitting the overdispersed Poisson regression with <code>Glm</code></a></li>
<li class="chapter" data-level="18.10.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#anova-on-a-glm-fit"><i class="fa fa-check"></i><b>18.10.3</b> ANOVA on a <code>Glm</code> fit</a></li>
<li class="chapter" data-level="18.10.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#ggplots-from-glm-fit"><i class="fa fa-check"></i><b>18.10.4</b> ggplots from <code>Glm</code> fit</a></li>
<li class="chapter" data-level="18.10.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#summary-of-a-glm-fit"><i class="fa fa-check"></i><b>18.10.5</b> Summary of a <code>Glm</code> fit</a></li>
<li class="chapter" data-level="18.10.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#plot-of-the-summary"><i class="fa fa-check"></i><b>18.10.6</b> Plot of the Summary</a></li>
<li class="chapter" data-level="18.10.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#nomogram-of-a-glm-fit"><i class="fa fa-check"></i><b>18.10.7</b> Nomogram of a <code>Glm</code> fit</a></li>
</ul></li>
<li class="chapter" data-level="18.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#negative-binomial-model"><i class="fa fa-check"></i><b>18.11</b> Negative Binomial Model</a><ul>
<li class="chapter" data-level="18.11.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-4"><i class="fa fa-check"></i><b>18.11.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.11.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-with-the-raw-poisson-model"><i class="fa fa-check"></i><b>18.11.2</b> Comparison with the (raw) Poisson model</a></li>
<li class="chapter" data-level="18.11.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-4"><i class="fa fa-check"></i><b>18.11.3</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.11.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpretation-of-coefficients-in-terms-of-irrs"><i class="fa fa-check"></i><b>18.11.4</b> Interpretation of Coefficients in terms of IRRs</a></li>
<li class="chapter" data-level="18.11.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-4"><i class="fa fa-check"></i><b>18.11.5</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.11.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-4"><i class="fa fa-check"></i><b>18.11.6</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.11.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-negative-binomial-model"><i class="fa fa-check"></i><b>18.11.7</b> Rootogram for Negative Binomial model</a></li>
<li class="chapter" data-level="18.11.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#simulating-what-the-negative-binomial-model-predicts"><i class="fa fa-check"></i><b>18.11.8</b> Simulating what the Negative Binomial model predicts</a></li>
<li class="chapter" data-level="18.11.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values-4"><i class="fa fa-check"></i><b>18.11.9</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.11.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-4"><i class="fa fa-check"></i><b>18.11.10</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.11.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-4"><i class="fa fa-check"></i><b>18.11.11</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.12" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-problem-too-few-zeros"><i class="fa fa-check"></i><b>18.12</b> The Problem: Too Few Zeros</a></li>
<li class="chapter" data-level="18.13" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-zero-inflated-poisson-regression-model"><i class="fa fa-check"></i><b>18.13</b> The Zero-Inflated Poisson Regression Model</a><ul>
<li class="chapter" data-level="18.13.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-null-model"><i class="fa fa-check"></i><b>18.13.1</b> Comparison to a null model</a></li>
<li class="chapter" data-level="18.13.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-poisson-model-with-the-vuong-test"><i class="fa fa-check"></i><b>18.13.2</b> Comparison to a Poisson Model with the Vuong test</a></li>
<li class="chapter" data-level="18.13.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-5"><i class="fa fa-check"></i><b>18.13.3</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.13.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-5"><i class="fa fa-check"></i><b>18.13.4</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.13.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-5"><i class="fa fa-check"></i><b>18.13.5</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.13.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-5"><i class="fa fa-check"></i><b>18.13.6</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.13.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#modeled-number-of-zero-counts"><i class="fa fa-check"></i><b>18.13.7</b> Modeled Number of Zero Counts</a></li>
<li class="chapter" data-level="18.13.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-zip-model"><i class="fa fa-check"></i><b>18.13.8</b> Rootogram for ZIP model</a></li>
<li class="chapter" data-level="18.13.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values"><i class="fa fa-check"></i><b>18.13.9</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.13.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-5"><i class="fa fa-check"></i><b>18.13.10</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.13.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-5"><i class="fa fa-check"></i><b>18.13.11</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.14" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-zero-inflated-negative-binomial-regression-model"><i class="fa fa-check"></i><b>18.14</b> The Zero-Inflated Negative Binomial Regression Model</a><ul>
<li class="chapter" data-level="18.14.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-null-model-1"><i class="fa fa-check"></i><b>18.14.1</b> Comparison to a null model</a></li>
<li class="chapter" data-level="18.14.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-negative-binomial-model-vuong-test"><i class="fa fa-check"></i><b>18.14.2</b> Comparison to a Negative Binomial Model: Vuong test</a></li>
<li class="chapter" data-level="18.14.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-6"><i class="fa fa-check"></i><b>18.14.3</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.14.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-6"><i class="fa fa-check"></i><b>18.14.4</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.14.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-6"><i class="fa fa-check"></i><b>18.14.5</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.14.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-6"><i class="fa fa-check"></i><b>18.14.6</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.14.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#modeled-number-of-zero-counts-1"><i class="fa fa-check"></i><b>18.14.7</b> Modeled Number of Zero Counts</a></li>
<li class="chapter" data-level="18.14.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-zero-inflated-negative-binomial-model"><i class="fa fa-check"></i><b>18.14.8</b> Rootogram for Zero-Inflated Negative Binomial model</a></li>
<li class="chapter" data-level="18.14.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values-1"><i class="fa fa-check"></i><b>18.14.9</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.14.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-6"><i class="fa fa-check"></i><b>18.14.10</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.14.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-6"><i class="fa fa-check"></i><b>18.14.11</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.15" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-hurdle-model-with-poisson"><i class="fa fa-check"></i><b>18.15</b> A “hurdle” model (with Poisson)</a><ul>
<li class="chapter" data-level="18.15.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-null-model-2"><i class="fa fa-check"></i><b>18.15.1</b> Comparison to a null model</a></li>
<li class="chapter" data-level="18.15.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-poisson-model-vuong-test"><i class="fa fa-check"></i><b>18.15.2</b> Comparison to a Poisson Model: Vuong test</a></li>
<li class="chapter" data-level="18.15.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-zero-inflated-poisson-model-vuong-test"><i class="fa fa-check"></i><b>18.15.3</b> Comparison to a Zero-Inflated Poisson Model: Vuong test</a></li>
<li class="chapter" data-level="18.15.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-7"><i class="fa fa-check"></i><b>18.15.4</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.15.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-7"><i class="fa fa-check"></i><b>18.15.5</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.15.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-7"><i class="fa fa-check"></i><b>18.15.6</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.15.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-7"><i class="fa fa-check"></i><b>18.15.7</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.15.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#modeled-number-of-zero-counts-2"><i class="fa fa-check"></i><b>18.15.8</b> Modeled Number of Zero Counts</a></li>
<li class="chapter" data-level="18.15.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-hurdle-model"><i class="fa fa-check"></i><b>18.15.9</b> Rootogram for Hurdle Model</a></li>
<li class="chapter" data-level="18.15.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#understanding-the-modeled-counts-in-detail"><i class="fa fa-check"></i><b>18.15.10</b> Understanding the Modeled Counts in Detail</a></li>
<li class="chapter" data-level="18.15.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values-2"><i class="fa fa-check"></i><b>18.15.11</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.15.12" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-7"><i class="fa fa-check"></i><b>18.15.12</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.15.13" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-7"><i class="fa fa-check"></i><b>18.15.13</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.16" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-hurdle-model-with-negative-binomial-for-overdispersion"><i class="fa fa-check"></i><b>18.16</b> A “hurdle” model (with negative binomial for overdispersion)</a><ul>
<li class="chapter" data-level="18.16.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-null-model-3"><i class="fa fa-check"></i><b>18.16.1</b> Comparison to a null model</a></li>
<li class="chapter" data-level="18.16.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-negative-binomial-model-vuong-test-1"><i class="fa fa-check"></i><b>18.16.2</b> Comparison to a Negative Binomial Model: Vuong test</a></li>
<li class="chapter" data-level="18.16.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-zero-inflated-nb-model-vuong-test"><i class="fa fa-check"></i><b>18.16.3</b> Comparison to a Zero-Inflated NB Model: Vuong test</a></li>
<li class="chapter" data-level="18.16.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparing-the-hurdle-models-with-aic-and-bic"><i class="fa fa-check"></i><b>18.16.4</b> Comparing the Hurdle Models with AIC and BIC</a></li>
<li class="chapter" data-level="18.16.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-8"><i class="fa fa-check"></i><b>18.16.5</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.16.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-8"><i class="fa fa-check"></i><b>18.16.6</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.16.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-8"><i class="fa fa-check"></i><b>18.16.7</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.16.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-8"><i class="fa fa-check"></i><b>18.16.8</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.16.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-nb-hurdle-model"><i class="fa fa-check"></i><b>18.16.9</b> Rootogram for NB Hurdle Model</a></li>
<li class="chapter" data-level="18.16.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values-3"><i class="fa fa-check"></i><b>18.16.10</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.16.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-8"><i class="fa fa-check"></i><b>18.16.11</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.16.12" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-8"><i class="fa fa-check"></i><b>18.16.12</b> Predictions for Harry and Sally</a></li>
<li class="chapter" data-level="18.16.13" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#note-fitting-a-different-hurdle-model-for-counts-and-przero"><i class="fa fa-check"></i><b>18.16.13</b> Note: Fitting a Different Hurdle Model for Counts and Pr(zero)</a></li>
<li class="chapter" data-level="18.16.14" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#hanging-rootogram-for-this-new-hurdle-model"><i class="fa fa-check"></i><b>18.16.14</b> Hanging Rootogram for this new Hurdle Model</a></li>
</ul></li>
<li class="chapter" data-level="18.17" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-tobit-censored-regression-model"><i class="fa fa-check"></i><b>18.17</b> A Tobit (Censored) Regression Model</a><ul>
<li class="chapter" data-level="18.17.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-9"><i class="fa fa-check"></i><b>18.17.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.17.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-9"><i class="fa fa-check"></i><b>18.17.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.17.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-9"><i class="fa fa-check"></i><b>18.17.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.17.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-9"><i class="fa fa-check"></i><b>18.17.4</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.17.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#building-something-like-a-rootogram"><i class="fa fa-check"></i><b>18.17.5</b> Building Something Like a Rootogram</a></li>
<li class="chapter" data-level="18.17.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#tables-of-the-observed-and-fitted-physhealth-from-tobit"><i class="fa fa-check"></i><b>18.17.6</b> Tables of the Observed and Fitted <code>physhealth</code> from Tobit</a></li>
<li class="chapter" data-level="18.17.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values-4"><i class="fa fa-check"></i><b>18.17.7</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.17.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-9"><i class="fa fa-check"></i><b>18.17.8</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.17.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-9"><i class="fa fa-check"></i><b>18.17.9</b> Predictions for Harry and Sally</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="modeling-an-ordinal-multi-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-multi-categorical-outcome-in-ohio-smart.html"><i class="fa fa-check"></i><b>19</b> Modeling an Ordinal Multi-Categorical Outcome in Ohio SMART</a><ul>
<li class="chapter" data-level="19.1" data-path="modeling-an-ordinal-multi-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-multi-categorical-outcome-in-ohio-smart.html#where-to-read-this-chapter"><i class="fa fa-check"></i><b>19.1</b> Where to Read this Chapter</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>20</b> Analyzing Literary Styles with Multinomial Logistic Regression</a><ul>
<li class="chapter" data-level="20.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#the-authorship-example"><i class="fa fa-check"></i><b>20.1</b> The Authorship Example</a></li>
<li class="chapter" data-level="20.2" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#focus-on-11-key-words"><i class="fa fa-check"></i><b>20.2</b> Focus on 11 key words</a><ul>
<li class="chapter" data-level="20.2.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#side-by-side-boxplots"><i class="fa fa-check"></i><b>20.2.1</b> Side by Side Boxplots</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#a-multinomial-logistic-regression-model"><i class="fa fa-check"></i><b>20.3</b> A Multinomial Logistic Regression Model</a><ul>
<li class="chapter" data-level="20.3.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#testing-model-1"><i class="fa fa-check"></i><b>20.3.1</b> Testing Model 1</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#model-2"><i class="fa fa-check"></i><b>20.4</b> Model 2</a><ul>
<li class="chapter" data-level="20.4.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#comparing-model-2-to-model-1"><i class="fa fa-check"></i><b>20.4.1</b> Comparing Model 2 to Model 1</a></li>
<li class="chapter" data-level="20.4.2" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#testing-model-2"><i class="fa fa-check"></i><b>20.4.2</b> Testing Model 2</a></li>
<li class="chapter" data-level="20.4.3" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#a-little-history"><i class="fa fa-check"></i><b>20.4.3</b> A little history</a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#classification-table"><i class="fa fa-check"></i><b>20.5</b> Classification Table</a></li>
<li class="chapter" data-level="20.6" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#probability-curves-based-on-a-single-predictor"><i class="fa fa-check"></i><b>20.6</b> Probability Curves based on a Single Predictor</a><ul>
<li class="chapter" data-level="20.6.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#produce-the-plot-of-estimated-probabilities-based-on-been-counts"><i class="fa fa-check"></i><b>20.6.1</b> Produce the Plot of Estimated Probabilities based on “been” counts</a></li>
<li class="chapter" data-level="20.6.2" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#boxplot-of-been-counts"><i class="fa fa-check"></i><b>20.6.2</b> Boxplot of “been” counts</a></li>
<li class="chapter" data-level="20.6.3" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#quote-sources"><i class="fa fa-check"></i><b>20.6.3</b> Quote Sources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science for Biological, Medical and Health Research: Notes for 432</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="best-subsets-variable-selection-in-our-prostate-cancer-study" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> “Best Subsets” Variable Selection in our Prostate Cancer Study</h1>
<p>A second approach to model selection involved fitting all possible subset models and identifying the ones that look best according to some meaningful criterion and ideally one that includes enough variables to model the response appropriately without including lots of redundant or unnecessary terms.</p>
<div id="four-key-summaries-well-use-to-evaluate-potential-models" class="section level2">
<h2><span class="header-section-number">8.1</span> Four Key Summaries We’ll Use to Evaluate Potential Models</h2>
<ol style="list-style-type: decimal">
<li>Adjusted R<sup>2</sup>, which we try to maximize.</li>
<li>Akaike’s Information Criterion (AIC), which we try to minimize, and a Bias-Corrected version of AIC due to <span class="citation">Hurvich and Tsai (<a href="#ref-HurvichTsai1989">1989</a>)</span>, which we use when the sample size is small, specifically when the sample size <span class="math inline">\(n\)</span> and the number of predictors being studied <span class="math inline">\(k\)</span> are such that <span class="math inline">\(n/k \leq 40\)</span>. We also try to minimize this bias-corrected AIC.</li>
<li>Bayesian Information Criterion (BIC), which we also try to minimize.</li>
<li>Mallows’ C<sub>p</sub> statistic, which we (essentially) try to minimize.</li>
</ol>
<p>Choosing between AIC and BIC can be challenging.</p>
<blockquote>
<p>For model selection purposes, there is no clear choice between AIC and BIC. Given a family of models, including the true model, the probability that BIC will select the correct model approaches one as the sample size n approaches infinity - thus BIC is asymptotically consistent, which AIC is not. [But, for practical purposes,] BIC often chooses models that are too simple [relative to AIC] because of its heavy penalty on complexity.</p>
</blockquote>
<ul>
<li>Source: <span class="citation">Hastie, Tibshriani, and Frideman (<a href="#ref-Hastie2001">2001</a>)</span>, page 208.</li>
</ul>
<p>Several useful tools for running “all subsets” or “best subsets” regression comparisons are developed in R’s <code>leaps</code> package.</p>
</div>
<div id="using-regsubsets-in-the-leaps-package" class="section level2">
<h2><span class="header-section-number">8.2</span> Using <code>regsubsets</code> in the <code>leaps</code> package</h2>
<p>We can use the <code>leaps</code> package to obtain results in the <code>prost</code> study from looking at all possible subsets of the candidate predictors. The <code>leaps</code> package isn’t particularly friendly to the tidyverse. In particular, we <strong>cannot have any character variables</strong> in our predictor set. We specify our “kitchen sink” model, and apply the <code>regsubsets</code> function from <code>leaps</code>, which identifies the set of models.</p>
<p>To start, we’ll ask R to find the one best subset (with 1 predictor variable [in addition to the intercept], then with 2 predictors, and then with each of 3, 4, … 8 predictor variables) according to an exhaustive search without forcing any of the variables to be in or out.</p>
<ul>
<li>Use the <code>nvmax</code> command within the <code>regsubsets</code> function to limit the number of regression inputs to a maximum.</li>
<li>Use the <code>nbest</code> command to identify how many subsets you want to identify for each predictor count.</li>
<li>If all of your predictors are <strong>quantitative</strong> or <strong>binary</strong> then you can skip the <code>preds</code> step, and simply place your kitchen sink model into <code>regsubsets</code>.</li>
<li>But if you have multi-categorical variables (like <code>gleason_f</code> or <code>svi_f</code> in our case) then you must create a <code>preds</code> group, as follows.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">preds &lt;-<span class="st"> </span><span class="kw">with</span>(prost, <span class="kw">cbind</span>(lcavol, lweight, age, bph_f, 
                           svi_f, lcp, gleason_f, pgg45))

rs.ks &lt;-<span class="st"> </span><span class="kw">regsubsets</span>(preds, <span class="dt">y =</span> prost<span class="op">$</span>lpsa, 
                    <span class="dt">nvmax =</span> <span class="dv">8</span>, <span class="dt">nbest =</span> <span class="dv">1</span>)
rs.summ &lt;-<span class="st"> </span><span class="kw">summary</span>(rs.ks)
rs.summ</code></pre></div>
<pre><code>Subset selection object
8 Variables  (and intercept)
          Forced in Forced out
lcavol        FALSE      FALSE
lweight       FALSE      FALSE
age           FALSE      FALSE
bph_f         FALSE      FALSE
svi_f         FALSE      FALSE
lcp           FALSE      FALSE
gleason_f     FALSE      FALSE
pgg45         FALSE      FALSE
1 subsets of each size up to 8
Selection Algorithm: exhaustive
         lcavol lweight age bph_f svi_f lcp gleason_f pgg45
1  ( 1 ) &quot;*&quot;    &quot; &quot;     &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
2  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
3  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot; &quot; &quot; &quot;   &quot;*&quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
4  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot; &quot; &quot;*&quot;   &quot;*&quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
5  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
6  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot; &quot; &quot;*&quot;       &quot; &quot;  
7  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot; &quot;*&quot;       &quot; &quot;  
8  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot; &quot;*&quot;       &quot;*&quot;  </code></pre>
<p>So…</p>
<ul>
<li>the best one-predictor model used <code>lcavol</code></li>
<li>the best two-predictor model used <code>lcavol</code> and <code>lweight</code></li>
<li>the best three-predictor model used <code>lcavol</code>, <code>lweight</code> and <code>svi_f</code></li>
<li>the best four-predictor model added <code>bph_f</code>, and</li>
<li>the best five-predictor model added <code>age</code></li>
<li>the best six-input model added <code>gleason_f</code>,</li>
<li>the best seven-input model added <code>lcp</code>,</li>
<li>and the eight-input model adds <code>pgg45</code>.</li>
</ul>
<p>All of these “best subsets” are hierarchical, in that each model is a subset of the one below it. This isn’t inevitably true.</p>
<ul>
<li>To determine which model is best, we can plot key summaries of model fit (adjusted R<sup>2</sup>, Mallows’ <span class="math inline">\(C_p\)</span>, bias-corrected AIC, and BIC) using either base R plotting techniques (what I’ve done in the past) or <code>ggplot2</code> (what I use now.) I’ll show both types of plotting approaches in the next two sections.</li>
</ul>
<div id="identifying-the-models-with-which-and-outmat" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Identifying the models with <code>which</code> and <code>outmat</code></h3>
<p>To see the models selected by the system, we use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rs.summ<span class="op">$</span>which</code></pre></div>
<pre><code>  (Intercept) lcavol lweight   age bph_f svi_f   lcp gleason_f pgg45
1        TRUE   TRUE   FALSE FALSE FALSE FALSE FALSE     FALSE FALSE
2        TRUE   TRUE    TRUE FALSE FALSE FALSE FALSE     FALSE FALSE
3        TRUE   TRUE    TRUE FALSE FALSE  TRUE FALSE     FALSE FALSE
4        TRUE   TRUE    TRUE FALSE  TRUE  TRUE FALSE     FALSE FALSE
5        TRUE   TRUE    TRUE  TRUE  TRUE  TRUE FALSE     FALSE FALSE
6        TRUE   TRUE    TRUE  TRUE  TRUE  TRUE FALSE      TRUE FALSE
7        TRUE   TRUE    TRUE  TRUE  TRUE  TRUE  TRUE      TRUE FALSE
8        TRUE   TRUE    TRUE  TRUE  TRUE  TRUE  TRUE      TRUE  TRUE</code></pre>
<p>Another version of this formatted for printing is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rs.summ<span class="op">$</span>outmat</code></pre></div>
<pre><code>         lcavol lweight age bph_f svi_f lcp gleason_f pgg45
1  ( 1 ) &quot;*&quot;    &quot; &quot;     &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
2  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
3  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot; &quot; &quot; &quot;   &quot;*&quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
4  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot; &quot; &quot;*&quot;   &quot;*&quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
5  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
6  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot; &quot; &quot;*&quot;       &quot; &quot;  
7  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot; &quot;*&quot;       &quot; &quot;  
8  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot; &quot;*&quot;       &quot;*&quot;  </code></pre>
<p>We built one subset of each size up to eight predictors, and if we add the intercept term, this means we have models of size k = 2, 3, 4, 5, 6, 7, 8 and 9.</p>
<p>The models are:</p>
<table>
<thead>
<tr class="header">
<th align="right">Size k</th>
<th>Predictors included (besides intercept)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
<td><code>lcavol</code></td>
</tr>
<tr class="even">
<td align="right">3</td>
<td><code>lcavol</code> and <code>lweight</code></td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td>add <code>svi_f</code></td>
</tr>
<tr class="even">
<td align="right">5</td>
<td>add <code>bph_f</code></td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td>add <code>age</code></td>
</tr>
<tr class="even">
<td align="right">7</td>
<td>add <code>gleason_f</code></td>
</tr>
<tr class="odd">
<td align="right">8</td>
<td>add <code>lcp</code></td>
</tr>
<tr class="even">
<td align="right">9</td>
<td>add <code>pgg45</code></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="calculating-bias-corrected-aic" class="section level2">
<h2><span class="header-section-number">8.3</span> Calculating bias-corrected AIC</h2>
<p>The bias-corrected AIC formula developed in <span class="citation">Hurvich and Tsai (<a href="#ref-HurvichTsai1989">1989</a>)</span> requires three inputs:</p>
<ul>
<li>the residual sum of squares for a model</li>
<li>the sample size (n) or number of observations used to fit the model</li>
<li>the number of regression inputs, k, including the intercept, used in the model</li>
</ul>
<p>So, for a particular model fit to <em>n</em> observations, on <em>k</em> predictors (including the intercept) and a residual sum of squares equal to RSS, we have:</p>
<p><span class="math display">\[
AIC_c = n log(\frac{RSS}{n}) + 2k + \frac{2k (k+1)}{n-k-1}
\]</span></p>
<p>Note that the corrected <span class="math inline">\(AIC_c\)</span> can be related to the original AIC via:</p>
<p><span class="math display">\[
AIC_c = AIC + \frac{2k (k+1)}{n - k - 1}
\]</span></p>
<div id="calculation-of-aic.c-in-our-setting" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Calculation of aic.c in our setting</h3>
<p>In our case, we have <span class="math inline">\(n\)</span> = 97 observations, and built a series of models with <span class="math inline">\(k\)</span> = <code>2:9</code> predictors (including the intercept in each case), so we will insert those values into the general formula for bias-corrected AIC which is:</p>
<pre><code>aic.c &lt;- n * log( rs.summ$rss / n) + 2 * k + 
                      (2 * k * (k + 1) / (n - k - 1))</code></pre>
<p>We can obtain the residual sum of squares explained by each model by pulling <code>rss</code> from the <code>regsubsets</code> summary contained here in <code>rs.summ</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data_frame</span>(<span class="dt">k =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>, <span class="dt">RSS =</span> rs.summ<span class="op">$</span>rss)</code></pre></div>
<pre><code># A tibble: 8 x 2
      k   RSS
  &lt;int&gt; &lt;dbl&gt;
1     2  58.9
2     3  51.7
3     4  46.6
4     5  45.7
5     6  44.6
6     7  43.7
7     8  43.0
8     9  42.8</code></pre>
<p>In this case, we have:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rs.summ<span class="op">$</span>aic.c &lt;-<span class="st"> </span><span class="dv">97</span><span class="op">*</span><span class="kw">log</span>(rs.summ<span class="op">$</span>rss <span class="op">/</span><span class="st"> </span><span class="dv">97</span>) <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">+</span>
<span class="st">               </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">*</span><span class="st"> </span>((<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>)<span class="op">+</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(<span class="dv">97</span> <span class="op">-</span><span class="st"> </span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))

<span class="kw">round</span>(rs.summ<span class="op">$</span>aic.c,<span class="dv">2</span>) <span class="co"># bias-corrected</span></code></pre></div>
<pre><code>[1] -44.24 -54.70 -62.74 -62.29 -62.34 -62.11 -61.17 -59.36</code></pre>
<p>The impact of this bias correction can be modest but important. Here’s a little table looking closely at the results in this problem. The uncorrected AIC are obtained using <code>extractAIC</code>, as described in the next section.</p>
<table>
<thead>
<tr class="header">
<th align="right">Size</th>
<th align="right">2</th>
<th align="right">3</th>
<th align="right">4</th>
<th align="right">5</th>
<th align="right">6</th>
<th align="right">7</th>
<th align="right">8</th>
<th align="right">9</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Bias-corrected AIC</td>
<td align="right">-44.2</td>
<td align="right">-54.7</td>
<td align="right">-62.7</td>
<td align="right">-62.3</td>
<td align="right">-62.3</td>
<td align="right">-62.1</td>
<td align="right">-61.2</td>
<td align="right">-59.4</td>
</tr>
<tr class="even">
<td align="right">Uncorrected AIC</td>
<td align="right">-44.4</td>
<td align="right">-55.0</td>
<td align="right">-63.2</td>
<td align="right">-62.4</td>
<td align="right">-63.4</td>
<td align="right">-63.0</td>
<td align="right">-62.4</td>
<td align="right">-61.4</td>
</tr>
</tbody>
</table>
</div>
<div id="the-uncorrected-aic-provides-no-more-useful-information-here" class="section level3">
<h3><span class="header-section-number">8.3.2</span> The Uncorrected AIC provides no more useful information here</h3>
<p>We could, if necessary, also calculate the <em>uncorrected</em> AIC value for each model, but we won’t make any direct use of that, because that will not provide any new information not already gathered by the <span class="math inline">\(C_p\)</span> statistic for a linear regression model. If you wanted to find the uncorrected AIC for a given model, you can use the <code>extractAIC</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">extractAIC</span>(<span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol, <span class="dt">data =</span> prost))</code></pre></div>
<pre><code>[1]   2.00000 -44.36603</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">extractAIC</span>(<span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight, <span class="dt">data =</span> prost))</code></pre></div>
<pre><code>[1]   3.00000 -54.95846</code></pre>
<p>Note that:</p>
<ul>
<li>these results are fairly comparable to the bias-corrected AIC we built above, and</li>
<li>the <code>extractAIC</code> and <code>AIC</code> functions look like they give very different results, but they really don’t.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(<span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol, <span class="dt">data =</span> prost))</code></pre></div>
<pre><code>[1] 232.908</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(<span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight, <span class="dt">data =</span> prost))</code></pre></div>
<pre><code>[1] 222.3156</code></pre>
<p>But notice that the differences in AIC are the same, either way, comparing these two models:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">extractAIC</span>(<span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol, <span class="dt">data =</span> prost)) <span class="op">-</span><span class="st"> </span><span class="kw">extractAIC</span>(<span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight, <span class="dt">data =</span> prost))</code></pre></div>
<pre><code>[1] -1.00000 10.59243</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(<span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol, <span class="dt">data =</span> prost)) <span class="op">-</span><span class="st"> </span><span class="kw">AIC</span>(<span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight, <span class="dt">data =</span> prost))</code></pre></div>
<pre><code>[1] 10.59243</code></pre>
<ul>
<li>AIC is only defined up to an additive constant.</li>
<li>Since the difference between two models using either <code>AIC</code> or <code>extractAIC</code> is the same, this doesn’t actually matter which one we use, so long as we use the same one consistently.</li>
</ul>
</div>
<div id="building-a-tibble-containing-the-necessary-information" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Building a Tibble containing the necessary information</h3>
<p>Again, note the use of 2:9 for the values of <span class="math inline">\(k\)</span>, because we’re fitting one model for each size from 2 through 9.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">best_mods_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">data_frame</span>(
    <span class="dt">k =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>,
    <span class="dt">r2 =</span> rs.summ<span class="op">$</span>rsq,
    <span class="dt">adjr2 =</span> rs.summ<span class="op">$</span>adjr2,
    <span class="dt">cp =</span> rs.summ<span class="op">$</span>cp,
    <span class="dt">aic.c =</span> rs.summ<span class="op">$</span>aic.c,
    <span class="dt">bic =</span> rs.summ<span class="op">$</span>bic
)

best_mods &lt;-<span class="st"> </span><span class="kw">cbind</span>(best_mods_<span class="dv">1</span>, rs.summ<span class="op">$</span>which)

best_mods</code></pre></div>
<pre><code>  k        r2     adjr2        cp     aic.c       bic (Intercept) lcavol
1 2 0.5394320 0.5345839 28.213914 -44.23838 -66.05416        TRUE   TRUE
2 3 0.5955040 0.5868977 15.456669 -54.70040 -74.07188        TRUE   TRUE
3 4 0.6359499 0.6242063  6.811986 -62.74265 -79.71614        TRUE   TRUE
4 5 0.6425479 0.6270065  7.075509 -62.29223 -76.91557        TRUE   TRUE
5 6 0.6509970 0.6318211  6.851826 -62.33858 -74.66120        TRUE   TRUE
6 7 0.6584484 0.6356783  6.890739 -62.10692 -72.17992        TRUE   TRUE
7 8 0.6634967 0.6370302  7.562119 -61.17338 -69.04961        TRUE   TRUE
8 9 0.6656326 0.6352355  9.000000 -59.35841 -65.09253        TRUE   TRUE
  lweight   age bph_f svi_f   lcp gleason_f pgg45
1   FALSE FALSE FALSE FALSE FALSE     FALSE FALSE
2    TRUE FALSE FALSE FALSE FALSE     FALSE FALSE
3    TRUE FALSE FALSE  TRUE FALSE     FALSE FALSE
4    TRUE FALSE  TRUE  TRUE FALSE     FALSE FALSE
5    TRUE  TRUE  TRUE  TRUE FALSE     FALSE FALSE
6    TRUE  TRUE  TRUE  TRUE FALSE      TRUE FALSE
7    TRUE  TRUE  TRUE  TRUE  TRUE      TRUE FALSE
8    TRUE  TRUE  TRUE  TRUE  TRUE      TRUE  TRUE</code></pre>
</div>
</div>
<div id="plotting-the-best-subsets-results-using-ggplot2" class="section level2">
<h2><span class="header-section-number">8.4</span> Plotting the Best Subsets Results using <code>ggplot2</code></h2>
<div id="the-adjusted-r2-plot" class="section level3">
<h3><span class="header-section-number">8.4.1</span> The Adjusted R<sup>2</sup> Plot</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(best_mods, <span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> adjr2,
                            <span class="dt">label =</span> <span class="kw">round</span>(adjr2,<span class="dv">2</span>))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_label</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_label</span>(<span class="dt">data =</span> <span class="kw">subset</span>(best_mods,
                             adjr2 <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(adjr2)),
               <span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> adjr2, <span class="dt">label =</span> <span class="kw">round</span>(adjr2,<span class="dv">2</span>)),
               <span class="dt">fill =</span> <span class="st">&quot;yellow&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;# of predictors (including intercept)&quot;</span>,
         <span class="dt">y =</span> <span class="st">&quot;Adjusted R-squared&quot;</span>)

p1</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
<p>Models 4-9 all look like reasonable choices here. The maximum adjusted R<sup>2</sup> is seen in the model of size 8.</p>
</div>
<div id="mallows-c_p" class="section level3">
<h3><span class="header-section-number">8.4.2</span> Mallows’ <span class="math inline">\(C_p\)</span></h3>
<p>The <span class="math inline">\(C_p\)</span> statistic focuses directly on the tradeoff between <strong>bias</strong> (due to excluding important predictors from the model) and extra <strong>variance</strong> (due to including too many unimportant predictors in the model.)</p>
<p>If N is the sample size, and we select <span class="math inline">\(p\)</span> regression predictors from a set of <span class="math inline">\(K\)</span> (where <span class="math inline">\(p &lt; K\)</span>), then the <span class="math inline">\(C_p\)</span> statistic is</p>
<p><span class="math inline">\(C_p = \frac{SSE_p}{MSE_K} - N + 2p\)</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(SSE_p\)</span> is the sum of squares for error (residual) in the model with <span class="math inline">\(p\)</span> predictors</li>
<li><span class="math inline">\(MSE_K\)</span> is the residual mean square after regression in the model with all <span class="math inline">\(K\)</span> predictors</li>
</ul>
<p>As it turns out, this is just measuring the particular model’s lack of fit, and then adding a penalty for the number of terms in the model (specifically <span class="math inline">\(2p - N\)</span> is the penalty since the lack of fit is measured as <span class="math inline">\((N-p) \frac{SSE_p}{MSE_K}\)</span>.</p>
<ul>
<li>If a model has no meaningful lack of fit (i.e. no substantial bias) then the expected value of <span class="math inline">\(C_p\)</span> is roughly <span class="math inline">\(p\)</span>.</li>
<li>Otherwise, the expectation is <span class="math inline">\(p\)</span> plus a positive bias term.</li>
<li>In general, we want to see <em>smaller</em> values of <span class="math inline">\(C_p\)</span>.</li>
<li>We usually select a “winning model” by choosing a subset of predictors that have <span class="math inline">\(C_p\)</span> near the value of <span class="math inline">\(p\)</span>.</li>
</ul>
</div>
<div id="the-c_p-plot" class="section level3">
<h3><span class="header-section-number">8.4.3</span> The <span class="math inline">\(C_p\)</span> Plot</h3>
<p>The <span class="math inline">\(C_p\)</span> plot is just a scatterplot of <span class="math inline">\(C_p\)</span> on the Y-axis, and the size of the model (coefficients plus intercept) <span class="math inline">\(p = k\)</span> on the X-axis.</p>
<p>Each of the various predictor subsets we will study is represented in a single point. A model without bias should have <span class="math inline">\(C_p\)</span> roughly equal to <span class="math inline">\(p\)</span>, so we’ll frequently draw a line at <span class="math inline">\(C_p = p\)</span> to make that clear. We then select our model from among all models with small <span class="math inline">\(C_p\)</span> statistics.</p>
<ul>
<li>My typical approach is to identify the models where <span class="math inline">\(C_p - p \geq 0\)</span>, then select from among those models the model where <span class="math inline">\(C_p - p\)</span> is minimized, and if there is a tie, select the model where <span class="math inline">\(p\)</span> is minimized.</li>
<li>Another good candidate might be a slightly overfit model (where <span class="math inline">\(C_p - p &lt; 0\)</span> but just barely.)</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(best_mods, <span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> cp,
                            <span class="dt">label =</span> <span class="kw">round</span>(cp,<span class="dv">1</span>))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_label</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>,
                <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;# of predictors (including intercept)&quot;</span>,
         <span class="dt">y =</span> <span class="st">&quot;Mallows&#39; Cp&quot;</span>)

p2</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<ul>
<li>Model 6 is a possibility here, with the difference <span class="math inline">\(C_p - p\)</span> minimized among all models with <span class="math inline">\(C_p &gt;= p\)</span>.</li>
<li>Model 7 also looks pretty good, with C<sub>p</sub> just barely smaller than the size (p = 7) of the model.</li>
</ul>
</div>
<div id="all-subsets-regression-and-information-criteria" class="section level3">
<h3><span class="header-section-number">8.4.4</span> “All Subsets” Regression and Information Criteria</h3>
<p>We might consider any of three main information criteria:</p>
<ul>
<li>the Bayesian Information Criterion, called BIC</li>
<li>the Akaike Information Criterion (used by R’s default stepwise approaches,) called AIC</li>
<li>a corrected version of AIC due to <span class="citation">Hurvich and Tsai (<a href="#ref-HurvichTsai1989">1989</a>)</span>, called AIC<sub>c</sub> or <code>aic.c</code></li>
</ul>
<p>Each of these indicates better models by getting smaller. Since the <span class="math inline">\(C_p\)</span> and AIC results will lead to the same model, I’ll focus on plotting the bias-corrected AIC and on BIC.</p>
</div>
<div id="the-bias-corrected-aic-plot" class="section level3">
<h3><span class="header-section-number">8.4.5</span> The bias-corrected AIC plot</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p3 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(best_mods, <span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> aic.c,
                             <span class="dt">label =</span> <span class="kw">round</span>(aic.c,<span class="dv">1</span>))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_label</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_label</span>(<span class="dt">data =</span> <span class="kw">subset</span>(best_mods, aic.c <span class="op">==</span><span class="st"> </span><span class="kw">min</span>(aic.c)),
               <span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> aic.c), <span class="dt">fill =</span> <span class="st">&quot;pink&quot;</span>, 
               <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;# of predictors (including intercept)&quot;</span>,
         <span class="dt">y =</span> <span class="st">&quot;Bias-Corrected AIC&quot;</span>)

p3</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<p>The smallest AIC<sub>c</sub> values occur in models 4 and later, especially model 4 itself.</p>
</div>
<div id="the-bic-plot" class="section level3">
<h3><span class="header-section-number">8.4.6</span> The BIC plot</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p4 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(best_mods, <span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> bic,
                            <span class="dt">label =</span> <span class="kw">round</span>(bic,<span class="dv">1</span>))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_label</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_label</span>(<span class="dt">data =</span> <span class="kw">subset</span>(best_mods, bic <span class="op">==</span><span class="st"> </span><span class="kw">min</span>(bic)),
               <span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> bic),
               <span class="dt">fill =</span> <span class="st">&quot;lightgreen&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;# of predictors (including intercept)&quot;</span>,
         <span class="dt">y =</span> <span class="st">&quot;BIC&quot;</span>)

p4</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
</div>
<div id="all-four-plots-in-one-figure-via-ggplot2" class="section level3">
<h3><span class="header-section-number">8.4.7</span> All Four Plots in One Figure (via ggplot2)</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gridExtra<span class="op">::</span><span class="kw">grid.arrange</span>(p1, p2, p3, p4, <span class="dt">nrow =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
</div>
</div>
<div id="table-of-key-results" class="section level2">
<h2><span class="header-section-number">8.5</span> Table of Key Results</h2>
<p>We can build a big table, like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">best_mods</code></pre></div>
<pre><code>  k        r2     adjr2        cp     aic.c       bic (Intercept) lcavol
1 2 0.5394320 0.5345839 28.213914 -44.23838 -66.05416        TRUE   TRUE
2 3 0.5955040 0.5868977 15.456669 -54.70040 -74.07188        TRUE   TRUE
3 4 0.6359499 0.6242063  6.811986 -62.74265 -79.71614        TRUE   TRUE
4 5 0.6425479 0.6270065  7.075509 -62.29223 -76.91557        TRUE   TRUE
5 6 0.6509970 0.6318211  6.851826 -62.33858 -74.66120        TRUE   TRUE
6 7 0.6584484 0.6356783  6.890739 -62.10692 -72.17992        TRUE   TRUE
7 8 0.6634967 0.6370302  7.562119 -61.17338 -69.04961        TRUE   TRUE
8 9 0.6656326 0.6352355  9.000000 -59.35841 -65.09253        TRUE   TRUE
  lweight   age bph_f svi_f   lcp gleason_f pgg45
1   FALSE FALSE FALSE FALSE FALSE     FALSE FALSE
2    TRUE FALSE FALSE FALSE FALSE     FALSE FALSE
3    TRUE FALSE FALSE  TRUE FALSE     FALSE FALSE
4    TRUE FALSE  TRUE  TRUE FALSE     FALSE FALSE
5    TRUE  TRUE  TRUE  TRUE FALSE     FALSE FALSE
6    TRUE  TRUE  TRUE  TRUE FALSE      TRUE FALSE
7    TRUE  TRUE  TRUE  TRUE  TRUE      TRUE FALSE
8    TRUE  TRUE  TRUE  TRUE  TRUE      TRUE  TRUE</code></pre>
</div>
<div id="models-worth-considering" class="section level2">
<h2><span class="header-section-number">8.6</span> Models Worth Considering?</h2>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(k\)</span></th>
<th align="right">Predictors</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4</td>
<td align="right"><code>lcavol lweight svi_f</code></td>
<td>minimizes BIC, AIC<sub>c</sub></td>
</tr>
<tr class="even">
<td align="right">7</td>
<td align="right"><code>+ age bph_f gleason_f</code></td>
<td><span class="math inline">\(C_p\)</span> near <em>p</em></td>
</tr>
<tr class="odd">
<td align="right">8</td>
<td align="right"><code>+ lcp</code></td>
<td>max <span class="math inline">\(R^2_{adj}\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="compare-these-candidate-models-in-sample" class="section level2">
<h2><span class="header-section-number">8.7</span> Compare these candidate models in-sample?</h2>
<div id="using-anova-to-compare-nested-models" class="section level3">
<h3><span class="header-section-number">8.7.1</span> Using <code>anova</code> to compare nested models</h3>
<p>Let’s run an ANOVA-based comparison of these nested models to each other and to the model with the intercept alone.</p>
<ul>
<li>The models are <strong>nested</strong> because <code>m04</code> is a subset of the predictors in <code>m07</code>, which includes a subset of the predictors in <code>m08</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m.int &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> prost)
m04 &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi_f, <span class="dt">data =</span> prost)
m07 &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi_f <span class="op">+</span><span class="st"> </span>
<span class="st">              </span>age <span class="op">+</span><span class="st"> </span>bph_f <span class="op">+</span><span class="st"> </span>gleason_f, <span class="dt">data =</span> prost)
m08 &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi_f <span class="op">+</span><span class="st"> </span>
<span class="st">              </span>age <span class="op">+</span><span class="st"> </span>bph_f <span class="op">+</span><span class="st"> </span>gleason_f <span class="op">+</span><span class="st"> </span>lcp, <span class="dt">data =</span> prost)
m.full &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi_f <span class="op">+</span><span class="st"> </span>
<span class="st">              </span>age <span class="op">+</span><span class="st"> </span>bph_f <span class="op">+</span><span class="st"> </span>gleason_f <span class="op">+</span><span class="st"> </span>lcp <span class="op">+</span><span class="st"> </span>pgg45, <span class="dt">data =</span> prost)</code></pre></div>
<p>Next, we’ll run…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(m.full, m08, m07, m04, m.int)</code></pre></div>
<pre><code>Analysis of Variance Table

Model 1: lpsa ~ lcavol + lweight + svi_f + age + bph_f + gleason_f + lcp + 
    pgg45
Model 2: lpsa ~ lcavol + lweight + svi_f + age + bph_f + gleason_f + lcp
Model 3: lpsa ~ lcavol + lweight + svi_f + age + bph_f + gleason_f
Model 4: lpsa ~ lcavol + lweight + svi_f
Model 5: lpsa ~ 1
  Res.Df     RSS Df Sum of Sq       F Pr(&gt;F)    
1     86  41.057                                
2     87  41.498 -1    -0.441  0.9234 0.3393    
3     88  42.066 -1    -0.568  1.1891 0.2786    
4     93  46.568 -5    -4.503  1.8863 0.1050    
5     96 127.918 -3   -81.349 56.7991 &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>What conclusions can we draw here, on the basis of these ANOVA tests?</p>
<ul>
<li>The first <em>p</em> value, of 0.3393, compares what the <code>anova</code> called Model 1, and what we call <code>m.full</code> to what the <code>anova</code> called Model 2, and what we call <code>m08</code>. So there’s no significant decline in predictive value observed when we drop from the <code>m.full</code> model to the <code>m08</code> model. This suggests that the <code>m08</code> model may be a better choice.</li>
<li>The second <em>p</em> value, of 0.2786, compares <code>m08</code> to <code>m07</code>, and suggests that we lose no significant predictive value by dropping down to <code>m07</code>.</li>
<li>The third <em>p</em> value, of 0.1050, compares <code>m07</code> to <code>m04</code>, and suggests that we lose no significant predictive value by dropping down to <code>m04</code>.</li>
<li>But the fourth <em>p</em> value, of 2e-16 (or, functionally, zero), compares <code>m04</code> to <code>m.int</code> and suggests that we do gain significant predictive value by including the predictors in <code>m04</code> as compared to a model with an intercept alone.</li>
<li>So, by the significance tests, the model we’d select would be <code>m04</code>, but, of course, in-sample statistical significance alone isn’t a good enough reason to select a model if we want to do prediction well.</li>
</ul>
</div>
</div>
<div id="aic-and-bic-comparisons-within-the-training-sample" class="section level2">
<h2><span class="header-section-number">8.8</span> AIC and BIC comparisons, within the training sample</h2>
<p>Next, we’ll compare the three candidate models (ignoring the intercept-only and kitchen sink models) in terms of their AIC values and BIC values, again using the same sample we used to fit the models in the first place.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">AIC</span>(m04, m07, m08)</code></pre></div>
<pre><code>    df      AIC
m04  5 214.0966
m07 10 214.2327
m08 11 214.9148</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">BIC</span>(m04, m07, m08)</code></pre></div>
<pre><code>    df      BIC
m04  5 226.9702
m07 10 239.9798
m08 11 243.2366</code></pre>
<ul>
<li>The model with the smallest AIC value shows the best performance within the sample on that measure.</li>
<li>Similarly, smaller BIC values are associated with predictor sets that perform better in sample on that criterion.</li>
<li>BIC often suggests smaller models (with fewer regression inputs) than does AIC. Does that happen in this case?</li>
<li>Note that <code>AIC</code> and <code>BIC</code> can be calculated in a few different ways, so we may see some variation if we don’t compare apples to apples with regard to the R functions involved.</li>
</ul>
</div>
<div id="cross-validation-of-candidate-models-out-of-sample" class="section level2">
<h2><span class="header-section-number">8.9</span> Cross-Validation of Candidate Models out of Sample</h2>
<div id="fold-cross-validation-of-model-m04" class="section level3">
<h3><span class="header-section-number">8.9.1</span> 20-fold Cross-Validation of model <code>m04</code></h3>
<p>Model <code>m04</code> uses <code>lcavol</code>, <code>lweight</code> and <code>svi_f</code> to predict the <code>lpsa</code> outcome. Let’s do 20-fold cross-validation of this modeling approach, and calculate the root mean squared prediction error and the mean absolute prediction error for that modeling scheme.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">43201</span>)

cv_m04 &lt;-<span class="st"> </span>prost <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">crossv_kfold</span>(<span class="dt">k =</span> <span class="dv">20</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(train, 
                       <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi_f,
                                   <span class="dt">data =</span> .)))

cv_m04_pred &lt;-<span class="st"> </span>cv_m04 <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">unnest</span>(<span class="kw">map2</span>(model, test, <span class="op">~</span><span class="st"> </span><span class="kw">augment</span>(.x, <span class="dt">newdata =</span> .y)))

cv_m04_results &lt;-<span class="st"> </span>cv_m04_pred <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">Model =</span> <span class="st">&quot;m04&quot;</span>, 
              <span class="dt">RMSE =</span> <span class="kw">sqrt</span>(<span class="kw">mean</span>((lpsa <span class="op">-</span><span class="st"> </span>.fitted) <span class="op">^</span><span class="dv">2</span>)),
              <span class="dt">MAE =</span> <span class="kw">mean</span>(<span class="kw">abs</span>(lpsa <span class="op">-</span><span class="st"> </span>.fitted)))

cv_m04_results</code></pre></div>
<pre><code># A tibble: 1 x 3
  Model  RMSE   MAE
  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
1 m04   0.725 0.574</code></pre>
</div>
<div id="fold-cross-validation-of-model-m07" class="section level3">
<h3><span class="header-section-number">8.9.2</span> 20-fold Cross-Validation of model <code>m07</code></h3>
<p>Model <code>m07</code> uses <code>lcavol</code>, <code>lweight</code>, <code>svi_f</code>, <code>age</code>, <code>bph_f</code>, and <code>gleason_f</code> to predict the <code>lpsa</code> outcome. Let’s now do 20-fold cross-validation of this modeling approach, and calculate the root mean squared prediction error and the mean absolute prediction error for that modeling scheme. Note the small changes required, as compared to our cross-validation of model <code>m04</code> a moment ago.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">43202</span>)

cv_m07 &lt;-<span class="st"> </span>prost <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">crossv_kfold</span>(<span class="dt">k =</span> <span class="dv">20</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(train, 
                       <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>
<span class="st">                                </span>svi_f <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>bph_f <span class="op">+</span><span class="st"> </span>
<span class="st">                                </span>gleason_f,
                                   <span class="dt">data =</span> .)))

cv_m07_pred &lt;-<span class="st"> </span>cv_m07 <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">unnest</span>(<span class="kw">map2</span>(model, test, <span class="op">~</span><span class="st"> </span><span class="kw">augment</span>(.x, <span class="dt">newdata =</span> .y)))

cv_m07_results &lt;-<span class="st"> </span>cv_m07_pred <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">Model =</span> <span class="st">&quot;m07&quot;</span>, 
              <span class="dt">RMSE =</span> <span class="kw">sqrt</span>(<span class="kw">mean</span>((lpsa <span class="op">-</span><span class="st"> </span>.fitted) <span class="op">^</span><span class="dv">2</span>)),
              <span class="dt">MAE =</span> <span class="kw">mean</span>(<span class="kw">abs</span>(lpsa <span class="op">-</span><span class="st"> </span>.fitted)))

cv_m07_results</code></pre></div>
<pre><code># A tibble: 1 x 3
  Model  RMSE   MAE
  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
1 m07   0.730 0.556</code></pre>
</div>
<div id="fold-cross-validation-of-model-m08" class="section level3">
<h3><span class="header-section-number">8.9.3</span> 20-fold Cross-Validation of model <code>m08</code></h3>
<p>Model <code>m08</code> uses <code>lcavol</code>, <code>lweight</code>, <code>svi_f</code>, <code>age</code>, <code>bph_f</code>, <code>gleason_f</code> and <code>lcp</code> to predict the <code>lpsa</code> outcome. Let’s now do 20-fold cross-validation of this modeling approach.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">43202</span>)

cv_m08 &lt;-<span class="st"> </span>prost <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">crossv_kfold</span>(<span class="dt">k =</span> <span class="dv">20</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">map</span>(train, 
                       <span class="op">~</span><span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>
<span class="st">                                </span>svi_f <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>bph_f <span class="op">+</span><span class="st"> </span>
<span class="st">                                </span>gleason_f <span class="op">+</span><span class="st"> </span>lcp,
                                   <span class="dt">data =</span> .)))

cv_m08_pred &lt;-<span class="st"> </span>cv_m08 <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">unnest</span>(<span class="kw">map2</span>(model, test, <span class="op">~</span><span class="st"> </span><span class="kw">augment</span>(.x, <span class="dt">newdata =</span> .y)))

cv_m08_results &lt;-<span class="st"> </span>cv_m08_pred <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">Model =</span> <span class="st">&quot;m08&quot;</span>, 
              <span class="dt">RMSE =</span> <span class="kw">sqrt</span>(<span class="kw">mean</span>((lpsa <span class="op">-</span><span class="st"> </span>.fitted) <span class="op">^</span><span class="dv">2</span>)),
              <span class="dt">MAE =</span> <span class="kw">mean</span>(<span class="kw">abs</span>(lpsa <span class="op">-</span><span class="st"> </span>.fitted)))

cv_m08_results</code></pre></div>
<pre><code># A tibble: 1 x 3
  Model  RMSE   MAE
  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
1 m08   0.729 0.557</code></pre>
</div>
<div id="comparing-the-results-of-the-cross-validations" class="section level3">
<h3><span class="header-section-number">8.9.4</span> Comparing the Results of the Cross-Validations</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bind_rows</span>(cv_m04_results, cv_m07_results, cv_m08_results)</code></pre></div>
<pre><code># A tibble: 3 x 3
  Model  RMSE   MAE
  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;
1 m04   0.725 0.574
2 m07   0.730 0.556
3 m08   0.729 0.557</code></pre>
<p>It appears that model <code>m04</code> has the smallest RMSE and MAE in this case. So, that’s the model with the strongest cross-validated predictive accuracy, by these two standards.</p>
</div>
</div>
<div id="what-about-interaction-terms" class="section level2">
<h2><span class="header-section-number">8.10</span> What about Interaction Terms?</h2>
<p>Suppose we consider for a moment a much smaller and less realistic problem. We want to use best subsets to identify a model out of a set of three predictors for <code>lpsa</code>: specifically <code>lcavol</code>, <code>age</code> and <code>svi_f</code>, but now we also want to consider the interaction of <code>svi_f</code> with <code>lcavol</code> as a potential addition. Remember that <code>svi</code> is the 1/0 numeric version of <code>svi_f</code>. We could simply add a numerical product term to our model, as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred2 &lt;-<span class="st"> </span><span class="kw">with</span>(prost, <span class="kw">cbind</span>(lcavol, age, svi_f, <span class="dt">svixlcavol =</span> svi<span class="op">*</span>lcavol))

rs.ks2 &lt;-<span class="st"> </span><span class="kw">regsubsets</span>(pred2, <span class="dt">y =</span> prost<span class="op">$</span>lpsa, 
                    <span class="dt">nvmax =</span> <span class="ot">NULL</span>, <span class="dt">nbest =</span> <span class="dv">1</span>)
rs.summ2 &lt;-<span class="st"> </span><span class="kw">summary</span>(rs.ks2)
rs.summ2</code></pre></div>
<pre><code>Subset selection object
4 Variables  (and intercept)
           Forced in Forced out
lcavol         FALSE      FALSE
age            FALSE      FALSE
svi_f          FALSE      FALSE
svixlcavol     FALSE      FALSE
1 subsets of each size up to 4
Selection Algorithm: exhaustive
         lcavol age svi_f svixlcavol
1  ( 1 ) &quot;*&quot;    &quot; &quot; &quot; &quot;   &quot; &quot;       
2  ( 1 ) &quot;*&quot;    &quot; &quot; &quot;*&quot;   &quot; &quot;       
3  ( 1 ) &quot;*&quot;    &quot; &quot; &quot;*&quot;   &quot;*&quot;       
4  ( 1 ) &quot;*&quot;    &quot;*&quot; &quot;*&quot;   &quot;*&quot;       </code></pre>
<p>In this case, best subsets doesn’t identify the interaction term as an attractive predictor until it has already included the main effects that go into it. So that’s fine. But if that isn’t the case, we would have a problem.</p>
<p>To resolve this, we could:</p>
<ol style="list-style-type: decimal">
<li>Consider interactions beforehand, and force them in if desired.</li>
<li>Consider interaction terms outside of best subsets, and only after the selection of main effects.</li>
<li>Use another approach to deal with variable selection for interaction terms.</li>
</ol>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-HurvichTsai1989">
<p>Hurvich, Clifford M., and Chih-Ling Tsai. 1989. “Regression and Time Series Model Selection in Small Samples.” <em>Biometrika</em> 76: 297–307. <a href="https://www.stat.berkeley.edu/~binyu/summer08/Hurvich.AICc.pdf" class="uri">https://www.stat.berkeley.edu/~binyu/summer08/Hurvich.AICc.pdf</a>.</p>
</div>
<div id="ref-Hastie2001">
<p>Hastie, Trevor, Robert Tibshriani, and Jerome H. Frideman. 2001. <em>The Elements of Statistical Learning</em>. New York: Springer.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="stepwise-variable-selection.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="adding-non-linear-terms-to-a-linear-regression-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08_bestsubsets.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
