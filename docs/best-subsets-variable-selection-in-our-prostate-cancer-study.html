<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Data Science for Biological, Medical and Health Research: Notes for 432</title>
  <meta name="description" content="These are the Course Notes for 432.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Data Science for Biological, Medical and Health Research: Notes for 432" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are the Course Notes for 432." />
  <meta name="github-repo" content="thomaselove/432-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Science for Biological, Medical and Health Research: Notes for 432" />
  
  <meta name="twitter:description" content="These are the Course Notes for 432." />
  

<meta name="author" content="Thomas E. Love, Ph.D.">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="stepwise-variable-selection.html">
<link rel="next" href="references.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">432 Course Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="r-packages-used-in-these-notes.html"><a href="r-packages-used-in-these-notes.html"><i class="fa fa-check"></i>R Packages used in these notes</a></li>
<li class="chapter" data-level="" data-path="data-used-in-these-notes.html"><a href="data-used-in-these-notes.html"><i class="fa fa-check"></i>Data used in these notes</a></li>
<li class="chapter" data-level="" data-path="special-functions-used-in-these-notes.html"><a href="special-functions-used-in-these-notes.html"><i class="fa fa-check"></i>Special Functions used in these notes</a></li>
<li class="chapter" data-level="1" data-path="building-table-1.html"><a href="building-table-1.html"><i class="fa fa-check"></i><b>1</b> Building Table 1</a><ul>
<li class="chapter" data-level="1.1" data-path="building-table-1.html"><a href="building-table-1.html#two-examples-from-the-new-england-journal-of-medicine"><i class="fa fa-check"></i><b>1.1</b> Two examples from the <em>New England Journal of Medicine</em></a><ul>
<li class="chapter" data-level="1.1.1" data-path="building-table-1.html"><a href="building-table-1.html#a-simple-table-1"><i class="fa fa-check"></i><b>1.1.1</b> A simple Table 1</a></li>
<li class="chapter" data-level="1.1.2" data-path="building-table-1.html"><a href="building-table-1.html#a-group-comparison"><i class="fa fa-check"></i><b>1.1.2</b> A group comparison</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="building-table-1.html"><a href="building-table-1.html#the-mr-clean-trial"><i class="fa fa-check"></i><b>1.2</b> The MR CLEAN trial</a></li>
<li class="chapter" data-level="1.3" data-path="building-table-1.html"><a href="building-table-1.html#simulated-fakestroke-data"><i class="fa fa-check"></i><b>1.3</b> Simulated <code>fakestroke</code> data</a></li>
<li class="chapter" data-level="1.4" data-path="building-table-1.html"><a href="building-table-1.html#building-table-1-for-fakestroke-attempt-1"><i class="fa fa-check"></i><b>1.4</b> Building Table 1 for <code>fakestroke</code>: Attempt 1</a><ul>
<li class="chapter" data-level="1.4.1" data-path="building-table-1.html"><a href="building-table-1.html#some-of-this-is-very-useful-and-other-parts-need-to-be-fixed."><i class="fa fa-check"></i><b>1.4.1</b> Some of this is very useful, and other parts need to be fixed.</a></li>
<li class="chapter" data-level="1.4.2" data-path="building-table-1.html"><a href="building-table-1.html#fakestroke-cleaning-up-categorical-variables"><i class="fa fa-check"></i><b>1.4.2</b> <code>fakestroke</code> Cleaning Up Categorical Variables</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="building-table-1.html"><a href="building-table-1.html#fakestroke-table-1-attempt-2"><i class="fa fa-check"></i><b>1.5</b> <code>fakestroke</code> Table 1: Attempt 2</a><ul>
<li class="chapter" data-level="1.5.1" data-path="building-table-1.html"><a href="building-table-1.html#what-summaries-should-we-show"><i class="fa fa-check"></i><b>1.5.1</b> What summaries should we show?</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="building-table-1.html"><a href="building-table-1.html#obtaining-a-more-detailed-summary"><i class="fa fa-check"></i><b>1.6</b> Obtaining a more detailed Summary</a></li>
<li class="chapter" data-level="1.7" data-path="building-table-1.html"><a href="building-table-1.html#exporting-the-completed-table-1-from-r-to-excel-or-word"><i class="fa fa-check"></i><b>1.7</b> Exporting the Completed Table 1 from R to Excel or Word</a><ul>
<li class="chapter" data-level="1.7.1" data-path="building-table-1.html"><a href="building-table-1.html#approach-a-save-and-open-in-excel"><i class="fa fa-check"></i><b>1.7.1</b> Approach A: Save and open in Excel</a></li>
<li class="chapter" data-level="1.7.2" data-path="building-table-1.html"><a href="building-table-1.html#approach-b-produce-the-table-so-you-can-cut-and-paste-it"><i class="fa fa-check"></i><b>1.7.2</b> Approach B: Produce the Table so you can cut and paste it</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="building-table-1.html"><a href="building-table-1.html#a-controlled-biological-experiment---the-blood-brain-barrier"><i class="fa fa-check"></i><b>1.8</b> A Controlled Biological Experiment - The Blood-Brain Barrier</a></li>
<li class="chapter" data-level="1.9" data-path="building-table-1.html"><a href="building-table-1.html#the-bloodbrain.csv-file"><i class="fa fa-check"></i><b>1.9</b> The <code>bloodbrain.csv</code> file</a></li>
<li class="chapter" data-level="1.10" data-path="building-table-1.html"><a href="building-table-1.html#a-table-1-for-bloodbrain"><i class="fa fa-check"></i><b>1.10</b> A Table 1 for <code>bloodbrain</code></a><ul>
<li class="chapter" data-level="1.10.1" data-path="building-table-1.html"><a href="building-table-1.html#generate-final-table-1-for-bloodbrain"><i class="fa fa-check"></i><b>1.10.1</b> Generate final Table 1 for <code>bloodbrain</code></a></li>
<li class="chapter" data-level="1.10.2" data-path="building-table-1.html"><a href="building-table-1.html#a-more-finished-version-after-cleanup-in-word"><i class="fa fa-check"></i><b>1.10.2</b> A More Finished Version (after Cleanup in Word)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html"><i class="fa fa-check"></i><b>2</b> Linear Regression on a small SMART data set</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#brfss-and-smart"><i class="fa fa-check"></i><b>2.1</b> BRFSS and SMART</a><ul>
<li class="chapter" data-level="2.1.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#key-resources"><i class="fa fa-check"></i><b>2.1.1</b> Key resources</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-smartcle1-data-cookbook"><i class="fa fa-check"></i><b>2.2</b> The <code>smartcle1</code> data: Cookbook</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#smartcle2-omitting-missing-observations-complete-case-analyses"><i class="fa fa-check"></i><b>2.3</b> <code>smartcle2</code>: Omitting Missing Observations: Complete-Case Analyses</a></li>
<li class="chapter" data-level="2.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#summarizing-the-smartcle2-data-numerically"><i class="fa fa-check"></i><b>2.4</b> Summarizing the <code>smartcle2</code> data numerically</a><ul>
<li class="chapter" data-level="2.4.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-new-toy-the-skim-function"><i class="fa fa-check"></i><b>2.4.1</b> The New Toy: The <code>skim</code> function</a></li>
<li class="chapter" data-level="2.4.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-usual-summary-for-a-data-frame"><i class="fa fa-check"></i><b>2.4.2</b> The usual <code>summary</code> for a data frame</a></li>
<li class="chapter" data-level="2.4.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-describe-function-in-hmisc"><i class="fa fa-check"></i><b>2.4.3</b> The <code>describe</code> function in <code>Hmisc</code></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#counting-as-exploratory-data-analysis"><i class="fa fa-check"></i><b>2.5</b> Counting as exploratory data analysis</a><ul>
<li class="chapter" data-level="2.5.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-respondents-had-exercised-in-the-past-30-days-did-this-vary-by-sex"><i class="fa fa-check"></i><b>2.5.1</b> How many respondents had exercised in the past 30 days? Did this vary by sex?</a></li>
<li class="chapter" data-level="2.5.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#whats-the-distribution-of-sleephrs"><i class="fa fa-check"></i><b>2.5.2</b> What’s the distribution of <code>sleephrs</code>?</a></li>
<li class="chapter" data-level="2.5.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#whats-the-distribution-of-bmi"><i class="fa fa-check"></i><b>2.5.3</b> What’s the distribution of <code>BMI</code>?</a></li>
<li class="chapter" data-level="2.5.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-of-the-respondents-have-a-bmi-below-30"><i class="fa fa-check"></i><b>2.5.4</b> How many of the respondents have a BMI below 30?</a></li>
<li class="chapter" data-level="2.5.5" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-of-the-respondents-who-have-a-bmi-30-exercised"><i class="fa fa-check"></i><b>2.5.5</b> How many of the respondents who have a BMI &lt; 30 exercised?</a></li>
<li class="chapter" data-level="2.5.6" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#is-obesity-associated-with-sex-in-these-data"><i class="fa fa-check"></i><b>2.5.6</b> Is obesity associated with sex, in these data?</a></li>
<li class="chapter" data-level="2.5.7" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#comparing-sleephrs-summaries-by-obesity-status"><i class="fa fa-check"></i><b>2.5.7</b> Comparing <code>sleephrs</code> summaries by obesity status</a></li>
<li class="chapter" data-level="2.5.8" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-skim-function-within-a-pipe"><i class="fa fa-check"></i><b>2.5.8</b> The <code>skim</code> function within a pipe</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#first-modeling-attempt-can-bmi-predict-physhealth"><i class="fa fa-check"></i><b>2.6</b> First Modeling Attempt: Can <code>bmi</code> predict <code>physhealth</code>?</a><ul>
<li class="chapter" data-level="2.6.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-a-simple-regression-model"><i class="fa fa-check"></i><b>2.6.1</b> Fitting a Simple Regression Model</a></li>
<li class="chapter" data-level="2.6.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#model-summary-for-a-simple-one-predictor-regression"><i class="fa fa-check"></i><b>2.6.2</b> Model Summary for a Simple (One-Predictor) Regression</a></li>
<li class="chapter" data-level="2.6.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#using-the-broom-package"><i class="fa fa-check"></i><b>2.6.3</b> Using the <code>broom</code> package</a></li>
<li class="chapter" data-level="2.6.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-does-the-model-do-residuals-vs.fitted-values"><i class="fa fa-check"></i><b>2.6.4</b> How does the model do? (Residuals vs. Fitted Values)</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#a-new-small-study-predicting-bmi"><i class="fa fa-check"></i><b>2.7</b> A New Small Study: Predicting BMI</a><ul>
<li class="chapter" data-level="2.7.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#does-female-predict-bmi-well"><i class="fa fa-check"></i><b>2.7.1</b> Does <code>female</code> predict <code>bmi</code> well?</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m1-a-simple-t-test-model"><i class="fa fa-check"></i><b>2.8</b> <code>c2_m1</code>: A simple t-test model</a></li>
<li class="chapter" data-level="2.9" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m2-adding-another-predictor-two-way-anova-without-interaction"><i class="fa fa-check"></i><b>2.9</b> <code>c2_m2</code>: Adding another predictor (two-way ANOVA without interaction)</a></li>
<li class="chapter" data-level="2.10" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m3-adding-the-interaction-term-two-way-anova-with-interaction"><i class="fa fa-check"></i><b>2.10</b> <code>c2_m3</code>: Adding the interaction term (Two-way ANOVA with interaction)</a></li>
<li class="chapter" data-level="2.11" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m4-using-female-and-sleephrs-in-a-model-for-bmi"><i class="fa fa-check"></i><b>2.11</b> <code>c2_m4</code>: Using <code>female</code> and <code>sleephrs</code> in a model for <code>bmi</code></a></li>
<li class="chapter" data-level="2.12" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#making-predictions-with-a-linear-regression-model"><i class="fa fa-check"></i><b>2.12</b> Making Predictions with a Linear Regression Model</a><ul>
<li class="chapter" data-level="2.12.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-an-individual-prediction-and-95-prediction-interval"><i class="fa fa-check"></i><b>2.12.1</b> Fitting an Individual Prediction and 95% Prediction Interval</a></li>
<li class="chapter" data-level="2.12.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#confidence-interval-for-an-average-prediction"><i class="fa fa-check"></i><b>2.12.2</b> Confidence Interval for an Average Prediction</a></li>
<li class="chapter" data-level="2.12.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-multiple-individual-predictions-to-new-data"><i class="fa fa-check"></i><b>2.12.3</b> Fitting Multiple Individual Predictions to New Data</a></li>
<li class="chapter" data-level="2.12.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#simulation-to-represent-predictive-uncertainty-in-model-4"><i class="fa fa-check"></i><b>2.12.4</b> Simulation to represent predictive uncertainty in Model 4</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#centering-the-model"><i class="fa fa-check"></i><b>2.13</b> Centering the model</a><ul>
<li class="chapter" data-level="2.13.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#plot-of-model-4-on-centered-sleephrs-c2_m4_c"><i class="fa fa-check"></i><b>2.13.1</b> Plot of Model 4 on Centered <code>sleephrs</code>: <code>c2_m4_c</code></a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#rescaling-an-input-by-subtracting-the-mean-and-dividing-by-2-standard-deviations"><i class="fa fa-check"></i><b>2.14</b> Rescaling an input by subtracting the mean and dividing by 2 standard deviations</a><ul>
<li class="chapter" data-level="2.14.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#refitting-model-c2_m4-to-the-rescaled-data"><i class="fa fa-check"></i><b>2.14.1</b> Refitting model <code>c2_m4</code> to the rescaled data</a></li>
<li class="chapter" data-level="2.14.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#interpreting-the-model-on-rescaled-data"><i class="fa fa-check"></i><b>2.14.2</b> Interpreting the model on rescaled data</a></li>
<li class="chapter" data-level="2.14.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#plot-of-model-on-rescaled-data"><i class="fa fa-check"></i><b>2.14.3</b> Plot of model on rescaled data</a></li>
</ul></li>
<li class="chapter" data-level="2.15" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m5-what-if-we-add-more-variables"><i class="fa fa-check"></i><b>2.15</b> <code>c2_m5</code>: What if we add more variables?</a></li>
<li class="chapter" data-level="2.16" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m6-would-adding-self-reported-health-help"><i class="fa fa-check"></i><b>2.16</b> <code>c2_m6</code>: Would adding self-reported health help?</a></li>
<li class="chapter" data-level="2.17" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m7-what-if-we-added-the-menthealth-variable"><i class="fa fa-check"></i><b>2.17</b> <code>c2_m7</code>: What if we added the <code>menthealth</code> variable?</a></li>
<li class="chapter" data-level="2.18" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#key-regression-assumptions-for-building-effective-prediction-models"><i class="fa fa-check"></i><b>2.18</b> Key Regression Assumptions for Building Effective Prediction Models</a><ul>
<li class="chapter" data-level="2.18.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#checking-assumptions-in-model-c2_m7"><i class="fa fa-check"></i><b>2.18.1</b> Checking Assumptions in model <code>c2_m7</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>3</b> Analysis of Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-bonding-data-a-designed-dental-experiment"><i class="fa fa-check"></i><b>3.1</b> The <code>bonding</code> data: A Designed Dental Experiment</a></li>
<li class="chapter" data-level="3.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-one-factor-analysis-of-variance"><i class="fa fa-check"></i><b>3.2</b> A One-Factor Analysis of Variance</a><ul>
<li class="chapter" data-level="3.2.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#look-at-the-data"><i class="fa fa-check"></i><b>3.2.1</b> Look at the Data!</a></li>
<li class="chapter" data-level="3.2.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#table-of-summary-statistics"><i class="fa fa-check"></i><b>3.2.2</b> Table of Summary Statistics</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-two-way-anova-looking-at-two-factors"><i class="fa fa-check"></i><b>3.3</b> A Two-Way ANOVA: Looking at Two Factors</a></li>
<li class="chapter" data-level="3.4" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-means-plot-with-standard-deviations-to-check-for-interaction"><i class="fa fa-check"></i><b>3.4</b> A Means Plot (with standard deviations) to check for interaction</a><ul>
<li class="chapter" data-level="3.4.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#skimming-the-data-after-grouping-by-resin-and-light"><i class="fa fa-check"></i><b>3.4.1</b> Skimming the data after grouping by <code>resin</code> and <code>light</code></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#fitting-the-two-way-anova-model-with-interaction"><i class="fa fa-check"></i><b>3.5</b> Fitting the Two-Way ANOVA model with Interaction</a><ul>
<li class="chapter" data-level="3.5.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-anova-table-for-our-model"><i class="fa fa-check"></i><b>3.5.1</b> The ANOVA table for our model</a></li>
<li class="chapter" data-level="3.5.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#is-the-interaction-important"><i class="fa fa-check"></i><b>3.5.2</b> Is the interaction important?</a></li>
<li class="chapter" data-level="3.5.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#interpreting-the-interaction"><i class="fa fa-check"></i><b>3.5.3</b> Interpreting the Interaction</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#comparing-individual-combinations-of-resin-and-light"><i class="fa fa-check"></i><b>3.6</b> Comparing Individual Combinations of <code>resin</code> and <code>light</code></a></li>
<li class="chapter" data-level="3.7" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-bonding-model-without-interaction"><i class="fa fa-check"></i><b>3.7</b> The <code>bonding</code> model without Interaction</a></li>
<li class="chapter" data-level="3.8" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#cortisol-a-hypothetical-clinical-trial"><i class="fa fa-check"></i><b>3.8</b> <code>cortisol</code>: A Hypothetical Clinical Trial</a><ul>
<li class="chapter" data-level="3.8.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#codebook-and-raw-data-for-cortisol"><i class="fa fa-check"></i><b>3.8.1</b> Codebook and Raw Data for <code>cortisol</code></a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#creating-a-factor-combining-sex-and-waist"><i class="fa fa-check"></i><b>3.9</b> Creating a factor combining sex and waist</a></li>
<li class="chapter" data-level="3.10" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-means-plot-for-the-cortisol-trial-with-standard-errors"><i class="fa fa-check"></i><b>3.10</b> A Means Plot for the <code>cortisol</code> trial (with standard errors)</a></li>
<li class="chapter" data-level="3.11" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-two-way-anova-model-for-cortisol-with-interaction"><i class="fa fa-check"></i><b>3.11</b> A Two-Way ANOVA model for <code>cortisol</code> with Interaction</a></li>
<li class="chapter" data-level="3.12" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-two-way-anova-model-for-cortisol-without-interaction"><i class="fa fa-check"></i><b>3.12</b> A Two-Way ANOVA model for <code>cortisol</code> without Interaction</a><ul>
<li class="chapter" data-level="3.12.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-graph"><i class="fa fa-check"></i><b>3.12.1</b> The Graph</a></li>
<li class="chapter" data-level="3.12.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-anova-model"><i class="fa fa-check"></i><b>3.12.2</b> The ANOVA Model</a></li>
<li class="chapter" data-level="3.12.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-regression-summary"><i class="fa fa-check"></i><b>3.12.3</b> The Regression Summary</a></li>
<li class="chapter" data-level="3.12.4" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#tukey-hsd-comparisons"><i class="fa fa-check"></i><b>3.12.4</b> Tukey HSD Comparisons</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html"><i class="fa fa-check"></i><b>4</b> Analysis of Covariance</a><ul>
<li class="chapter" data-level="4.1" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#an-emphysema-study"><i class="fa fa-check"></i><b>4.1</b> An Emphysema Study</a><ul>
<li class="chapter" data-level="4.1.1" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#codebook"><i class="fa fa-check"></i><b>4.1.1</b> Codebook</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#does-sex-affect-the-mean-change-in-theophylline"><i class="fa fa-check"></i><b>4.2</b> Does <code>sex</code> affect the mean change in theophylline?</a></li>
<li class="chapter" data-level="4.3" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#is-there-an-association-between-age-and-sex-in-this-study"><i class="fa fa-check"></i><b>4.3</b> Is there an association between <code>age</code> and <code>sex</code> in this study?</a></li>
<li class="chapter" data-level="4.4" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#adding-a-quantitative-covariate-age-to-the-model"><i class="fa fa-check"></i><b>4.4</b> Adding a quantitative covariate, <code>age</code>, to the model</a><ul>
<li class="chapter" data-level="4.4.1" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#the-ancova-model"><i class="fa fa-check"></i><b>4.4.1</b> The ANCOVA model</a></li>
<li class="chapter" data-level="4.4.2" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#the-ancova-table"><i class="fa fa-check"></i><b>4.4.2</b> The ANCOVA Table</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#rerunning-the-ancova-model-after-simple-imputation"><i class="fa fa-check"></i><b>4.5</b> Rerunning the ANCOVA model after simple imputation</a></li>
<li class="chapter" data-level="4.6" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#looking-at-a-factor-covariate-interaction"><i class="fa fa-check"></i><b>4.6</b> Looking at a factor-covariate interaction</a></li>
<li class="chapter" data-level="4.7" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#centering-the-covariate-to-facilitate-ancova-interpretation"><i class="fa fa-check"></i><b>4.7</b> Centering the Covariate to Facilitate ANCOVA Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html"><i class="fa fa-check"></i><b>5</b> Missing Data Mechanisms and Single Imputation</a><ul>
<li class="chapter" data-level="5.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#a-toy-example"><i class="fa fa-check"></i><b>5.1</b> A Toy Example</a><ul>
<li class="chapter" data-level="5.1.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#how-many-missing-values-do-we-have-in-each-column"><i class="fa fa-check"></i><b>5.1.1</b> How many missing values do we have in each column?</a></li>
<li class="chapter" data-level="5.1.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#what-is-the-pattern-of-missing-data"><i class="fa fa-check"></i><b>5.1.2</b> What is the pattern of missing data?</a></li>
<li class="chapter" data-level="5.1.3" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#how-can-we-identify-the-subjects-with-missing-data"><i class="fa fa-check"></i><b>5.1.3</b> How can we identify the subjects with missing data?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#missing-data-mechanisms"><i class="fa fa-check"></i><b>5.2</b> Missing-data mechanisms</a></li>
<li class="chapter" data-level="5.3" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#options-for-dealing-with-missingness"><i class="fa fa-check"></i><b>5.3</b> Options for Dealing with Missingness</a></li>
<li class="chapter" data-level="5.4" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#complete-case-and-available-case-analyses"><i class="fa fa-check"></i><b>5.4</b> Complete Case (and Available Case) analyses</a></li>
<li class="chapter" data-level="5.5" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#single-imputation"><i class="fa fa-check"></i><b>5.5</b> Single Imputation</a></li>
<li class="chapter" data-level="5.6" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#multiple-imputation"><i class="fa fa-check"></i><b>5.6</b> Multiple Imputation</a></li>
<li class="chapter" data-level="5.7" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#building-a-complete-case-analysis"><i class="fa fa-check"></i><b>5.7</b> Building a Complete Case Analysis</a></li>
<li class="chapter" data-level="5.8" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#single-imputation-with-the-mean-or-mode"><i class="fa fa-check"></i><b>5.8</b> Single Imputation with the Mean or Mode</a></li>
<li class="chapter" data-level="5.9" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#doing-single-imputation-with-simputation"><i class="fa fa-check"></i><b>5.9</b> Doing Single Imputation with <code>simputation</code></a><ul>
<li class="chapter" data-level="5.9.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#mirroring-our-prior-approach-imputing-meansmediansmodes"><i class="fa fa-check"></i><b>5.9.1</b> Mirroring Our Prior Approach (imputing means/medians/modes)</a></li>
<li class="chapter" data-level="5.9.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#using-a-model-to-impute-sbp.before-and-diabetes"><i class="fa fa-check"></i><b>5.9.2</b> Using a model to impute <code>sbp.before</code> and <code>diabetes</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html"><i class="fa fa-check"></i><b>6</b> A Study of Prostate Cancer</a><ul>
<li class="chapter" data-level="6.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#data-load-and-background"><i class="fa fa-check"></i><b>6.1</b> Data Load and Background</a></li>
<li class="chapter" data-level="6.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#code-book"><i class="fa fa-check"></i><b>6.2</b> Code Book</a></li>
<li class="chapter" data-level="6.3" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#additions-for-later-use"><i class="fa fa-check"></i><b>6.3</b> Additions for Later Use</a></li>
<li class="chapter" data-level="6.4" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#fitting-and-evaluating-a-two-predictor-model"><i class="fa fa-check"></i><b>6.4</b> Fitting and Evaluating a Two-Predictor Model</a><ul>
<li class="chapter" data-level="6.4.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#using-tidy"><i class="fa fa-check"></i><b>6.4.1</b> Using <code>tidy</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#interpretation"><i class="fa fa-check"></i><b>6.4.2</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#exploring-model-c5_prost_a"><i class="fa fa-check"></i><b>6.5</b> Exploring Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="6.5.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#summary-for-model-c5_prost_a"><i class="fa fa-check"></i><b>6.5.1</b> <code>summary</code> for Model <code>c5_prost_A</code></a></li>
<li class="chapter" data-level="6.5.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#adjusted-r2"><i class="fa fa-check"></i><b>6.5.2</b> Adjusted R<sup>2</sup></a></li>
<li class="chapter" data-level="6.5.3" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#coefficient-confidence-intervals"><i class="fa fa-check"></i><b>6.5.3</b> Coefficient Confidence Intervals</a></li>
<li class="chapter" data-level="6.5.4" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#anova-for-model-c5_prost_a"><i class="fa fa-check"></i><b>6.5.4</b> ANOVA for Model <code>c5_prost_A</code></a></li>
<li class="chapter" data-level="6.5.5" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#residuals-fitted-values-and-standard-errors-with-augment"><i class="fa fa-check"></i><b>6.5.5</b> Residuals, Fitted Values and Standard Errors with <code>augment</code></a></li>
<li class="chapter" data-level="6.5.6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#making-predictions-with-c5_prost_a"><i class="fa fa-check"></i><b>6.5.6</b> Making Predictions with <code>c5_prost_A</code></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#plotting-model-c5_prost_a"><i class="fa fa-check"></i><b>6.6</b> Plotting Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="6.6.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#residual-plots-of-c5_prost_a"><i class="fa fa-check"></i><b>6.6.1</b> Residual Plots of <code>c5_prost_A</code></a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#cross-validation-of-model-c5_prost_a"><i class="fa fa-check"></i><b>6.7</b> Cross-Validation of Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="6.7.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#cross-validated-summaries-of-prediction-quality"><i class="fa fa-check"></i><b>6.7.1</b> Cross-Validated Summaries of Prediction Quality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html"><i class="fa fa-check"></i><b>7</b> Stepwise Variable Selection</a><ul>
<li class="chapter" data-level="7.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#strategy-for-model-selection"><i class="fa fa-check"></i><b>7.1</b> Strategy for Model Selection</a><ul>
<li class="chapter" data-level="7.1.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#how-do-we-choose-potential-subsets-of-predictors"><i class="fa fa-check"></i><b>7.1.1</b> How Do We Choose Potential Subsets of Predictors?</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#a-kitchen-sink-model-model-c5_prost_ks"><i class="fa fa-check"></i><b>7.2</b> A “Kitchen Sink” Model (Model <code>c5_prost_ks</code>)</a></li>
<li class="chapter" data-level="7.3" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#sequential-variable-selection-stepwise-approaches"><i class="fa fa-check"></i><b>7.3</b> Sequential Variable Selection: Stepwise Approaches</a><ul>
<li class="chapter" data-level="7.3.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#the-big-problems-with-stepwise-regression"><i class="fa fa-check"></i><b>7.3.1</b> The Big Problems with Stepwise Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#forward-selection-with-the-step-function"><i class="fa fa-check"></i><b>7.4</b> Forward Selection with the <code>step</code> function</a></li>
<li class="chapter" data-level="7.5" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#backward-elimination-using-the-step-function"><i class="fa fa-check"></i><b>7.5</b> Backward Elimination using the <code>step</code> function</a></li>
<li class="chapter" data-level="7.6" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#allen-cady-modified-backward-elimination"><i class="fa fa-check"></i><b>7.6</b> Allen-Cady Modified Backward Elimination</a><ul>
<li class="chapter" data-level="7.6.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#demonstration-of-the-allen-cady-approach"><i class="fa fa-check"></i><b>7.6.1</b> Demonstration of the Allen-Cady approach</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#summarizing-the-results"><i class="fa fa-check"></i><b>7.7</b> Summarizing the Results</a><ul>
<li class="chapter" data-level="7.7.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#in-sample-testing-and-summaries"><i class="fa fa-check"></i><b>7.7.1</b> In-Sample Testing and Summaries</a></li>
<li class="chapter" data-level="7.7.2" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#validating-the-results-of-the-various-models"><i class="fa fa-check"></i><b>7.7.2</b> Validating the Results of the Various Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><i class="fa fa-check"></i><b>8</b> “Best Subsets” Variable Selection in our Prostate Cancer Study</a><ul>
<li class="chapter" data-level="8.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#four-key-summaries-well-use-to-evaluate-potential-models"><i class="fa fa-check"></i><b>8.1</b> Four Key Summaries We’ll Use to Evaluate Potential Models</a></li>
<li class="chapter" data-level="8.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#using-regsubsets-in-the-leaps-package"><i class="fa fa-check"></i><b>8.2</b> Using <code>regsubsets</code> in the <code>leaps</code> package</a><ul>
<li class="chapter" data-level="8.2.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#summaries-of-winning-models"><i class="fa fa-check"></i><b>8.2.1</b> Summaries of “Winning” Models</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#plotting-the-best-subsets-results"><i class="fa fa-check"></i><b>8.3</b> Plotting the Best Subsets Results</a><ul>
<li class="chapter" data-level="8.3.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-adjusted-r2-plot"><i class="fa fa-check"></i><b>8.3.1</b> The Adjusted R<sup>2</sup> Plot</a></li>
<li class="chapter" data-level="8.3.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#a-fancier-version-identifying-the-largest-adjusted-r2"><i class="fa fa-check"></i><b>8.3.2</b> A Fancier Version (identifying the largest adjusted R<sup>2</sup>)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#mallows-c_p"><i class="fa fa-check"></i><b>8.4</b> Mallows’ <span class="math inline">\(C_p\)</span></a><ul>
<li class="chapter" data-level="8.4.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-c_p-plot"><i class="fa fa-check"></i><b>8.4.1</b> The <span class="math inline">\(C_p\)</span> Plot</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#all-subsets-regression-and-information-criteria"><i class="fa fa-check"></i><b>8.5</b> “All Subsets” Regression and Information Criteria</a><ul>
<li class="chapter" data-level="8.5.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-bic-plot"><i class="fa fa-check"></i><b>8.5.1</b> The BIC Plot</a></li>
<li class="chapter" data-level="8.5.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#aic-with-all-subsets"><i class="fa fa-check"></i><b>8.5.2</b> AIC with “All Subsets”</a></li>
<li class="chapter" data-level="8.5.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-bias-corrected-aic-hurwitz-tsai"><i class="fa fa-check"></i><b>8.5.3</b> The Bias-Corrected AIC (Hurwitz &amp; Tsai)</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#all-four-plots-together"><i class="fa fa-check"></i><b>8.6</b> All Four Plots, Together</a></li>
<li class="chapter" data-level="8.7" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#table-of-key-results"><i class="fa fa-check"></i><b>8.7</b> Table of Key Results</a></li>
<li class="chapter" data-level="8.8" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#models-worth-considering"><i class="fa fa-check"></i><b>8.8</b> Models Worth Considering?</a></li>
<li class="chapter" data-level="8.9" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#anova-testing-to-compare-these-three-models"><i class="fa fa-check"></i><b>8.9</b> ANOVA Testing to compare these three models?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science for Biological, Medical and Health Research: Notes for 432</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="best-subsets-variable-selection-in-our-prostate-cancer-study" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> “Best Subsets” Variable Selection in our Prostate Cancer Study</h1>
<p>A second approach to model selection involved fitting all possible subset models and identifying the ones that look best according to some meaningful criterion and ideally one that includes enough variables to model the response appropriately without including lots of redundant or unnecessary terms.</p>
<div id="four-key-summaries-well-use-to-evaluate-potential-models" class="section level2">
<h2><span class="header-section-number">8.1</span> Four Key Summaries We’ll Use to Evaluate Potential Models</h2>
<ol style="list-style-type: decimal">
<li>Adjusted R<sup>2</sup>, which we try to maximize.</li>
<li>Akaike’s Information Criterion (AIC), which we try to minimize, and a Bias-Corrected version of AIC due to Hurwitz and Tsai, which we use when the sample size is small, specifically when the sample size <span class="math inline">\(n\)</span> and the number of predictors being studied <span class="math inline">\(k\)</span> are such that <span class="math inline">\(n/k \leq 40\)</span>. We also try to minimize this bias-corrected AIC.</li>
<li>Bayesian Information Criterion (BIC), which we also try to minimize.</li>
<li>Mallows’ C<sub>p</sub> statistic, which we (essentially) try to minimize.</li>
</ol>
<p>Choosing between AIC and BIC can be challenging.</p>
<blockquote>
<p>For model selection purposes, there is no clear choice between AIC and BIC. Given a family of models, including the true model, the probability that BIC will select the correct model approaches one as the sample size n approaches infinity - thus BIC is asymptotically consistent, which AIC is not. [But, for practical purposes,] BIC often chooses models that are too simple [relative to AIC] because of its heavy penalty on complexity.</p>
</blockquote>
<ul>
<li>Source: <span class="citation">Hastie, Tibshriani, and Frideman (<a href="#ref-Hastie2001">2001</a>)</span>, page 208.</li>
</ul>
<p>Several useful tools for running “all subsets” or “best subsets” regression comparisons are developed in R’s <code>leaps</code> package.</p>
</div>
<div id="using-regsubsets-in-the-leaps-package" class="section level2">
<h2><span class="header-section-number">8.2</span> Using <code>regsubsets</code> in the <code>leaps</code> package</h2>
<p>We can use the <code>leaps</code> package to obtain results in the <code>prost</code> study from looking at all possible subsets of the candidate predictors.</p>
<p>The <code>leaps</code> package isn’t particularly friendly to the tidyverse, and will require us first to identify a set of candidate predictors using <code>with</code> and <code>cbind</code>, then apply those to a <code>regsubsets</code> function, which identifies the set of models.</p>
<p>To start, we’ll ask R to find the one best subset (with 1 predictor variable [in addition to the intercept], then with 2 predictors, and then with each of 3, 4, … 8 predictor variables) according to an exhaustive search without forcing any of the variables to be in or out. We’d use the <code>nvmax</code> command within the <code>regsubsets</code> function to limit the number of regression inputs to a maximum.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">preds &lt;-<span class="st"> </span><span class="kw">with</span>(prost, 
   <span class="kw">cbind</span>(lcavol, lweight, age, bph_f, svi_f, lcp, gleason_f, pgg45))

x1 &lt;-<span class="st"> </span><span class="kw">regsubsets</span>(preds, <span class="dt">y=</span>prost<span class="op">$</span>lpsa)
rs &lt;-<span class="st"> </span><span class="kw">summary</span>(x1)
rs</code></pre></div>
<pre><code>Subset selection object
8 Variables  (and intercept)
          Forced in Forced out
lcavol        FALSE      FALSE
lweight       FALSE      FALSE
age           FALSE      FALSE
bph_f         FALSE      FALSE
svi_f         FALSE      FALSE
lcp           FALSE      FALSE
gleason_f     FALSE      FALSE
pgg45         FALSE      FALSE
1 subsets of each size up to 8
Selection Algorithm: exhaustive
         lcavol lweight age bph_f svi_f lcp gleason_f pgg45
1  ( 1 ) &quot;*&quot;    &quot; &quot;     &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
2  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot; &quot; &quot; &quot;   &quot; &quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
3  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot; &quot; &quot; &quot;   &quot;*&quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
4  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot; &quot; &quot;*&quot;   &quot;*&quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
5  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot; &quot; &quot; &quot;       &quot; &quot;  
6  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot; &quot; &quot;*&quot;       &quot; &quot;  
7  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot; &quot;*&quot;       &quot; &quot;  
8  ( 1 ) &quot;*&quot;    &quot;*&quot;     &quot;*&quot; &quot;*&quot;   &quot;*&quot;   &quot;*&quot; &quot;*&quot;       &quot;*&quot;  </code></pre>
<p>So…</p>
<ul>
<li>the best one-predictor model used <code>lcavol</code></li>
<li>the best two-predictor model used <code>lcavol</code> and <code>lweight</code></li>
<li>the best three-predictor model used <code>lcavol</code>, <code>lweight</code> and <code>svi_f</code></li>
<li>the best four-predictor model added <code>bph_f</code>, and</li>
<li>the best five-predictor model added <code>age</code></li>
<li>the best six-input model added <code>gleason_f</code>,</li>
<li>the best seven-input model added <code>lcp</code>,</li>
<li>and the eight-input model adds <code>pgg45</code>.</li>
</ul>
<div id="summaries-of-winning-models" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Summaries of “Winning” Models</h3>
<p>We can easily pull out R<sup>2</sup>, adjusted R<sup>2</sup>, C<sub>p</sub>, and BIC results for the “winning” models of each size.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">winners &lt;-<span class="st"> </span><span class="kw">tbl_df</span>(rs<span class="op">$</span>which)
winners<span class="op">$</span>k &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">:</span><span class="dv">9</span>
winners<span class="op">$</span>r2 &lt;-<span class="st"> </span>rs<span class="op">$</span>rsq
winners<span class="op">$</span>adjr2 &lt;-<span class="st"> </span>rs<span class="op">$</span>adjr2
winners<span class="op">$</span>cp &lt;-<span class="st"> </span>rs<span class="op">$</span>cp
winners<span class="op">$</span>bic &lt;-<span class="st"> </span>rs<span class="op">$</span>bic</code></pre></div>
<p>And here is a table of those results…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">winners</code></pre></div>
<pre><code># A tibble: 8 x 14
  `(Intercept)` lcavol lweight age   bph_f svi_f lcp   gleason_f pgg45
  &lt;lgl&gt;         &lt;lgl&gt;  &lt;lgl&gt;   &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;     &lt;lgl&gt;
1 T             T      F       F     F     F     F     F         F    
2 T             T      T       F     F     F     F     F         F    
3 T             T      T       F     F     T     F     F         F    
4 T             T      T       F     T     T     F     F         F    
5 T             T      T       T     T     T     F     F         F    
6 T             T      T       T     T     T     F     T         F    
7 T             T      T       T     T     T     T     T         F    
8 T             T      T       T     T     T     T     T         T    
# ... with 5 more variables: k &lt;int&gt;, r2 &lt;dbl&gt;, adjr2 &lt;dbl&gt;, cp &lt;dbl&gt;, bic
#   &lt;dbl&gt;</code></pre>
<ul>
<li>All of these “best subsets” are hierarchical, in that each model is a subset of the one below it. This isn’t inevitably true.</li>
<li>By adjusted R<sup>2</sup>, which we want to maximize, the best model appears to be the model with <span class="math inline">\(k\)</span> = 8.</li>
<li>By <em>C<sub>p</sub></em>, which we want to minimize (within reason), the best choice appears to be the <span class="math inline">\(k\)</span> = 4, 6 or 7 model.</li>
<li>By BIC, the best model has <span class="math inline">\(k\)</span> = 4.</li>
</ul>
</div>
</div>
<div id="plotting-the-best-subsets-results" class="section level2">
<h2><span class="header-section-number">8.3</span> Plotting the Best Subsets Results</h2>
<div id="the-adjusted-r2-plot" class="section level3">
<h3><span class="header-section-number">8.3.1</span> The Adjusted R<sup>2</sup> Plot</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(rs<span class="op">$</span>adjr2 <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>), <span class="dt">ylab=</span><span class="st">&quot;Adjusted R-squared&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;# of Inputs, including intercept&quot;</span>)
<span class="kw">lines</span>(<span class="kw">spline</span>(rs<span class="op">$</span>adjr2 <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>)))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-71-1.png" width="672" /></p>
<p>Models 4-9 all look like reasonable choices here.</p>
</div>
<div id="a-fancier-version-identifying-the-largest-adjusted-r2" class="section level3">
<h3><span class="header-section-number">8.3.2</span> A Fancier Version (identifying the largest adjusted R<sup>2</sup>)</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2 &lt;-<span class="st"> </span><span class="kw">max</span>(rs<span class="op">$</span>adjr2) 
m1 &lt;-<span class="st"> </span><span class="kw">which.max</span>(rs<span class="op">$</span>adjr2) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
<span class="kw">plot</span>(rs<span class="op">$</span>adjr2 <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>), <span class="dt">ylab=</span><span class="st">&quot;Adjusted R-squared&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;# of Inputs, including intercept&quot;</span>)
<span class="kw">lines</span>(<span class="kw">spline</span>(rs<span class="op">$</span>adjr2 <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>)))
<span class="kw">arrows</span>(m1, m2<span class="op">-</span><span class="fl">0.02</span>, m1, m2)
<span class="kw">text</span>(m1, m2<span class="op">-</span><span class="fl">0.03</span>, <span class="kw">paste</span>(<span class="st">&quot;max =&quot;</span>, <span class="kw">format</span>(m2, <span class="dt">digits=</span><span class="dv">3</span>)))
<span class="kw">text</span>(m1, m2<span class="op">-</span><span class="fl">0.045</span>, <span class="kw">paste</span>(<span class="st">&quot;with&quot;</span>, <span class="kw">format</span>(m1, <span class="dt">digits=</span><span class="dv">1</span>),
                        <span class="st">&quot;inputs&quot;</span>), <span class="dt">pos=</span><span class="dv">3</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-72-1.png" width="672" /></p>
</div>
</div>
<div id="mallows-c_p" class="section level2">
<h2><span class="header-section-number">8.4</span> Mallows’ <span class="math inline">\(C_p\)</span></h2>
<p>The <span class="math inline">\(C_p\)</span> statistic focuses directly on the tradeoff between <strong>bias</strong> (due to excluding important predictors from the model) and extra <strong>variance</strong> (due to including too many unimportant predictors in the model.)</p>
<p>If N is the sample size, and we select <span class="math inline">\(p\)</span> regression predictors from a set of <span class="math inline">\(K\)</span> (where <span class="math inline">\(p &lt; K\)</span>), then the <span class="math inline">\(C_p\)</span> statistic is</p>
<p><span class="math inline">\(C_p = \frac{SSE_p}{MSE_K} - N + 2p\)</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(SSE_p\)</span> is the sum of squares for error (residual) in the model with <span class="math inline">\(p\)</span> predictors</li>
<li><span class="math inline">\(MSE_K\)</span> is the residual mean square after regression in the model with all <span class="math inline">\(K\)</span> predictors</li>
</ul>
<p>As it turns out, this is just measuring the particular model’s lack of fit, and then adding a penalty for the number of terms in the model (specifically <span class="math inline">\(2p - N\)</span> is the penalty since the lack of fit is measured as <span class="math inline">\((N-p) \frac{SSE_p}{MSE_K}\)</span>.</p>
<p>If a model has no meaningful lack of fit (i.e. no substantial bias) then the expected value of <span class="math inline">\(C_p\)</span> is roughly <span class="math inline">\(p\)</span>.</p>
<p>Otherwise, the expectation is <span class="math inline">\(p\)</span> plus a positive bias term.</p>
<p>In general, we want to see <em>smaller</em> values of <span class="math inline">\(C_p\)</span>.</p>
<p>Often, we do this by choosing a subset of predictors that have <span class="math inline">\(C_p\)</span> near the value of <span class="math inline">\(p\)</span>.</p>
<div id="the-c_p-plot" class="section level3">
<h3><span class="header-section-number">8.4.1</span> The <span class="math inline">\(C_p\)</span> Plot</h3>
<p>The <span class="math inline">\(C_p\)</span> plot is just a scatterplot of <span class="math inline">\(C_p\)</span> on the Y-axis, and <span class="math inline">\(p\)</span> on the X-axis.</p>
<p>Each of the various predictor subsets we will study is represented in a single point. A model without bias should have <span class="math inline">\(C_p\)</span> roughly equal to <span class="math inline">\(p\)</span>, so we’ll frequently draw a line at <span class="math inline">\(C_p = p\)</span> to make that clear. We then select our model from among all models with small <span class="math inline">\(C_p\)</span> statistics.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(rs<span class="op">$</span>cp <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>),
     <span class="dt">ylab=</span><span class="st">&quot;Cp Statistic&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;# of Regression Inputs, including Intercept&quot;</span>,
     <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">main=</span><span class="st">&quot;Cp Plot&quot;</span>)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;purple&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
<p>Model 4 has the smallest value of <span class="math inline">\(C_p\)</span> (and is the leftmost of the largely comparable models 4-9) while 6 is close to and 7 is right on the <span class="math inline">\(C_p = p\)</span> line, so those are the likeliest candidates.</p>
</div>
</div>
<div id="all-subsets-regression-and-information-criteria" class="section level2">
<h2><span class="header-section-number">8.5</span> “All Subsets” Regression and Information Criteria</h2>
<p>We will have three main information criteria:</p>
<ul>
<li>the Bayesian Information Criterion, called BIC</li>
<li>the Akaike Information Criterion (used by R’s default stepwise approaches,) called AIC</li>
<li>a corrected version of AIC due to Hurwitz and Tsai, called AIC<sub>c</sub></li>
</ul>
<p>Each of these indicates better models by getting smaller.</p>
<div id="the-bic-plot" class="section level3">
<h3><span class="header-section-number">8.5.1</span> The BIC Plot</h3>
<p>R provides the BIC directly as part of the result of running <code>regsubsets</code>, as we’ve seen.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(rs<span class="op">$</span>bic <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>), <span class="dt">ylab=</span><span class="st">&quot;BIC&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;# of Fitted Inputs&quot;</span>,
     <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">1.5</span>, <span class="dt">col=</span><span class="st">&quot;slateblue&quot;</span>, <span class="dt">main=</span><span class="st">&quot;BIC Plot&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
<p>We want to minimize BIC, which argues strongly for the model with 4 inputs, including the intercept.</p>
</div>
<div id="aic-with-all-subsets" class="section level3">
<h3><span class="header-section-number">8.5.2</span> AIC with “All Subsets”</h3>
<p>To get the AIC, we can use the formula</p>
<p><span class="math display">\[
AIC = n log(RSS/n) + 2p
\]</span></p>
<p>where <em>n</em> is the sample size, <em>p</em> = # of regression inputs to be fit in the model (including the intercept) and the RSS can be found in the <code>regsubsets</code> output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rs<span class="op">$</span>rss</code></pre></div>
<pre><code>[1] 58.91478 51.74218 46.56844 45.72444 44.64364 43.69047 43.04471 42.77150</code></pre>
<p>So, in our case, we have n = 97 subjects, and models being fit with 2 to 9 regression inputs (including the intercept), so we have:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rs<span class="op">$</span>aic &lt;-<span class="st"> </span><span class="dv">97</span><span class="op">*</span><span class="kw">log</span>(rs<span class="op">$</span>rss <span class="op">/</span><span class="st"> </span><span class="dv">97</span>) <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>)
rs<span class="op">$</span>aic</code></pre></div>
<pre><code>[1] -44.36603 -54.95846 -63.17744 -62.95157 -63.27191 -63.36534 -62.80974
[8] -61.42738</code></pre>
</div>
<div id="the-bias-corrected-aic-hurwitz-tsai" class="section level3">
<h3><span class="header-section-number">8.5.3</span> The Bias-Corrected AIC (Hurwitz &amp; Tsai)</h3>
<p>The bias-corrected AIC formula due to Hurwitz and Tsai is:</p>
<p><span class="math inline">\(AIC_c\)</span> = n log(RSS/n) + 2p + [2p (p+1) / (n-p-1)] = AIC + [2p (p+1) / (n-p-1)]</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rs<span class="op">$</span>aic.corr &lt;-<span class="st"> </span><span class="dv">97</span><span class="op">*</span><span class="kw">log</span>(rs<span class="op">$</span>rss <span class="op">/</span><span class="st"> </span><span class="dv">97</span>) <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">+</span>
<span class="st">               </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">*</span><span class="st"> </span>((<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>)<span class="op">+</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(<span class="dv">97</span> <span class="op">-</span><span class="st"> </span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))

<span class="kw">round</span>(rs<span class="op">$</span>aic,<span class="dv">2</span>) <span class="co"># uncorrected </span></code></pre></div>
<pre><code>[1] -44.37 -54.96 -63.18 -62.95 -63.27 -63.37 -62.81 -61.43</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(rs<span class="op">$</span>aic.corr,<span class="dv">2</span>) <span class="co"># bias-corrected</span></code></pre></div>
<pre><code>[1] -44.24 -54.70 -62.74 -62.29 -62.34 -62.11 -61.17 -59.36</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(rs<span class="op">$</span>aic.corr <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>), <span class="dt">ylab=</span><span class="st">&quot;AIC, corrected&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;# of Fitted Inputs&quot;</span>,
     <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">1.5</span>, <span class="dt">col=</span><span class="st">&quot;tomato&quot;</span>, <span class="dt">main=</span><span class="st">&quot;AIC (corrected) Plot&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<p>The smallest AIC<sub>c</sub> values occur in models 4 and later, especially model 4 itself.</p>
</div>
</div>
<div id="all-four-plots-together" class="section level2">
<h2><span class="header-section-number">8.6</span> All Four Plots, Together</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
m2 &lt;-<span class="st"> </span><span class="kw">max</span>(rs<span class="op">$</span>adjr2) 
m1 &lt;-<span class="st"> </span><span class="kw">which.max</span>(rs<span class="op">$</span>adjr2) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
<span class="kw">plot</span>(rs<span class="op">$</span>adjr2 <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>), <span class="dt">ylab=</span><span class="st">&quot;Adjusted R-squared&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;# of Inputs, including intercept&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Adjusted R-squared&quot;</span>)
<span class="kw">lines</span>(<span class="kw">spline</span>(rs<span class="op">$</span>adjr2 <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>)))
<span class="kw">arrows</span>(m1, m2<span class="op">-</span><span class="fl">0.02</span>, m1, m2)
<span class="kw">text</span>(m1, m2<span class="op">-</span><span class="fl">0.03</span>, <span class="kw">paste</span>(<span class="st">&quot;max =&quot;</span>, <span class="kw">format</span>(m2, <span class="dt">digits=</span><span class="dv">3</span>)))
<span class="kw">text</span>(m1, m2<span class="op">-</span><span class="fl">0.045</span>, <span class="kw">paste</span>(<span class="st">&quot;with&quot;</span>, <span class="kw">format</span>(m1, <span class="dt">digits=</span><span class="dv">1</span>),
                        <span class="st">&quot;inputs&quot;</span>), <span class="dt">pos=</span><span class="dv">3</span>)

<span class="kw">plot</span>(rs<span class="op">$</span>cp <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>),
     <span class="dt">ylab=</span><span class="st">&quot;Cp Statistic&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;# of Regression Inputs, including Intercept&quot;</span>,
     <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">main=</span><span class="st">&quot;Cp Plot&quot;</span>)
<span class="kw">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;purple&quot;</span>)

rs<span class="op">$</span>aic.corr &lt;-<span class="st"> </span><span class="dv">97</span><span class="op">*</span><span class="kw">log</span>(rs<span class="op">$</span>rss <span class="op">/</span><span class="st"> </span><span class="dv">97</span>) <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">+</span>
<span class="st">               </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">*</span><span class="st"> </span>((<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>)<span class="op">+</span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(<span class="dv">97</span> <span class="op">-</span><span class="st"> </span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
<span class="kw">plot</span>(rs<span class="op">$</span>aic.corr <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>), <span class="dt">ylab=</span><span class="st">&quot;AIC, corrected&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;# of Fitted Inputs&quot;</span>,
     <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">1.5</span>, <span class="dt">col=</span><span class="st">&quot;tomato&quot;</span>, <span class="dt">main=</span><span class="st">&quot;AIC (corrected) Plot&quot;</span>)

<span class="kw">plot</span>(rs<span class="op">$</span>bic <span class="op">~</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">9</span>), <span class="dt">ylab=</span><span class="st">&quot;BIC&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;# of Fitted Inputs&quot;</span>,
     <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">1.5</span>, <span class="dt">col=</span><span class="st">&quot;slateblue&quot;</span>, <span class="dt">main=</span><span class="st">&quot;BIC Plot&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</code></pre></div>
</div>
<div id="table-of-key-results" class="section level2">
<h2><span class="header-section-number">8.7</span> Table of Key Results</h2>
<p>We can build a big table, like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">winners &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">inputs =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">9</span>)
winners<span class="op">$</span>r2 &lt;-<span class="st"> </span>rs<span class="op">$</span>rsq
winners<span class="op">$</span>adjr2 &lt;-<span class="st"> </span>rs<span class="op">$</span>adjr2
winners<span class="op">$</span>cp &lt;-<span class="st"> </span>rs<span class="op">$</span>cp
winners<span class="op">$</span>bic &lt;-<span class="st"> </span>rs<span class="op">$</span>bic
winners<span class="op">$</span>aic &lt;-<span class="st"> </span>rs<span class="op">$</span>aic
winners<span class="op">$</span>aic.corr &lt;-<span class="st"> </span>rs<span class="op">$</span>aic.corr
winners <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(., <span class="dv">3</span>)</code></pre></div>
<pre><code># A tibble: 8 x 7
  inputs    r2 adjr2    cp   bic   aic aic.corr
   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;
1   2.00 0.539 0.535 28.2  -66.1 -44.4    -44.2
2   3.00 0.596 0.587 15.5  -74.1 -55.0    -54.7
3   4.00 0.636 0.624  6.81 -79.7 -63.2    -62.7
4   5.00 0.643 0.627  7.08 -76.9 -63.0    -62.3
5   6.00 0.651 0.632  6.85 -74.7 -63.3    -62.3
6   7.00 0.658 0.636  6.89 -72.2 -63.4    -62.1
7   8.00 0.663 0.637  7.56 -69.0 -62.8    -61.2
8   9.00 0.666 0.635  9.00 -65.1 -61.4    -59.4</code></pre>
</div>
<div id="models-worth-considering" class="section level2">
<h2><span class="header-section-number">8.8</span> Models Worth Considering?</h2>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(k\)</span></th>
<th align="right">Size</th>
<th>Predictors</th>
<th>Reason</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4</td>
<td align="right">3</td>
<td><code>lcavol lweight svi_f</code></td>
<td>minimizes BIC</td>
</tr>
<tr class="even">
<td align="right">7</td>
<td align="right">6</td>
<td><code>+ age bph_f gleason_f</code></td>
<td><span class="math inline">\(C_p\)</span> near <em>p</em></td>
</tr>
<tr class="odd">
<td align="right">8</td>
<td align="right">7</td>
<td><code>+ lcp</code></td>
<td>max <span class="math inline">\(R^2_{adj}\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="anova-testing-to-compare-these-three-models" class="section level2">
<h2><span class="header-section-number">8.9</span> ANOVA Testing to compare these three models?</h2>
<p>Let’s run an ANOVA-based comparison of these nested models to each other and to the model with the intercept alone.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m.int &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> prost)
m04 &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi_f, <span class="dt">data =</span> prost)
m07 &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi_f <span class="op">+</span><span class="st"> </span>
<span class="st">              </span>age <span class="op">+</span><span class="st"> </span>bph_f <span class="op">+</span><span class="st"> </span>gleason_f, <span class="dt">data =</span> prost)
m08 &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi_f <span class="op">+</span><span class="st"> </span>
<span class="st">              </span>age <span class="op">+</span><span class="st"> </span>bph_f <span class="op">+</span><span class="st"> </span>gleason_f <span class="op">+</span><span class="st"> </span>lcp, <span class="dt">data =</span> prost)
m.full &lt;-<span class="st"> </span><span class="kw">lm</span>(lpsa <span class="op">~</span><span class="st"> </span>lcavol <span class="op">+</span><span class="st"> </span>lweight <span class="op">+</span><span class="st"> </span>svi_f <span class="op">+</span><span class="st"> </span>
<span class="st">              </span>age <span class="op">+</span><span class="st"> </span>bph_f <span class="op">+</span><span class="st"> </span>gleason_f <span class="op">+</span><span class="st"> </span>lcp <span class="op">+</span><span class="st"> </span>pgg45, <span class="dt">data =</span> prost)</code></pre></div>
<p>Next, we’ll run…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(m.full, m08, m07, m04, m.int)</code></pre></div>
<pre><code>Analysis of Variance Table

Model 1: lpsa ~ lcavol + lweight + svi_f + age + bph_f + gleason_f + lcp + 
    pgg45
Model 2: lpsa ~ lcavol + lweight + svi_f + age + bph_f + gleason_f + lcp
Model 3: lpsa ~ lcavol + lweight + svi_f + age + bph_f + gleason_f
Model 4: lpsa ~ lcavol + lweight + svi_f
Model 5: lpsa ~ 1
  Res.Df     RSS Df Sum of Sq       F Pr(&gt;F)    
1     86  41.057                                
2     87  41.498 -1    -0.441  0.9234 0.3393    
3     88  42.066 -1    -0.568  1.1891 0.2786    
4     93  46.568 -5    -4.503  1.8863 0.1050    
5     96 127.918 -3   -81.349 56.7991 &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>What conclusions can we draw here, on the basis of these ANOVA tests?</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Hastie2001">
<p>Hastie, Trevor, Robert Tibshriani, and Jerome H. Frideman. 2001. <em>The Elements of Statistical Learning</em>. New York: Springer.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="stepwise-variable-selection.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08_bestsubsets.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
