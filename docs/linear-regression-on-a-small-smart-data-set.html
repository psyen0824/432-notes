<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Data Science for Biological, Medical and Health Research: Notes for 432</title>
  <meta name="description" content="These are the Course Notes for 432.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Data Science for Biological, Medical and Health Research: Notes for 432" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are the Course Notes for 432." />
  <meta name="github-repo" content="thomaselove/432-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Science for Biological, Medical and Health Research: Notes for 432" />
  
  <meta name="twitter:description" content="These are the Course Notes for 432." />
  

<meta name="author" content="Thomas E. Love, Ph.D.">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="building-table-1.html">
<link rel="next" href="analysis-of-variance-and-analysis-of-covariance.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">432 Course Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="r-packages-used-in-these-notes.html"><a href="r-packages-used-in-these-notes.html"><i class="fa fa-check"></i>R Packages used in these notes</a></li>
<li class="chapter" data-level="" data-path="data-used-in-these-notes.html"><a href="data-used-in-these-notes.html"><i class="fa fa-check"></i>Data used in these notes</a></li>
<li class="chapter" data-level="" data-path="special-functions-used-in-these-notes.html"><a href="special-functions-used-in-these-notes.html"><i class="fa fa-check"></i>Special Functions used in these notes</a></li>
<li class="chapter" data-level="1" data-path="building-table-1.html"><a href="building-table-1.html"><i class="fa fa-check"></i><b>1</b> Building Table 1</a><ul>
<li class="chapter" data-level="1.1" data-path="building-table-1.html"><a href="building-table-1.html#two-examples-from-the-new-england-journal-of-medicine"><i class="fa fa-check"></i><b>1.1</b> Two examples from the <em>New England Journal of Medicine</em></a><ul>
<li class="chapter" data-level="1.1.1" data-path="building-table-1.html"><a href="building-table-1.html#a-simple-table-1"><i class="fa fa-check"></i><b>1.1.1</b> A simple Table 1</a></li>
<li class="chapter" data-level="1.1.2" data-path="building-table-1.html"><a href="building-table-1.html#a-group-comparison"><i class="fa fa-check"></i><b>1.1.2</b> A group comparison</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="building-table-1.html"><a href="building-table-1.html#the-mr-clean-trial"><i class="fa fa-check"></i><b>1.2</b> The MR CLEAN trial</a></li>
<li class="chapter" data-level="1.3" data-path="building-table-1.html"><a href="building-table-1.html#simulated-fakestroke-data"><i class="fa fa-check"></i><b>1.3</b> Simulated <code>fakestroke</code> data</a></li>
<li class="chapter" data-level="1.4" data-path="building-table-1.html"><a href="building-table-1.html#building-table-1-for-fakestroke-attempt-1"><i class="fa fa-check"></i><b>1.4</b> Building Table 1 for <code>fakestroke</code>: Attempt 1</a><ul>
<li class="chapter" data-level="1.4.1" data-path="building-table-1.html"><a href="building-table-1.html#some-of-this-is-very-useful-and-other-parts-need-to-be-fixed."><i class="fa fa-check"></i><b>1.4.1</b> Some of this is very useful, and other parts need to be fixed.</a></li>
<li class="chapter" data-level="1.4.2" data-path="building-table-1.html"><a href="building-table-1.html#fakestroke-cleaning-up-categorical-variables"><i class="fa fa-check"></i><b>1.4.2</b> <code>fakestroke</code> Cleaning Up Categorical Variables</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="building-table-1.html"><a href="building-table-1.html#fakestroke-table-1-attempt-2"><i class="fa fa-check"></i><b>1.5</b> <code>fakestroke</code> Table 1: Attempt 2</a><ul>
<li class="chapter" data-level="1.5.1" data-path="building-table-1.html"><a href="building-table-1.html#what-summaries-should-we-show"><i class="fa fa-check"></i><b>1.5.1</b> What summaries should we show?</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="building-table-1.html"><a href="building-table-1.html#obtaining-a-more-detailed-summary"><i class="fa fa-check"></i><b>1.6</b> Obtaining a more detailed Summary</a></li>
<li class="chapter" data-level="1.7" data-path="building-table-1.html"><a href="building-table-1.html#exporting-the-completed-table-1-from-r-to-excel-or-word"><i class="fa fa-check"></i><b>1.7</b> Exporting the Completed Table 1 from R to Excel or Word</a><ul>
<li class="chapter" data-level="1.7.1" data-path="building-table-1.html"><a href="building-table-1.html#approach-a-save-and-open-in-excel"><i class="fa fa-check"></i><b>1.7.1</b> Approach A: Save and open in Excel</a></li>
<li class="chapter" data-level="1.7.2" data-path="building-table-1.html"><a href="building-table-1.html#approach-b-produce-the-table-so-you-can-cut-and-paste-it"><i class="fa fa-check"></i><b>1.7.2</b> Approach B: Produce the Table so you can cut and paste it</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="building-table-1.html"><a href="building-table-1.html#a-controlled-biological-experiment---the-blood-brain-barrier"><i class="fa fa-check"></i><b>1.8</b> A Controlled Biological Experiment - The Blood-Brain Barrier</a></li>
<li class="chapter" data-level="1.9" data-path="building-table-1.html"><a href="building-table-1.html#the-bloodbrain.csv-file"><i class="fa fa-check"></i><b>1.9</b> The <code>bloodbrain.csv</code> file</a></li>
<li class="chapter" data-level="1.10" data-path="building-table-1.html"><a href="building-table-1.html#a-table-1-for-bloodbrain"><i class="fa fa-check"></i><b>1.10</b> A Table 1 for <code>bloodbrain</code></a><ul>
<li class="chapter" data-level="1.10.1" data-path="building-table-1.html"><a href="building-table-1.html#generate-final-table-1-for-bloodbrain"><i class="fa fa-check"></i><b>1.10.1</b> Generate final Table 1 for <code>bloodbrain</code></a></li>
<li class="chapter" data-level="1.10.2" data-path="building-table-1.html"><a href="building-table-1.html#a-more-finished-version-after-cleanup-in-word"><i class="fa fa-check"></i><b>1.10.2</b> A More Finished Version (after Cleanup in Word)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html"><i class="fa fa-check"></i><b>2</b> Linear Regression on a small SMART data set</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#brfss-and-smart"><i class="fa fa-check"></i><b>2.1</b> BRFSS and SMART</a><ul>
<li class="chapter" data-level="2.1.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#key-resources"><i class="fa fa-check"></i><b>2.1.1</b> Key resources</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-smartcle1-data-cookbook"><i class="fa fa-check"></i><b>2.2</b> The <code>smartcle1</code> data: Cookbook</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#smartcle2-omitting-missing-observations-complete-case-analyses"><i class="fa fa-check"></i><b>2.3</b> <code>smartcle2</code>: Omitting Missing Observations: Complete-Case Analyses</a></li>
<li class="chapter" data-level="2.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#summarizing-the-smartcle2-data-numerically"><i class="fa fa-check"></i><b>2.4</b> Summarizing the <code>smartcle2</code> data numerically</a><ul>
<li class="chapter" data-level="2.4.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-new-toy-the-skim-function"><i class="fa fa-check"></i><b>2.4.1</b> The New Toy: The <code>skim</code> function</a></li>
<li class="chapter" data-level="2.4.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-usual-summary-for-a-data-frame"><i class="fa fa-check"></i><b>2.4.2</b> The usual <code>summary</code> for a data frame</a></li>
<li class="chapter" data-level="2.4.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-describe-function-in-hmisc"><i class="fa fa-check"></i><b>2.4.3</b> The <code>describe</code> function in <code>Hmisc</code></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#counting-as-exploratory-data-analysis"><i class="fa fa-check"></i><b>2.5</b> Counting as exploratory data analysis</a><ul>
<li class="chapter" data-level="2.5.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-respondents-had-exercised-in-the-past-30-days-did-this-vary-by-sex"><i class="fa fa-check"></i><b>2.5.1</b> How many respondents had exercised in the past 30 days? Did this vary by sex?</a></li>
<li class="chapter" data-level="2.5.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#whats-the-distribution-of-sleephrs"><i class="fa fa-check"></i><b>2.5.2</b> What’s the distribution of <code>sleephrs</code>?</a></li>
<li class="chapter" data-level="2.5.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#whats-the-distribution-of-bmi"><i class="fa fa-check"></i><b>2.5.3</b> What’s the distribution of <code>BMI</code>?</a></li>
<li class="chapter" data-level="2.5.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-of-the-respondents-have-a-bmi-below-30"><i class="fa fa-check"></i><b>2.5.4</b> How many of the respondents have a BMI below 30?</a></li>
<li class="chapter" data-level="2.5.5" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-of-the-respondents-who-have-a-bmi-30-exercised"><i class="fa fa-check"></i><b>2.5.5</b> How many of the respondents who have a BMI &lt; 30 exercised?</a></li>
<li class="chapter" data-level="2.5.6" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#is-obesity-associated-with-sex-in-these-data"><i class="fa fa-check"></i><b>2.5.6</b> Is obesity associated with sex, in these data?</a></li>
<li class="chapter" data-level="2.5.7" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#comparing-sleephrs-summaries-by-obesity-status"><i class="fa fa-check"></i><b>2.5.7</b> Comparing <code>sleephrs</code> summaries by obesity status</a></li>
<li class="chapter" data-level="2.5.8" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-skim-function-within-a-pipe"><i class="fa fa-check"></i><b>2.5.8</b> The <code>skim</code> function within a pipe</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#first-modeling-attempt-can-bmi-predict-physhealth"><i class="fa fa-check"></i><b>2.6</b> First Modeling Attempt: Can <code>bmi</code> predict <code>physhealth</code>?</a><ul>
<li class="chapter" data-level="2.6.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-a-simple-regression-model"><i class="fa fa-check"></i><b>2.6.1</b> Fitting a Simple Regression Model</a></li>
<li class="chapter" data-level="2.6.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#model-summary-for-a-simple-one-predictor-regression"><i class="fa fa-check"></i><b>2.6.2</b> Model Summary for a Simple (One-Predictor) Regression</a></li>
<li class="chapter" data-level="2.6.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#using-the-broom-package"><i class="fa fa-check"></i><b>2.6.3</b> Using the <code>broom</code> package</a></li>
<li class="chapter" data-level="2.6.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-does-the-model-do-residuals-vs.fitted-values"><i class="fa fa-check"></i><b>2.6.4</b> How does the model do? (Residuals vs. Fitted Values)</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#a-new-small-study-predicting-bmi"><i class="fa fa-check"></i><b>2.7</b> A New Small Study: Predicting BMI</a><ul>
<li class="chapter" data-level="2.7.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#does-female-predict-bmi-well"><i class="fa fa-check"></i><b>2.7.1</b> Does <code>female</code> predict <code>bmi</code> well?</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m1-a-simple-t-test-model"><i class="fa fa-check"></i><b>2.8</b> <code>c2_m1</code>: A simple t-test model</a></li>
<li class="chapter" data-level="2.9" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m2-adding-another-predictor-two-way-anova-without-interaction"><i class="fa fa-check"></i><b>2.9</b> <code>c2_m2</code>: Adding another predictor (two-way ANOVA without interaction)</a></li>
<li class="chapter" data-level="2.10" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m3-adding-the-interaction-term-two-way-anova-with-interaction"><i class="fa fa-check"></i><b>2.10</b> <code>c2_m3</code>: Adding the interaction term (Two-way ANOVA with interaction)</a></li>
<li class="chapter" data-level="2.11" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m4-using-female-and-sleephrs-in-a-model-for-bmi"><i class="fa fa-check"></i><b>2.11</b> <code>c2_m4</code>: Using <code>female</code> and <code>sleephrs</code> in a model for <code>bmi</code></a></li>
<li class="chapter" data-level="2.12" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#making-predictions-with-a-linear-regression-model"><i class="fa fa-check"></i><b>2.12</b> Making Predictions with a Linear Regression Model</a><ul>
<li class="chapter" data-level="2.12.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-an-individual-prediction-and-95-prediction-interval"><i class="fa fa-check"></i><b>2.12.1</b> Fitting an Individual Prediction and 95% Prediction Interval</a></li>
<li class="chapter" data-level="2.12.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#confidence-interval-for-an-average-prediction"><i class="fa fa-check"></i><b>2.12.2</b> Confidence Interval for an Average Prediction</a></li>
<li class="chapter" data-level="2.12.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-multiple-individual-predictions-to-new-data"><i class="fa fa-check"></i><b>2.12.3</b> Fitting Multiple Individual Predictions to New Data</a></li>
<li class="chapter" data-level="2.12.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#simulation-to-represent-predictive-uncertainty-in-model-4"><i class="fa fa-check"></i><b>2.12.4</b> Simulation to represent predictive uncertainty in Model 4</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#centering-the-model"><i class="fa fa-check"></i><b>2.13</b> Centering the model</a><ul>
<li class="chapter" data-level="2.13.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#plot-of-model-4-on-centered-sleephrs-c2_m4_c"><i class="fa fa-check"></i><b>2.13.1</b> Plot of Model 4 on Centered <code>sleephrs</code>: <code>c2_m4_c</code></a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#rescaling-an-input-by-subtracting-the-mean-and-dividing-by-2-standard-deviations"><i class="fa fa-check"></i><b>2.14</b> Rescaling an input by subtracting the mean and dividing by 2 standard deviations</a><ul>
<li class="chapter" data-level="2.14.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#refitting-model-c2_m4-to-the-rescaled-data"><i class="fa fa-check"></i><b>2.14.1</b> Refitting model <code>c2_m4</code> to the rescaled data</a></li>
<li class="chapter" data-level="2.14.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#interpreting-the-model-on-rescaled-data"><i class="fa fa-check"></i><b>2.14.2</b> Interpreting the model on rescaled data</a></li>
<li class="chapter" data-level="2.14.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#plot-of-model-on-rescaled-data"><i class="fa fa-check"></i><b>2.14.3</b> Plot of model on rescaled data</a></li>
</ul></li>
<li class="chapter" data-level="2.15" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m5-what-if-we-add-more-variables"><i class="fa fa-check"></i><b>2.15</b> <code>c2_m5</code>: What if we add more variables?</a></li>
<li class="chapter" data-level="2.16" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m6-would-adding-self-reported-health-help"><i class="fa fa-check"></i><b>2.16</b> <code>c2_m6</code>: Would adding self-reported health help?</a></li>
<li class="chapter" data-level="2.17" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m7-what-if-we-added-days-of-work-missed"><i class="fa fa-check"></i><b>2.17</b> <code>c2_m7</code>: What if we added days of work missed?</a></li>
<li class="chapter" data-level="2.18" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#key-regression-assumptions-for-building-effective-prediction-models"><i class="fa fa-check"></i><b>2.18</b> Key Regression Assumptions for Building Effective Prediction Models</a><ul>
<li class="chapter" data-level="2.18.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#checking-assumptions-in-model-c2_m7"><i class="fa fa-check"></i><b>2.18.1</b> Checking Assumptions in model <code>c2_m7</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html"><i class="fa fa-check"></i><b>3</b> Analysis of Variance and Analysis of Covariance</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#the-bonding-data-a-designed-dental-experiment"><i class="fa fa-check"></i><b>3.1</b> The <code>bonding</code> data: A Designed Dental Experiment</a></li>
<li class="chapter" data-level="3.2" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#a-one-factor-analysis-of-variance"><i class="fa fa-check"></i><b>3.2</b> A One-Factor Analysis of Variance</a><ul>
<li class="chapter" data-level="3.2.1" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#look-at-the-data"><i class="fa fa-check"></i><b>3.2.1</b> Look at the Data!</a></li>
<li class="chapter" data-level="3.2.2" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#table-of-summary-statistics"><i class="fa fa-check"></i><b>3.2.2</b> Table of Summary Statistics</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#a-two-way-anova-looking-at-two-factors"><i class="fa fa-check"></i><b>3.3</b> A Two-Way ANOVA: Looking at Two Factors</a></li>
<li class="chapter" data-level="3.4" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#a-means-plot-with-standard-deviations-to-check-for-interaction"><i class="fa fa-check"></i><b>3.4</b> A Means Plot (with standard deviations) to check for interaction</a><ul>
<li class="chapter" data-level="3.4.1" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#skimming-the-data-after-grouping-by-resin-and-light"><i class="fa fa-check"></i><b>3.4.1</b> Skimming the data after grouping by <code>resin</code> and <code>light</code></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#fitting-the-two-way-anova-model-with-interaction"><i class="fa fa-check"></i><b>3.5</b> Fitting the Two-Way ANOVA model with Interaction</a><ul>
<li class="chapter" data-level="3.5.1" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#the-anova-table-for-our-model"><i class="fa fa-check"></i><b>3.5.1</b> The ANOVA table for our model</a></li>
<li class="chapter" data-level="3.5.2" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#is-the-interaction-important"><i class="fa fa-check"></i><b>3.5.2</b> Is the interaction important?</a></li>
<li class="chapter" data-level="3.5.3" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#interpreting-the-interaction"><i class="fa fa-check"></i><b>3.5.3</b> Interpreting the Interaction</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#comparing-individual-combinations-of-resin-and-light"><i class="fa fa-check"></i><b>3.6</b> Comparing Individual Combinations of <code>resin</code> and <code>light</code></a></li>
<li class="chapter" data-level="3.7" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#the-bonding-model-without-interaction"><i class="fa fa-check"></i><b>3.7</b> The <code>bonding</code> model without Interaction</a></li>
<li class="chapter" data-level="3.8" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#cortisol-a-hypothetical-clinical-trial"><i class="fa fa-check"></i><b>3.8</b> <code>cortisol</code>: A Hypothetical Clinical Trial</a><ul>
<li class="chapter" data-level="3.8.1" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#codebook-and-raw-data-for-cortisol"><i class="fa fa-check"></i><b>3.8.1</b> Codebook and Raw Data for <code>cortisol</code></a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#creating-a-factor-combining-sex-and-waist"><i class="fa fa-check"></i><b>3.9</b> Creating a factor combining sex and waist</a></li>
<li class="chapter" data-level="3.10" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#a-means-plot-for-the-cortisol-trial-with-standard-errors"><i class="fa fa-check"></i><b>3.10</b> A Means Plot for the <code>cortisol</code> trial (with standard errors)</a></li>
<li class="chapter" data-level="3.11" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#a-two-way-anova-model-for-cortisol-with-interaction"><i class="fa fa-check"></i><b>3.11</b> A Two-Way ANOVA model for <code>cortisol</code> with Interaction</a></li>
<li class="chapter" data-level="3.12" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#a-two-way-anova-model-for-cortisol-without-interaction"><i class="fa fa-check"></i><b>3.12</b> A Two-Way ANOVA model for <code>cortisol</code> without Interaction</a><ul>
<li class="chapter" data-level="3.12.1" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#the-graph"><i class="fa fa-check"></i><b>3.12.1</b> The Graph</a></li>
<li class="chapter" data-level="3.12.2" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#the-anova-model"><i class="fa fa-check"></i><b>3.12.2</b> The ANOVA Model</a></li>
<li class="chapter" data-level="3.12.3" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#the-regression-summary"><i class="fa fa-check"></i><b>3.12.3</b> The Regression Summary</a></li>
<li class="chapter" data-level="3.12.4" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#tukey-hsd-comparisons"><i class="fa fa-check"></i><b>3.12.4</b> Tukey HSD Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#an-emphysema-study-analysis-of-covariance"><i class="fa fa-check"></i><b>3.13</b> An Emphysema Study: Analysis of Covariance</a><ul>
<li class="chapter" data-level="3.13.1" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#codebook"><i class="fa fa-check"></i><b>3.13.1</b> Codebook</a></li>
<li class="chapter" data-level="3.13.2" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#does-sex-affect-the-mean-change-in-theophylline"><i class="fa fa-check"></i><b>3.13.2</b> Does <code>sex</code> affect the mean change in theophylline?</a></li>
<li class="chapter" data-level="3.13.3" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#is-there-an-association-between-age-and-sex-in-this-study"><i class="fa fa-check"></i><b>3.13.3</b> Is there an association between <code>age</code> and <code>sex</code> in this study?</a></li>
<li class="chapter" data-level="3.13.4" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#adding-a-quantitative-covariate-age-to-the-model"><i class="fa fa-check"></i><b>3.13.4</b> Adding a quantitative covariate, <code>age</code>, to the model</a></li>
<li class="chapter" data-level="3.13.5" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#rerunning-the-ancova-model-after-simple-imputation"><i class="fa fa-check"></i><b>3.13.5</b> Rerunning the ANCOVA model after simple imputation</a></li>
<li class="chapter" data-level="3.13.6" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#looking-at-a-factor-covariate-interaction"><i class="fa fa-check"></i><b>3.13.6</b> Looking at a factor-covariate interaction</a></li>
<li class="chapter" data-level="3.13.7" data-path="analysis-of-variance-and-analysis-of-covariance.html"><a href="analysis-of-variance-and-analysis-of-covariance.html#centering-the-covariate-to-facilitate-anova-interpretation"><i class="fa fa-check"></i><b>3.13.7</b> Centering the Covariate to Facilitate ANOVA Interpretation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html"><i class="fa fa-check"></i><b>4</b> Missing Data Mechanisms and Single Imputation</a><ul>
<li class="chapter" data-level="4.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#a-toy-example"><i class="fa fa-check"></i><b>4.1</b> A Toy Example</a><ul>
<li class="chapter" data-level="4.1.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#how-many-missing-values-do-we-have-in-each-column"><i class="fa fa-check"></i><b>4.1.1</b> How many missing values do we have in each column?</a></li>
<li class="chapter" data-level="4.1.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#what-is-the-pattern-of-missing-data"><i class="fa fa-check"></i><b>4.1.2</b> What is the pattern of missing data?</a></li>
<li class="chapter" data-level="4.1.3" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#how-can-we-identify-the-subjects-with-missing-data"><i class="fa fa-check"></i><b>4.1.3</b> How can we identify the subjects with missing data?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#missing-data-mechanisms"><i class="fa fa-check"></i><b>4.2</b> Missing-data mechanisms</a></li>
<li class="chapter" data-level="4.3" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#options-for-dealing-with-missingness"><i class="fa fa-check"></i><b>4.3</b> Options for Dealing with Missingness</a></li>
<li class="chapter" data-level="4.4" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#complete-case-and-available-case-analyses"><i class="fa fa-check"></i><b>4.4</b> Complete Case (and Available Case) analyses</a></li>
<li class="chapter" data-level="4.5" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#single-imputation"><i class="fa fa-check"></i><b>4.5</b> Single Imputation</a></li>
<li class="chapter" data-level="4.6" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#multiple-imputation"><i class="fa fa-check"></i><b>4.6</b> Multiple Imputation</a></li>
<li class="chapter" data-level="4.7" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#building-a-complete-case-analysis"><i class="fa fa-check"></i><b>4.7</b> Building a Complete Case Analysis</a></li>
<li class="chapter" data-level="4.8" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#single-imputation-with-the-mean-or-mode"><i class="fa fa-check"></i><b>4.8</b> Single Imputation with the Mean or Mode</a></li>
<li class="chapter" data-level="4.9" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#doing-single-imputation-with-simputation"><i class="fa fa-check"></i><b>4.9</b> Doing Single Imputation with <code>simputation</code></a><ul>
<li class="chapter" data-level="4.9.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#mirroring-our-prior-approach-imputing-meansmediansmodes"><i class="fa fa-check"></i><b>4.9.1</b> Mirroring Our Prior Approach (imputing means/medians/modes)</a></li>
<li class="chapter" data-level="4.9.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#using-a-model-to-impute-sbp.before-and-diabetes"><i class="fa fa-check"></i><b>4.9.2</b> Using a model to impute <code>sbp.before</code> and <code>diabetes</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html"><i class="fa fa-check"></i><b>5</b> A Study of Prostate Cancer</a><ul>
<li class="chapter" data-level="5.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#data-load-and-background"><i class="fa fa-check"></i><b>5.1</b> Data Load and Background</a></li>
<li class="chapter" data-level="5.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#code-book"><i class="fa fa-check"></i><b>5.2</b> Code Book</a></li>
<li class="chapter" data-level="5.3" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#additions-for-later-use"><i class="fa fa-check"></i><b>5.3</b> Additions for Later Use</a></li>
<li class="chapter" data-level="5.4" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#fitting-and-evaluating-a-two-predictor-model"><i class="fa fa-check"></i><b>5.4</b> Fitting and Evaluating a Two-Predictor Model</a><ul>
<li class="chapter" data-level="5.4.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#using-tidy"><i class="fa fa-check"></i><b>5.4.1</b> Using <code>tidy</code></a></li>
<li class="chapter" data-level="5.4.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#interpretation"><i class="fa fa-check"></i><b>5.4.2</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#exploring-model-c5_prost_a"><i class="fa fa-check"></i><b>5.5</b> Exploring Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="5.5.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#summary-for-model-c5_prost_a"><i class="fa fa-check"></i><b>5.5.1</b> <code>summary</code> for Model <code>c5_prost_A</code></a></li>
<li class="chapter" data-level="5.5.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#adjusted-r2"><i class="fa fa-check"></i><b>5.5.2</b> Adjusted R<sup>2</sup></a></li>
<li class="chapter" data-level="5.5.3" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#coefficient-confidence-intervals"><i class="fa fa-check"></i><b>5.5.3</b> Coefficient Confidence Intervals</a></li>
<li class="chapter" data-level="5.5.4" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#anova-for-model-c5_prost_a"><i class="fa fa-check"></i><b>5.5.4</b> ANOVA for Model <code>c5_prost_A</code></a></li>
<li class="chapter" data-level="5.5.5" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#residuals-fitted-values-and-standard-errors-with-augment"><i class="fa fa-check"></i><b>5.5.5</b> Residuals, Fitted Values and Standard Errors with <code>augment</code></a></li>
<li class="chapter" data-level="5.5.6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#making-predictions-with-c5_prost_a"><i class="fa fa-check"></i><b>5.5.6</b> Making Predictions with <code>c5_prost_A</code></a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#plotting-model-c5_prost_a"><i class="fa fa-check"></i><b>5.6</b> Plotting Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="5.6.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#residual-plots-of-c5_prost_a"><i class="fa fa-check"></i><b>5.6.1</b> Residual Plots of <code>c5_prost_A</code></a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#cross-validation-of-model-c5_prost_a"><i class="fa fa-check"></i><b>5.7</b> Cross-Validation of Model <code>c5_prost_A</code></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html"><i class="fa fa-check"></i><b>6</b> Stepwise Variable Selection</a><ul>
<li class="chapter" data-level="6.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#strategy-for-model-selection"><i class="fa fa-check"></i><b>6.1</b> Strategy for Model Selection</a><ul>
<li class="chapter" data-level="6.1.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#how-do-we-choose-potential-subsets-of-predictors"><i class="fa fa-check"></i><b>6.1.1</b> How Do We Choose Potential Subsets of Predictors?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#a-kitchen-sink-model-model-c5_prost_ks"><i class="fa fa-check"></i><b>6.2</b> A “Kitchen Sink” Model (Model <code>c5_prost_ks</code>)</a></li>
<li class="chapter" data-level="6.3" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#sequential-variable-selection-stepwise-approaches"><i class="fa fa-check"></i><b>6.3</b> Sequential Variable Selection: Stepwise Approaches</a><ul>
<li class="chapter" data-level="6.3.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#the-big-problems-with-stepwise-regression"><i class="fa fa-check"></i><b>6.3.1</b> The Big Problems with Stepwise Regression</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#forward-selection-with-the-step-function"><i class="fa fa-check"></i><b>6.4</b> Forward Selection with the <code>step</code> function</a></li>
<li class="chapter" data-level="6.5" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#backward-elimination-using-the-step-function"><i class="fa fa-check"></i><b>6.5</b> Backward Elimination using the <code>step</code> function</a></li>
<li class="chapter" data-level="6.6" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#allen-cady-modified-backward-elimination"><i class="fa fa-check"></i><b>6.6</b> Allen-Cady Modified Backward Elimination</a><ul>
<li class="chapter" data-level="6.6.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#demonstration-of-the-allen-cady-approach"><i class="fa fa-check"></i><b>6.6.1</b> Demonstration of the Allen-Cady approach</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#summarizing-the-results"><i class="fa fa-check"></i><b>6.7</b> Summarizing the Results</a><ul>
<li class="chapter" data-level="6.7.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#in-sample-testing-and-summaries"><i class="fa fa-check"></i><b>6.7.1</b> In-Sample Testing and Summaries</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science for Biological, Medical and Health Research: Notes for 432</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-regression-on-a-small-smart-data-set" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Linear Regression on a small SMART data set</h1>
<div id="brfss-and-smart" class="section level2">
<h2><span class="header-section-number">2.1</span> BRFSS and SMART</h2>
<p>The Centers for Disease Control analyzes Behavioral Risk Factor Surveillance System (BRFSS) survey data for specific metropolitan and micropolitan statistical areas (MMSAs) in a program called the <a href="https://www.cdc.gov/brfss/smart/Smart_data.htm">Selected Metropolitan/Micropolitan Area Risk Trends of BRFSS</a> (SMART BRFSS.)</p>
<p>In this work, we will focus on <a href="https://www.cdc.gov/brfss/smart/smart_2016.html">data from the 2016 SMART</a>, and in particular on data from the Cleveland-Elyria, OH, Metropolitan Statistical Area. The purpose of this survey is to provide localized health information that can help public health practitioners identify local emerging health problems, plan and evaluate local responses, and efficiently allocate resources to specific needs.</p>
<div id="key-resources" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Key resources</h3>
<ul>
<li>the full data are available in the form of the 2016 SMART BRFSS MMSA Data, found in a zipped <a href="https://www.cdc.gov/brfss/smart/2016/MMSA2016_XPT.zip">SAS Transport Format</a> file. The data were released in August 2017.</li>
<li>the <a href="https://www.cdc.gov/brfss/smart/2016/mmsa_varlayout_16.pdf">MMSA Variable Layout PDF</a> which simply lists the variables included in the data file</li>
<li>the <a href="https://www.cdc.gov/brfss/annual_data/2016/pdf/2016_calculated_variables_version4.pdf">Calculated Variables PDF</a> which describes the risk factors by data variable names - there is also an <a href="https://www.cdc.gov/brfss/annual_data/2016/Summary_Matrix_16.html">online summary matrix of these calculated variables</a>, as well.</li>
<li>the lengthy <a href="https://www.cdc.gov/brfss/questionnaires/pdf-ques/2016_BRFSS_Questionnaire_FINAL.pdf">2016 Survey Questions PDF</a> which lists all questions asked as part of the BRFSS in 2016</li>
<li>the enormous <a href="https://www.cdc.gov/brfss/annual_data/2016/pdf/codebook16_llcp.pdf">Codebook for the 2016 BRFSS Survey PDF</a> which identifies the variables by name for us.</li>
</ul>
<p>Later this term, we’ll use all of those resources to help construct a more complete data set than we’ll study today. I’ll also demonstrate how I built the <code>smartcle1</code> data set that we’ll use in this Chapter.</p>
</div>
</div>
<div id="the-smartcle1-data-cookbook" class="section level2">
<h2><span class="header-section-number">2.2</span> The <code>smartcle1</code> data: Cookbook</h2>
<p>The <code>smartcle1.csv</code> data file available on the Data and Code page of <a href="https://github.com/THOMASELOVE/432-2018">our website</a> describes information on 11 variables for 1036 respondents to the BRFSS 2016, who live in the Cleveland-Elyria, OH, Metropolitan Statistical Area. The variables in the <code>smartcle1.csv</code> file are listed below, along with (in some cases) the BRFSS items that generate these responses.</p>
<table style="width:94%;">
<colgroup>
<col width="15%" />
<col width="79%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><code>SEQNO</code></td>
<td>respondent identification number (all begin with 2016)</td>
</tr>
<tr class="even">
<td align="right"><code>physhealth</code></td>
<td>Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good?</td>
</tr>
<tr class="odd">
<td align="right"><code>menthealth</code></td>
<td>Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good?</td>
</tr>
<tr class="even">
<td align="right"><code>poorhealth</code></td>
<td>During the past 30 days, for about how many days did poor physical or mental health keep you from doing your usual activities, such as self-care, work, or recreation?</td>
</tr>
<tr class="odd">
<td align="right"><code>genhealth</code></td>
<td>Would you say that in general, your health is … (five categories: Excellent, Very Good, Good, Fair or Poor)</td>
</tr>
<tr class="even">
<td align="right"><code>bmi</code></td>
<td>Body mass index, in kg/m<sup>2</sup></td>
</tr>
<tr class="odd">
<td align="right"><code>female</code></td>
<td>Sex, 1 = female, 0 = male</td>
</tr>
<tr class="even">
<td align="right"><code>internet30</code></td>
<td>Have you used the internet in the past 30 days? (1 = yes, 0 = no)</td>
</tr>
<tr class="odd">
<td align="right"><code>exerany</code></td>
<td>During the past month, other than your regular job, did you participate in any physical activities or exercises such as running, calisthenics, golf, gardening, or walking for exercise? (1 = yes, 0 = no)</td>
</tr>
<tr class="even">
<td align="right"><code>sleephrs</code></td>
<td>On average, how many hours of sleep do you get in a 24-hour period?</td>
</tr>
<tr class="odd">
<td align="right"><code>alcdays</code></td>
<td>How many days during the past 30 days did you have at least one drink of any alcoholic beverage such as beer, wine, a malt beverage or liquor?</td>
</tr>
</tbody>
</table>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(smartcle1)</code></pre></div>
<pre><code>Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;:   1036 obs. of  11 variables:
 $ SEQNO     : num  2.02e+09 2.02e+09 2.02e+09 2.02e+09 2.02e+09 ...
 $ physhealth: int  0 0 1 0 5 4 2 2 0 0 ...
 $ menthealth: int  0 0 5 0 0 18 0 3 0 0 ...
 $ poorhealth: int  NA NA 0 NA 0 6 0 0 NA NA ...
 $ genhealth : Factor w/ 5 levels &quot;1_Excellent&quot;,..: 2 1 2 3 1 2 3 3 2 3 ...
 $ bmi       : num  26.7 23.7 26.9 21.7 24.1 ...
 $ female    : int  1 0 0 1 0 0 1 1 0 0 ...
 $ internet30: int  1 1 1 1 1 1 1 1 1 1 ...
 $ exerany   : int  1 1 0 1 1 1 1 1 1 0 ...
 $ sleephrs  : int  6 6 8 9 7 5 9 7 7 7 ...
 $ alcdays   : int  1 4 4 3 2 28 4 2 4 25 ...</code></pre>
</div>
<div id="smartcle2-omitting-missing-observations-complete-case-analyses" class="section level2">
<h2><span class="header-section-number">2.3</span> <code>smartcle2</code>: Omitting Missing Observations: Complete-Case Analyses</h2>
<p>For the purpose of fitting our first few models, we will eliminate the missingness problem, and look only at the <em>complete cases</em> in our <code>smartcle1</code> data. We will discuss methods for imputing missing data later in these Notes.</p>
<p>To inspect the missingness in our data, we might consider using the <code>skim</code> function from the <code>skimr</code> package. We’ll exclude the respondent identifier code (<code>SEQNO</code>) from this summary as uninteresting.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">skim_with</span>(<span class="dt">numeric =</span> <span class="kw">list</span>(<span class="dt">hist =</span> <span class="ot">NULL</span>), <span class="dt">integer =</span> <span class="kw">list</span>(<span class="dt">hist =</span> <span class="ot">NULL</span>))
## above line eliminates the sparkline histograms
## it can be commented out when working in the console,
## but I need it to produce the Notes without errors right now

smartcle1 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">skim</span>(<span class="op">-</span>SEQNO)</code></pre></div>
<pre><code>Skim summary statistics
 n obs: 1036 
 n variables: 11 

Variable type: factor 
  variable missing complete    n n_unique
 genhealth       3     1033 1036        5
                             top_counts ordered
 2_V: 350, 3_G: 344, 1_E: 173, 4_F: 122   FALSE

Variable type: integer 
   variable missing complete    n mean   sd p0 p25 median p75 p100
    alcdays      46      990 1036 4.65 8.05  0   0      1   4   30
    exerany       3     1033 1036 0.76 0.43  0   1      1   1    1
     female       0     1036 1036 0.6  0.49  0   0      1   1    1
 internet30       6     1030 1036 0.81 0.39  0   1      1   1    1
 menthealth      11     1025 1036 2.72 6.82  0   0      0   2   30
 physhealth      17     1019 1036 3.97 8.67  0   0      0   2   30
 poorhealth     543      493 1036 4.07 8.09  0   0      0   3   30
   sleephrs       8     1028 1036 7.02 1.53  1   6      7   8   20

Variable type: numeric 
 variable missing complete    n  mean   sd    p0  p25 median   p75  p100
      bmi      84      952 1036 27.89 6.47 12.71 23.7  26.68 30.53 66.06</code></pre>
<p>Now, we’ll create a new tibble called <code>smartcle2</code> which contains every variable except <code>poorhealth</code>, and which includes all respondents with complete data on the variables (other than <code>poorhealth</code>). We’ll store those observations with complete data in the <code>smartcle2</code> tibble.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 &lt;-<span class="st"> </span>smartcle1 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">select</span>(<span class="op">-</span>poorhealth) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(<span class="kw">complete.cases</span>(.))

smartcle2</code></pre></div>
<pre><code># A tibble: 896 x 10
     SEQNO physhealth menthealth genhealth   bmi female internet30 exerany
     &lt;dbl&gt;      &lt;int&gt;      &lt;int&gt; &lt;fct&gt;     &lt;dbl&gt;  &lt;int&gt;      &lt;int&gt;   &lt;int&gt;
 1  2.02e9          0          0 2_VeryGo~  26.7      1          1       1
 2  2.02e9          0          0 1_Excell~  23.7      0          1       1
 3  2.02e9          1          5 2_VeryGo~  26.9      0          1       0
 4  2.02e9          0          0 3_Good     21.7      1          1       1
 5  2.02e9          5          0 1_Excell~  24.1      0          1       1
 6  2.02e9          4         18 2_VeryGo~  27.6      0          1       1
 7  2.02e9          2          0 3_Good     25.7      1          1       1
 8  2.02e9          2          3 3_Good     28.5      1          1       1
 9  2.02e9          0          0 2_VeryGo~  28.6      0          1       1
10  2.02e9          0          0 3_Good     23.1      0          1       0
# ... with 886 more rows, and 2 more variables: sleephrs &lt;int&gt;, alcdays
#   &lt;int&gt;</code></pre>
<p>Note that there are only 896 respondents with <strong>complete</strong> data on the 10 variables (excluding <code>poorhealth</code>) in the <code>smartcle2</code> tibble, as compared to our original <code>smartcle1</code> data which described 1036 respondents and 11 variables, but with lots of missing data.</p>
</div>
<div id="summarizing-the-smartcle2-data-numerically" class="section level2">
<h2><span class="header-section-number">2.4</span> Summarizing the <code>smartcle2</code> data numerically</h2>
<div id="the-new-toy-the-skim-function" class="section level3">
<h3><span class="header-section-number">2.4.1</span> The New Toy: The <code>skim</code> function</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">skim</span>(smartcle2, <span class="op">-</span>SEQNO)</code></pre></div>
<pre><code>Skim summary statistics
 n obs: 896 
 n variables: 10 

Variable type: factor 
  variable missing complete   n n_unique
 genhealth       0      896 896        5
                             top_counts ordered
 2_V: 306, 3_G: 295, 1_E: 155, 4_F: 102   FALSE

Variable type: integer 
   variable missing complete   n mean   sd p0 p25 median p75 p100
    alcdays       0      896 896 4.83 8.14  0   0      1   5   30
    exerany       0      896 896 0.77 0.42  0   1      1   1    1
     female       0      896 896 0.58 0.49  0   0      1   1    1
 internet30       0      896 896 0.81 0.39  0   1      1   1    1
 menthealth       0      896 896 2.69 6.72  0   0      0   2   30
 physhealth       0      896 896 3.99 8.64  0   0      0   2   30
   sleephrs       0      896 896 7.02 1.48  1   6      7   8   20

Variable type: numeric 
 variable missing complete   n  mean   sd    p0  p25 median   p75  p100
      bmi       0      896 896 27.87 6.33 12.71 23.7   26.8 30.53 66.06</code></pre>
</div>
<div id="the-usual-summary-for-a-data-frame" class="section level3">
<h3><span class="header-section-number">2.4.2</span> The usual <code>summary</code> for a data frame</h3>
<p>Of course, we can use the usual <code>summary</code> to get some basic information about the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(smartcle2)</code></pre></div>
<pre><code>     SEQNO             physhealth      menthealth           genhealth  
 Min.   :2.016e+09   Min.   : 0.00   Min.   : 0.000   1_Excellent:155  
 1st Qu.:2.016e+09   1st Qu.: 0.00   1st Qu.: 0.000   2_VeryGood :306  
 Median :2.016e+09   Median : 0.00   Median : 0.000   3_Good     :295  
 Mean   :2.016e+09   Mean   : 3.99   Mean   : 2.693   4_Fair     :102  
 3rd Qu.:2.016e+09   3rd Qu.: 2.00   3rd Qu.: 2.000   5_Poor     : 38  
 Max.   :2.016e+09   Max.   :30.00   Max.   :30.000                    
      bmi            female         internet30        exerany      
 Min.   :12.71   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
 1st Qu.:23.70   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:1.0000  
 Median :26.80   Median :1.0000   Median :1.0000   Median :1.0000  
 Mean   :27.87   Mean   :0.5848   Mean   :0.8147   Mean   :0.7667  
 3rd Qu.:30.53   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  
 Max.   :66.06   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
    sleephrs         alcdays      
 Min.   : 1.000   Min.   : 0.000  
 1st Qu.: 6.000   1st Qu.: 0.000  
 Median : 7.000   Median : 1.000  
 Mean   : 7.022   Mean   : 4.834  
 3rd Qu.: 8.000   3rd Qu.: 5.000  
 Max.   :20.000   Max.   :30.000  </code></pre>
</div>
<div id="the-describe-function-in-hmisc" class="section level3">
<h3><span class="header-section-number">2.4.3</span> The <code>describe</code> function in <code>Hmisc</code></h3>
<p>Or we can use the <code>describe</code> function from the <code>Hmisc</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hmisc<span class="op">::</span><span class="kw">describe</span>(<span class="kw">select</span>(smartcle2, bmi, genhealth, female))</code></pre></div>
<pre><code>select(smartcle2, bmi, genhealth, female) 

 3  Variables      896  Observations
---------------------------------------------------------------------------
bmi 
       n  missing distinct     Info     Mean      Gmd      .05      .10 
     896        0      467        1    27.87    6.572    20.06    21.23 
     .25      .50      .75      .90      .95 
   23.70    26.80    30.53    35.36    39.30 

lowest : 12.71 13.34 14.72 16.22 17.30, highest: 56.89 57.04 60.95 61.84 66.06
---------------------------------------------------------------------------
genhealth 
       n  missing distinct 
     896        0        5 
                                                                      
Value      1_Excellent  2_VeryGood      3_Good      4_Fair      5_Poor
Frequency          155         306         295         102          38
Proportion       0.173       0.342       0.329       0.114       0.042
---------------------------------------------------------------------------
female 
       n  missing distinct     Info      Sum     Mean      Gmd 
     896        0        2    0.728      524   0.5848   0.4862 

---------------------------------------------------------------------------</code></pre>
</div>
</div>
<div id="counting-as-exploratory-data-analysis" class="section level2">
<h2><span class="header-section-number">2.5</span> Counting as exploratory data analysis</h2>
<p>Counting things can be amazingly useful.</p>
<div id="how-many-respondents-had-exercised-in-the-past-30-days-did-this-vary-by-sex" class="section level3">
<h3><span class="header-section-number">2.5.1</span> How many respondents had exercised in the past 30 days? Did this vary by sex?</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(female, exerany) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">percent =</span> <span class="dv">100</span><span class="op">*</span>n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n))</code></pre></div>
<pre><code># A tibble: 4 x 4
  female exerany     n percent
   &lt;int&gt;   &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;
1      0       0    64    7.14
2      0       1   308   34.4 
3      1       0   145   16.2 
4      1       1   379   42.3 </code></pre>
<p>so we know now that 42.3% of the subjects in our data were women who exercised. Suppose that instead we want to find the percentage of exercisers within each sex…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">count</span>(female, exerany) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(female) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">prob =</span> <span class="dv">100</span><span class="op">*</span>n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n)) </code></pre></div>
<pre><code># A tibble: 4 x 4
# Groups: female [2]
  female exerany     n  prob
   &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;
1      0       0    64  17.2
2      0       1   308  82.8
3      1       0   145  27.7
4      1       1   379  72.3</code></pre>
<p>and now we know that 82.8% of the males exercised at least once in the last 30 days, as compared to 72.3% of the females.</p>
</div>
<div id="whats-the-distribution-of-sleephrs" class="section level3">
<h3><span class="header-section-number">2.5.2</span> What’s the distribution of <code>sleephrs</code>?</h3>
<p>We can count quantitative variables with discrete sets of possible values, like <code>sleephrs</code>, which is captured as an integer (that must fall between 0 and 24.)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(sleephrs)</code></pre></div>
<pre><code># A tibble: 14 x 2
   sleephrs     n
      &lt;int&gt; &lt;int&gt;
 1        1     5
 2        2     1
 3        3     6
 4        4    20
 5        5    63
 6        6   192
 7        7   276
 8        8   266
 9        9    38
10       10    22
11       11     2
12       12     2
13       16     2
14       20     1</code></pre>
<p>Of course, a natural summary of a quantitative variable like this would be graphical.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2, <span class="kw">aes</span>(sleephrs)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">1</span>, <span class="dt">fill =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/c2_histogram_sleephrs_smartcle2-1.png" width="672" /></p>
</div>
<div id="whats-the-distribution-of-bmi" class="section level3">
<h3><span class="header-section-number">2.5.3</span> What’s the distribution of <code>BMI</code>?</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2, <span class="kw">aes</span>(bmi)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>, <span class="dt">col =</span> <span class="st">&quot;white&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/c2_histogram_bmi_smartcle2-1.png" width="672" /></p>
</div>
<div id="how-many-of-the-respondents-have-a-bmi-below-30" class="section level3">
<h3><span class="header-section-number">2.5.4</span> How many of the respondents have a BMI below 30?</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(bmi <span class="op">&lt;</span><span class="st"> </span><span class="dv">30</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">proportion =</span> n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n))</code></pre></div>
<pre><code># A tibble: 2 x 3
  `bmi &lt; 30`     n proportion
  &lt;lgl&gt;      &lt;int&gt;      &lt;dbl&gt;
1 F            253      0.282
2 T            643      0.718</code></pre>
</div>
<div id="how-many-of-the-respondents-who-have-a-bmi-30-exercised" class="section level3">
<h3><span class="header-section-number">2.5.5</span> How many of the respondents who have a BMI &lt; 30 exercised?</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(exerany, bmi <span class="op">&lt;</span><span class="st"> </span><span class="dv">30</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(exerany) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">percent =</span> <span class="dv">100</span><span class="op">*</span>n<span class="op">/</span><span class="kw">sum</span>(n))</code></pre></div>
<pre><code># A tibble: 4 x 4
# Groups: exerany [2]
  exerany `bmi &lt; 30`     n percent
    &lt;int&gt; &lt;lgl&gt;      &lt;int&gt;   &lt;dbl&gt;
1       0 F             88    42.1
2       0 T            121    57.9
3       1 F            165    24.0
4       1 T            522    76.0</code></pre>
</div>
<div id="is-obesity-associated-with-sex-in-these-data" class="section level3">
<h3><span class="header-section-number">2.5.6</span> Is obesity associated with sex, in these data?</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(female, bmi <span class="op">&lt;</span><span class="st"> </span><span class="dv">30</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(female) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">percent =</span> <span class="dv">100</span><span class="op">*</span>n<span class="op">/</span><span class="kw">sum</span>(n))</code></pre></div>
<pre><code># A tibble: 4 x 4
# Groups: female [2]
  female `bmi &lt; 30`     n percent
   &lt;int&gt; &lt;lgl&gt;      &lt;int&gt;   &lt;dbl&gt;
1      0 F            105    28.2
2      0 T            267    71.8
3      1 F            148    28.2
4      1 T            376    71.8</code></pre>
</div>
<div id="comparing-sleephrs-summaries-by-obesity-status" class="section level3">
<h3><span class="header-section-number">2.5.7</span> Comparing <code>sleephrs</code> summaries by obesity status</h3>
<p>Can we compare the <code>sleephrs</code> means, medians and 75<sup>th</sup> percentiles for respondents whose BMI is below 30 to the respondents whose BMI is not?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(bmi <span class="op">&lt;</span><span class="st"> </span><span class="dv">30</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="kw">mean</span>(sleephrs), <span class="kw">median</span>(sleephrs), 
              <span class="dt">q75 =</span> <span class="kw">quantile</span>(sleephrs, <span class="fl">0.75</span>))</code></pre></div>
<pre><code># A tibble: 2 x 4
  `bmi &lt; 30` `mean(sleephrs)` `median(sleephrs)`   q75
  &lt;lgl&gt;                 &lt;dbl&gt;              &lt;int&gt; &lt;dbl&gt;
1 F                      6.93                  7  8.00
2 T                      7.06                  7  8.00</code></pre>
</div>
<div id="the-skim-function-within-a-pipe" class="section level3">
<h3><span class="header-section-number">2.5.8</span> The <code>skim</code> function within a pipe</h3>
<p>The <strong>skim</strong> function works within pipes and with the other <code>tidyverse</code> functions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(exerany) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">skim</span>(bmi, sleephrs)</code></pre></div>
<pre><code>Skim summary statistics
 n obs: 896 
 n variables: 10 
 group variables: exerany 

Variable type: integer 
 exerany variable missing complete   n mean   sd p0 p25 median p75 p100
       0 sleephrs       0      209 209 7    1.85  1   6      7   8   20
       1 sleephrs       0      687 687 7.03 1.34  1   6      7   8   16

Variable type: numeric 
 exerany variable missing complete   n  mean   sd    p0   p25 median   p75
       0      bmi       0      209 209 29.57 7.46 18    24.11  28.49 33.13
       1      bmi       0      687 687 27.35 5.84 12.71 23.7   26.52 29.81
  p100
 66.06
 60.95</code></pre>
</div>
</div>
<div id="first-modeling-attempt-can-bmi-predict-physhealth" class="section level2">
<h2><span class="header-section-number">2.6</span> First Modeling Attempt: Can <code>bmi</code> predict <code>physhealth</code>?</h2>
<p>We’ll start with an effort to predict <code>physhealth</code> using <code>bmi</code>. A natural graph would be a scatterplot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> smartcle2, <span class="kw">aes</span>(<span class="dt">x =</span> bmi, <span class="dt">y =</span> physhealth)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/scatter_physhealth_bmi_1-1.png" width="672" /></p>
<p>A good question to ask ourselves here might be: “In what BMI range can we make a reasonable prediction of <code>physhealth</code>?”</p>
<p>Now, we might take the plot above and add a simple linear model …</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> smartcle2, <span class="kw">aes</span>(<span class="dt">x =</span> bmi, <span class="dt">y =</span> physhealth)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/c2_scatter_physhealth_bmi_2-1.png" width="672" /></p>
<p>which shows the same least squares regression model that we can fit with the <code>lm</code> command.</p>
<div id="fitting-a-simple-regression-model" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Fitting a Simple Regression Model</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_A &lt;-<span class="st"> </span><span class="kw">lm</span>(physhealth <span class="op">~</span><span class="st"> </span>bmi, <span class="dt">data =</span> smartcle2)

model_A</code></pre></div>
<pre><code>
Call:
lm(formula = physhealth ~ bmi, data = smartcle2)

Coefficients:
(Intercept)          bmi  
    -1.4514       0.1953  </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(model_A)</code></pre></div>
<pre><code>
Call:
lm(formula = physhealth ~ bmi, data = smartcle2)

Residuals:
   Min     1Q Median     3Q    Max 
-9.171 -4.057 -3.193 -1.576 28.073 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -1.45143    1.29185  -1.124    0.262    
bmi          0.19527    0.04521   4.319 1.74e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 8.556 on 894 degrees of freedom
Multiple R-squared:  0.02044,   Adjusted R-squared:  0.01934 
F-statistic: 18.65 on 1 and 894 DF,  p-value: 1.742e-05</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model_A, <span class="dt">level =</span> <span class="fl">0.95</span>)</code></pre></div>
<pre><code>                 2.5 %    97.5 %
(Intercept) -3.9868457 1.0839862
bmi          0.1065409 0.2840068</code></pre>
<p>The model coefficients can be obtained by printing the model object, and the <code>summary</code> function provides several useful descriptions of the model’s residuals, its statistical significance, and quality of fit.</p>
</div>
<div id="model-summary-for-a-simple-one-predictor-regression" class="section level3">
<h3><span class="header-section-number">2.6.2</span> Model Summary for a Simple (One-Predictor) Regression</h3>
<p>The fitted model predicts <code>physhealth</code> with the equation -1.45 + 0.195*<code>bmi</code>, as we can read off from the model coefficients.</p>
<p>Each of the 896 respondents included in the <code>smartcle2</code> data makes a contribution to this model.</p>
<div id="residuals" class="section level4">
<h4><span class="header-section-number">2.6.2.1</span> Residuals</h4>
<p>Suppose Harry is one of the people in that group, and Harry’s data is <code>bmi</code> = 20, and <code>physhealth</code> = 3.</p>
<ul>
<li>Harry’s <em>observed</em> value of <code>physhealth</code> is just the value we have in the data for them, in this case, observed <code>physhealth</code> = 3 for Harry.</li>
<li>Harry’s <em>fitted</em> or <em>predicted</em> <code>physhealth</code> value is the result of calculating -1.45 + 0.195*<code>bmi</code> for Harry. So, if Harry’s BMI was 20, then Harry’s predicted <code>physhealth</code> value is -1.45 + (0.195)(20) = 2.45.</li>
<li>The <em>residual</em> for Harry is then his <em>observed</em> outcome minus his <em>fitted</em> outcome, so Harry has a residual of 3 - 2.45 = 0.55.</li>
<li>Graphically, a residual represents vertical distance between the observed point and the fitted regression line.</li>
<li>Points above the regression line will have positive residuals, and points below the regression line will have negative residuals. Points on the line have zero residuals.</li>
</ul>
<p>The residuals are summarized at the top of the <code>summary</code> output for linear model.</p>
<ul>
<li>The mean residual will always be zero in an ordinary least squares model, but a five number summary of the residuals is provided by the summary, as is an estimated standard deviation of the residuals (called here the Residual standard error.)</li>
<li>In the <code>smartcle2</code> data, the minimum residual was -9.17, so for one subject, the observed value was 9.17 days smaller than the predicted value. This means that the prediction was 9.17 days too large for that subject.</li>
<li>Similarly, the maximum residual was 28.07 days, so for one subject the prediction was 28.07 days too small. Not a strong performance.</li>
<li>In a least squares model, the residuals are assumed to follow a Normal distribution, with mean zero, and standard deviation (for the <code>smartcle2</code> data) of about 8.6 days. Thus, by the definition of a Normal distribution, we’d expect</li>
<li>about 68% of the residuals to be between -8.6 and +8.6 days,</li>
<li>about 95% of the residuals to be between -17.2 and +17.2 days,</li>
<li>about all (99.7%) of the residuals to be between -25.8 and +25.8 days.</li>
</ul>
</div>
<div id="coefficients-section" class="section level4">
<h4><span class="header-section-number">2.6.2.2</span> Coefficients section</h4>
<p>The <code>summary</code> for a linear model shows Estimates, Standard Errors, t values and <em>p</em> values for each coefficient fit.</p>
<ul>
<li>The Estimates are the point estimates of the intercept and slope of <code>bmi</code> in our model.</li>
<li>In this case, our estimated slope is 0.195, which implies that if Harry’s BMI is 20 and Sally’s BMI is 21, we predict that Sally’s <code>physhealth</code> will be 0.195 days larger than Harry’s.</li>
<li>The Standard Errors are also provided for each estimate. We can create rough 95% confidence intervals by adding and subtracting two standard errors from each coefficient, or we can get a slightly more accurate answer with the <code>confint</code> function.</li>
<li>Here, the 95% confidence interval for the slope of <code>bmi</code> is estimated to be (0.11, 0.28). This is a good measure of the uncertainty in the slope that is captured by our model. We are 95% confident in the process of building this interval, but this doesn’t mean we’re 95% sure that the true slope is actually in that interval.</li>
</ul>
<p>Also available are a <em>t</em> value (just the Estimate divided by the Standard Error) and the appropriate <em>p</em> value for testing the null hypothesis that the true value of the coefficient is 0 against a two-tailed alternative.</p>
<ul>
<li>If a slope coefficient is statistically significantly different from 0, this implies that 0 will not be part of the uncertainty interval obtained through <code>confint</code>.</li>
<li>If the slope was zero, it would suggest that <code>bmi</code> would add no predictive value to the model. But that’s unlikely here.</li>
</ul>
<p>If the <code>bmi</code> slope coefficient is associated with a small <em>p</em> value, as in the case of our <code>model_A</code>, it suggests that the model including <code>bmi</code> is statistically significantly better at predicting <code>physhealth</code> than the model without <code>bmi</code>.</p>
<ul>
<li>Without <code>bmi</code> our <code>model_A</code> would become an <em>intercept-only</em> model, in this case, which would predict the mean <code>physhealth</code> for everyone, regardless of any other information.</li>
</ul>
</div>
<div id="model-fit-summaries" class="section level4">
<h4><span class="header-section-number">2.6.2.3</span> Model Fit Summaries</h4>
<p>The <code>summary</code> of a linear model also displays:</p>
<ul>
<li>The residual standard error and associated degrees of freedom for the residuals.</li>
<li>For a simple (one-predictor) least regression like this, the residual degrees of freedom will be the sample size minus 2.</li>
<li>The multiple R-squared (or coefficient of determination)</li>
<li>This is interpreted as the proportion of variation in the outcome (<code>physhealth</code>) accounted for by the model, and will always fall between 0 and 1 as a result.</li>
<li>Our model_A accounts for a mere 2% of the variation in <code>physhealth</code>.</li>
<li>The Adjusted R-squared value “adjusts” for the size of our model in terms of the number of coefficients included in the model.</li>
<li>The adjusted R-squared will always be less than the Multiple R-squared.</li>
<li>We still hope to find models with relatively large adjusted R<sup>2</sup> values.</li>
<li>In particular, we hope to find models where the adjusted R<sup>2</sup> isn’t substantially less than the Multiple R-squared.</li>
<li>The adjusted R-squared is usually a better estimate of likely performance of our model in new data than is the Multiple R-squared.</li>
<li>The adjusted R-squared result is no longer interpretable as a proportion of anything - in fact, it can fall below 0.</li>
<li>We can obtain the adjusted R<sup>2</sup> from the raw R<sup>2</sup>, the number of observations <em>N</em> and the number of predictors <em>p</em> included in the model, as follows:</li>
</ul>
<p><span class="math display">\[
R^2_{adj} = 1 - \frac{(1 - R^2)(N - 1)}{N - p - 1},
\]</span></p>
<ul>
<li>The F statistic and <em>p</em> value from a global ANOVA test of the model.
<ul>
<li>Obtaining a statistically significant result here is usually pretty straightforward, since the comparison is between our model, and a model which simply predicts the mean value of the outcome for everyone.</li>
<li>In a simple (one-predictor) linear regression like this, the t statistic for the slope is just the square root of the F statistic, and the resulting <em>p</em> values for the slope’s t test and for the global F test will be identical.</li>
</ul></li>
<li>To see the complete ANOVA F test for this model, we can run <code>anova(model_A)</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(model_A)</code></pre></div>
<pre><code>Analysis of Variance Table

Response: physhealth
           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
bmi         1   1366  1365.5  18.655 1.742e-05 ***
Residuals 894  65441    73.2                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
</div>
<div id="using-the-broom-package" class="section level3">
<h3><span class="header-section-number">2.6.3</span> Using the <code>broom</code> package</h3>
<p>The <code>broom</code> package has three functions of particular use in a linear regression model:</p>
<div id="the-tidy-function" class="section level4">
<h4><span class="header-section-number">2.6.3.1</span> The <code>tidy</code> function</h4>
<p><code>tidy</code> builds a data frame/tibble containing information about the coefficients in the model, their standard errors, t statistics and <em>p</em> values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(model_A)</code></pre></div>
<pre><code>         term   estimate  std.error statistic      p.value
1 (Intercept) -1.4514298 1.29185199 -1.123526 2.615156e-01
2         bmi  0.1952739 0.04521145  4.319125 1.741859e-05</code></pre>
</div>
<div id="the-glance-function" class="section level4">
<h4><span class="header-section-number">2.6.3.2</span> The <code>glance</code> function</h4>
<p>glance` builds a data frame/tibble containing summary statistics about the model, including</p>
<ul>
<li>the (raw) multiple R<sup>2</sup> and adjusted R^2</li>
<li><code>sigma</code> which is the residual standard error</li>
<li>the F <code>statistic</code>, <code>p.value</code> model <code>df</code> and <code>df.residual</code> associated with the global ANOVA test, plus</li>
<li>several statistics that will be useful in comparing models down the line:</li>
<li>the model’s log likelihood function value, <code>logLik</code></li>
<li>the model’s Akaike’s Information Criterion value, <code>AIC</code></li>
<li>the model’s Bayesian Information Criterion value, <code>BIC</code></li>
<li>and the model’s <code>deviance</code> statistic</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(model_A)</code></pre></div>
<pre><code>   r.squared adj.r.squared    sigma statistic      p.value df    logLik
1 0.02044019    0.01934449 8.555737  18.65484 1.741859e-05  2 -3193.723
       AIC     BIC deviance df.residual
1 6393.446 6407.84 65441.36         894</code></pre>
</div>
<div id="the-augment-function" class="section level4">
<h4><span class="header-section-number">2.6.3.3</span> The <code>augment</code> function</h4>
<p><code>augment</code> builds a data frame/tibble which adds fitted values, residuals and other diagnostic summaries that describe each observation to the original data used to fit the model, and this includes</p>
<ul>
<li><code>.fitted</code> and <code>.resid</code>, the fitted and residual values, in addition to</li>
<li><code>.hat</code>, the leverage value for this observation</li>
<li><code>.cooksd</code>, the Cook’s distance measure of <em>influence</em> for this observation</li>
<li><code>.stdresid</code>, the standardized residual (think of this as a z-score - a measure of the residual divided by its associated standard deviation <code>.sigma</code>)</li>
<li>and <code>se.fit</code> which will help us generate prediction intervals for the model downstream</li>
</ul>
<p>Note that each of the new columns begins with <code>.</code> to avoid overwriting any data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">augment</span>(model_A))</code></pre></div>
<pre><code>  physhealth   bmi  .fitted   .se.fit      .resid        .hat   .sigma
1          0 26.69 3.760430 0.2907252 -3.76043009 0.001154651 8.559600
2          0 23.70 3.176561 0.3422908 -3.17656119 0.001600574 8.559865
3          1 26.92 3.805343 0.2890054 -2.80534308 0.001141030 8.560010
4          0 21.66 2.778202 0.4005101 -2.77820248 0.002191352 8.560020
5          5 24.09 3.252718 0.3329154  1.74728200 0.001514095 8.560326
6          4 27.64 3.945940 0.2860087  0.05405972 0.001117490 8.560526
       .cooksd   .std.resid
1 1.117852e-04 -0.439775451
2 1.106717e-04 -0.371575999
3 6.147744e-05 -0.328077528
4 1.160381e-04 -0.325074461
5 3.167016e-05  0.204378225
6 2.235722e-08  0.006322069</code></pre>
<p>For more on the <code>broom</code> package, you may want to look at <a href="https://cran.r-project.org/web/packages/broom/vignettes/broom.html">this vignette</a>.</p>
</div>
</div>
<div id="how-does-the-model-do-residuals-vs.fitted-values" class="section level3">
<h3><span class="header-section-number">2.6.4</span> How does the model do? (Residuals vs. Fitted Values)</h3>
<ul>
<li>Remember that the R<sup>2</sup> value was about 2%.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(model_A, <span class="dt">which =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/chapter2_first_resid_plot_model_A-1.png" width="672" /></p>
<p>This is a plot of residuals vs. fitted values. The goal here is for this plot to look like a random scatter of points, perhaps like a “fuzzy football”, and that’s <strong>not</strong> what we have. Why?</p>
<p>If you prefer, here’s a <code>ggplot2</code> version of a similar plot, now looking at standardized residuals instead of raw residuals, and adding a loess smooth and a linear fit to the result.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">augment</span>(model_A), <span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .std.resid)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;loess&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">col =</span> <span class="st">&quot;navy&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/chapter2_ggplot_first_resid_plot_model_A-1.png" width="672" /></p>
<p>The problem we’re having here becomes, I think, a little more obvious if we look at what we’re predicting. Does <code>physhealth</code> look like a good candidate for a linear model?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2, <span class="kw">aes</span>(<span class="dt">x =</span> physhealth)) <span class="op">+</span>
<span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>, <span class="dt">fill =</span> <span class="st">&quot;dodgerblue&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;royalblue&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/histogram_of_physhealth_smartcle2-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">count</span>(physhealth <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, physhealth <span class="op">==</span><span class="st"> </span><span class="dv">30</span>)</code></pre></div>
<pre><code># A tibble: 3 x 3
  `physhealth == 0` `physhealth == 30`     n
  &lt;lgl&gt;             &lt;lgl&gt;              &lt;int&gt;
1 F                 F                    231
2 F                 T                     74
3 T                 F                    591</code></pre>
<p>No matter what model we fit, if we are predicting <code>physhealth</code>, and most of the data are values of 0 and 30, we have limited variation in our outcome, and so our linear model will be somewhat questionable just on that basis.</p>
<p>A normal Q-Q plot of the standardized residuals for our <code>model_A</code> shows this problem, too.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(model_A, <span class="dt">which =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/chapter2_second_resid_plot_model_A-1.png" width="672" /></p>
<p>We’re going to need a method to deal with this sort of outcome, that has both a floor and a ceiling. We’ll get there eventually, but linear regression alone doesn’t look promising.</p>
<p>All right, so that didn’t go anywhere great. Let’s try again, with a new outcome.</p>
</div>
</div>
<div id="a-new-small-study-predicting-bmi" class="section level2">
<h2><span class="header-section-number">2.7</span> A New Small Study: Predicting BMI</h2>
<p>We’ll begin by investigating the problem of predicting <code>bmi</code>, at first with just three regression inputs: <code>sex</code>, <code>exerany</code> and <code>sleephrs</code>, in our new <code>smartcle2</code> data set.</p>
<ul>
<li>The outcome of interest is <code>bmi</code>.</li>
<li>Inputs to the regression model are:
<ul>
<li><code>female</code> = 1 if the subject is female, and 0 if they are male</li>
<li><code>exerany</code> = 1 if the subject exercised in the past 30 days, and 0 if they didn’t</li>
<li><code>sleephrs</code> = hours slept in a typical 24-hour period (treated as quantitative)</li>
</ul></li>
</ul>
<div id="does-female-predict-bmi-well" class="section level3">
<h3><span class="header-section-number">2.7.1</span> Does <code>female</code> predict <code>bmi</code> well?</h3>
<div id="graphical-assessment" class="section level4">
<h4><span class="header-section-number">2.7.1.1</span> Graphical Assessment</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2, <span class="kw">aes</span>(<span class="dt">x =</span> female, <span class="dt">y =</span> bmi)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/c2_sex_bmi_plot1-1.png" width="672" /></p>
<p>Not so helpful. We should probably specify that <code>female</code> is a factor, and try another plotting approach.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(female), <span class="dt">y =</span> bmi)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/c2_sex_bmi_plot2-1.png" width="672" /></p>
<p>The median BMI looks a little higher for males. Let’s see if a model reflects that.</p>
</div>
</div>
</div>
<div id="c2_m1-a-simple-t-test-model" class="section level2">
<h2><span class="header-section-number">2.8</span> <code>c2_m1</code>: A simple t-test model</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>female, <span class="dt">data =</span> smartcle2)
c2_m1</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female, data = smartcle2)

Coefficients:
(Intercept)       female  
    28.3600      -0.8457  </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(c2_m1)</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female, data = smartcle2)

Residuals:
    Min      1Q  Median      3Q     Max 
-15.650  -4.129  -1.080   2.727  38.546 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  28.3600     0.3274  86.613   &lt;2e-16 ***
female       -0.8457     0.4282  -1.975   0.0485 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 6.315 on 894 degrees of freedom
Multiple R-squared:  0.004345,  Adjusted R-squared:  0.003231 
F-statistic: 3.902 on 1 and 894 DF,  p-value: 0.04855</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(c2_m1)</code></pre></div>
<pre><code>                2.5 %      97.5 %
(Intercept) 27.717372 29.00262801
female      -1.686052 -0.00539878</code></pre>
<p>The model suggests, based on these 896 subjects, that</p>
<ul>
<li>our best prediction for males is BMI = 28.36 kg/m<sup>2</sup>, and</li>
<li>our best prediction for females is BMI = 28.36 - 0.85 = 27.51 kg/m<sup>2</sup>.</li>
<li>the mean difference between females and males is -0.85 kg/m<sup>2</sup> in BMI</li>
<li>a 95% confidence (uncertainty) interval for that mean female - male difference in BMI ranges from -1.69 to -0.01</li>
<li>the model accounts for 0.4% of the variation in BMI, so that knowing the respondent’s sex does very little to reduce the size of the prediction errors as compared to an intercept only model that would predict the overall mean (regardless of sex) for all subjects.</li>
<li>the model makes some enormous errors, with one subject being predicted to have a BMI 38 points lower than his/her actual BMI.</li>
</ul>
<p>Note that this simple regression model just gives us the t-test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(bmi <span class="op">~</span><span class="st"> </span>female, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>, <span class="dt">data =</span> smartcle2)</code></pre></div>
<pre><code>
    Two Sample t-test

data:  bmi by female
t = 1.9752, df = 894, p-value = 0.04855
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 0.00539878 1.68605160
sample estimates:
mean in group 0 mean in group 1 
       28.36000        27.51427 </code></pre>
</div>
<div id="c2_m2-adding-another-predictor-two-way-anova-without-interaction" class="section level2">
<h2><span class="header-section-number">2.9</span> <code>c2_m2</code>: Adding another predictor (two-way ANOVA without interaction)</h2>
<p>When we add in the information about <code>exerany</code> to our original model, we might first picture the data. We could look at separate histograms,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2, <span class="kw">aes</span>(<span class="dt">x =</span> bmi)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">bins =</span> <span class="dv">30</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_grid</span>(female <span class="op">~</span><span class="st"> </span>exerany, <span class="dt">labeller =</span> label_both)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/c2_smartcle2_plot_bmi_hist_by_female_exerany-1.png" width="672" /></p>
<p>or maybe boxplots?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(female), <span class="dt">y =</span> bmi)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>exerany, <span class="dt">labeller =</span> label_both)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/c2_smartcle2_plot_bmi_box_by_female_exerany-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2, <span class="kw">aes</span>(<span class="dt">x =</span> female, <span class="dt">y =</span> bmi))<span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>exerany, <span class="dt">labeller =</span> label_both)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/c2_smartcle2_plot_bmi_points_by_female_exerany-1.png" width="672" /></p>
<p>OK. Let’s try fitting a model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>female <span class="op">+</span><span class="st"> </span>exerany, <span class="dt">data =</span> smartcle2)
c2_m2</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female + exerany, data = smartcle2)

Coefficients:
(Intercept)       female      exerany  
     30.334       -1.095       -2.384  </code></pre>
<p>This new model predicts only four predicted values:</p>
<ul>
<li><code>bmi</code> = 30.334 if the subject is male and did not exercise (so <code>female</code> = 0 and <code>exerany</code> = 0)</li>
<li><code>bmi</code> = 30.334 - 1.095 = 29.239 if the subject is female and did not exercise (<code>female</code> = 1 and <code>exerany</code> = 0)</li>
<li><code>bmi</code> = 30.334 - 2.384 = 27.950 if the subject is male and exercised (so <code>female</code> = 0 and <code>exerany</code> = 1), and, finally</li>
<li><code>bmi</code> = 30.334 - 1.095 - 2.384 = 26.855 if the subject is female and exercised (so both <code>female</code> and <code>exerany</code> = 1).</li>
</ul>
<p>For those who did not exercise, the model is:</p>
<ul>
<li><code>bmi</code> = 30.334 - 1.095 <code>female</code></li>
</ul>
<p>and for those who did exercise, the model is:</p>
<ul>
<li><code>bmi</code> = 27.95 - 1.095 <code>female</code></li>
</ul>
<p>Only the intercept of the <code>bmi-female</code> model changes depending on <code>exerany</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(c2_m2)</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female + exerany, data = smartcle2)

Residuals:
    Min      1Q  Median      3Q     Max 
-15.240  -4.091  -1.095   2.602  36.822 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  30.3335     0.5231   57.99  &lt; 2e-16 ***
female       -1.0952     0.4262   -2.57   0.0103 *  
exerany      -2.3836     0.4965   -4.80 1.86e-06 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 6.239 on 893 degrees of freedom
Multiple R-squared:  0.02939,   Adjusted R-squared:  0.02722 
F-statistic: 13.52 on 2 and 893 DF,  p-value: 1.641e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(c2_m2)</code></pre></div>
<pre><code>                2.5 %     97.5 %
(Intercept) 29.306846 31.3602182
female      -1.931629 -0.2588299
exerany     -3.358156 -1.4090777</code></pre>
<p>The slopes of both <code>female</code> and <code>exerany</code> have confidence intervals that are completely below zero, indicating that both <code>female</code> sex and <code>exerany</code> appear to be associated with reductions in <code>bmi</code>.</p>
<p>The R<sup>2</sup> value suggests that just under 3% of the variation in <code>bmi</code> is accounted for by this ANOVA model.</p>
<p>In fact, this regression (on two binary indicator variables) is simply a two-way ANOVA model without an interaction term.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(c2_m2)</code></pre></div>
<pre><code>Analysis of Variance Table

Response: bmi
           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
female      1    156  155.61  3.9977   0.04586 *  
exerany     1    897  896.93 23.0435 1.856e-06 ***
Residuals 893  34759   38.92                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="c2_m3-adding-the-interaction-term-two-way-anova-with-interaction" class="section level2">
<h2><span class="header-section-number">2.10</span> <code>c2_m3</code>: Adding the interaction term (Two-way ANOVA with interaction)</h2>
<p>Suppose we want to let the effect of <code>female</code> vary depending on the <code>exerany</code> status. Then we need to incorporate an interaction term in our model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m3 &lt;-<span class="st"> </span><span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>female <span class="op">*</span><span class="st"> </span>exerany, <span class="dt">data =</span> smartcle2)
c2_m3</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female * exerany, data = smartcle2)

Coefficients:
   (Intercept)          female         exerany  female:exerany  
       30.1359         -0.8104         -2.1450         -0.3592  </code></pre>
<p>So, for example, for a male who exercises, this model predicts</p>
<ul>
<li><code>bmi</code> = 30.136 - 0.810 (0) - 2.145 (1) - 0.359 (0)(1) = 30.136 - 2.145 = 27.991</li>
</ul>
<p>And for a female who exercises, the model predicts</p>
<ul>
<li><code>bmi</code> = 30.136 - 0.810 (1) - 2.145 (1) - 0.359 (1)(1) = 30.136 - 0.810 - 2.145 - 0.359 = 26.822</li>
</ul>
<p>For those who did not exercise, the model is:</p>
<ul>
<li><code>bmi</code> = 30.136 - 0.81 <code>female</code></li>
</ul>
<p>But for those who did exercise, the model is:</p>
<ul>
<li><code>bmi</code> = (30.136 - 2.145) + (-0.810 + (-0.359)) <code>female</code>, or ,,,</li>
<li><code>bmi</code> = 27.991 - 1.169 <code>female</code></li>
</ul>
<p>Now, both the slope and the intercept of the <code>bmi-female</code> model change depending on <code>exerany</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(c2_m3)</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female * exerany, data = smartcle2)

Residuals:
    Min      1Q  Median      3Q     Max 
-15.281  -4.101  -1.061   2.566  36.734 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     30.1359     0.7802  38.624   &lt;2e-16 ***
female          -0.8104     0.9367  -0.865   0.3872    
exerany         -2.1450     0.8575  -2.501   0.0125 *  
female:exerany  -0.3592     1.0520  -0.341   0.7328    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 6.242 on 892 degrees of freedom
Multiple R-squared:  0.02952,   Adjusted R-squared:  0.02625 
F-statistic: 9.044 on 3 and 892 DF,  p-value: 6.669e-06</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(c2_m3)</code></pre></div>
<pre><code>                   2.5 %     97.5 %
(Intercept)    28.604610 31.6672650
female         -2.648893  1.0280526
exerany        -3.827886 -0.4620407
female:exerany -2.423994  1.7055248</code></pre>
<p>In fact, this regression (on two binary indicator variables and a product term) is simply a two-way ANOVA model with an interaction term.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(c2_m3)</code></pre></div>
<pre><code>Analysis of Variance Table

Response: bmi
                Df Sum Sq Mean Sq F value    Pr(&gt;F)    
female           1    156  155.61  3.9938   0.04597 *  
exerany          1    897  896.93 23.0207 1.878e-06 ***
female:exerany   1      5    4.54  0.1166   0.73283    
Residuals      892  34754   38.96                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The interaction term doesn’t change very much here. Its uncertainty interval includes zero, and the overall model still accounts for just under 3% of the variation in <code>bmi</code>.</p>
</div>
<div id="c2_m4-using-female-and-sleephrs-in-a-model-for-bmi" class="section level2">
<h2><span class="header-section-number">2.11</span> <code>c2_m4</code>: Using <code>female</code> and <code>sleephrs</code> in a model for <code>bmi</code></h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2, <span class="kw">aes</span>(<span class="dt">x =</span> sleephrs, <span class="dt">y =</span> bmi, <span class="dt">color =</span> <span class="kw">factor</span>(female))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">guides</span>(<span class="dt">col =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>female, <span class="dt">labeller =</span> label_both) </code></pre></div>
<p><img src="bookdown-demo_files/figure-html/graph_to_set_up_c2_m4-1.png" width="672" /></p>
<p>Does the difference in slopes of <code>bmi</code> and <code>sleephrs</code> for males and females appear to be substantial and important?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m4 &lt;-<span class="st"> </span><span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>female <span class="op">*</span><span class="st"> </span>sleephrs, <span class="dt">data =</span> smartcle2)

<span class="kw">summary</span>(c2_m4)</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female * sleephrs, data = smartcle2)

Residuals:
    Min      1Q  Median      3Q     Max 
-15.498  -4.179  -1.035   2.830  38.204 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)      27.2661     1.6320  16.707   &lt;2e-16 ***
female            2.5263     2.0975   1.204    0.229    
sleephrs          0.1569     0.2294   0.684    0.494    
female:sleephrs  -0.4797     0.2931  -1.636    0.102    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 6.31 on 892 degrees of freedom
Multiple R-squared:  0.008341,  Adjusted R-squared:  0.005006 
F-statistic: 2.501 on 3 and 892 DF,  p-value: 0.05818</code></pre>
<p>Does it seem as though the addition of <code>sleephrs</code> has improved our model substantially over a model with <code>female</code> alone (which, you recall, was <code>c2_m1</code>)?</p>
<p>Since the <code>c2_m4</code> model contains the <code>c2_m1</code> model’s predictors as a subset and the outcome is the same for each model, we consider the models <em>nested</em> and have some extra tools available to compare them.</p>
<ul>
<li>I might start by looking at the basic summaries for each model.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(c2_m4)</code></pre></div>
<pre><code>    r.squared adj.r.squared    sigma statistic    p.value df    logLik
1 0.008341404   0.005006229 6.309685   2.50104 0.05818038  4 -2919.873
       AIC      BIC deviance df.residual
1 5849.747 5873.736 35512.42         892</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(c2_m1)</code></pre></div>
<pre><code>    r.squared adj.r.squared   sigma statistic    p.value df    logLik
1 0.004345169   0.003231461 6.31531  3.901534 0.04854928  2 -2921.675
      AIC      BIC deviance df.residual
1 5849.35 5863.744 35655.53         894</code></pre>
<ul>
<li>The R<sup>2</sup> is twice as large for the model with <code>sleephrs</code>, but still very tiny.</li>
<li>The <em>p</em> value for the global ANOVA test is actually less significant in <code>c2_m4</code> than in <code>c2_m1</code>.</li>
<li>Smaller AIC and smaller BIC statistics are more desirable. Here, there’s little to choose from, but <code>c2_m1</code> is a little better on each standard.</li>
<li>We might also consider a significance test by looking at an ANOVA model comparison. This is only appropriate because <code>c2_m1</code> is nested in <code>c2_m4</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(c2_m4, c2_m1)</code></pre></div>
<pre><code>Analysis of Variance Table

Model 1: bmi ~ female * sleephrs
Model 2: bmi ~ female
  Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)
1    892 35512                           
2    894 35656 -2   -143.11 1.7973 0.1663</code></pre>
<p>The addition of the <code>sleephrs</code> term picked up 143 in the sum of squares column, at a cost of two degrees of freedom, yielding a <em>p</em> value of 0.166, suggesting that this isn’t a significant improvement over the model that just did a t-test on <code>female</code>.</p>
</div>
<div id="making-predictions-with-a-linear-regression-model" class="section level2">
<h2><span class="header-section-number">2.12</span> Making Predictions with a Linear Regression Model</h2>
<p>Recall model 4, which yields predictions for body mass index on the basis of the main effects of sex (<code>female</code>) and hours of sleep (<code>sleephrs</code>) and their interaction.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m4</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female * sleephrs, data = smartcle2)

Coefficients:
    (Intercept)           female         sleephrs  female:sleephrs  
        27.2661           2.5263           0.1569          -0.4797  </code></pre>
<div id="fitting-an-individual-prediction-and-95-prediction-interval" class="section level3">
<h3><span class="header-section-number">2.12.1</span> Fitting an Individual Prediction and 95% Prediction Interval</h3>
<p>What do we predict for the <code>bmi</code> of a subject who is <code>female</code> and gets 8 hours of sleep per night?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_new1 &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">female =</span> <span class="dv">1</span>, <span class="dt">sleephrs =</span> <span class="dv">8</span>)
<span class="kw">predict</span>(c2_m4, <span class="dt">newdata =</span> c2_new1, <span class="dt">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="dt">level =</span> <span class="fl">0.95</span>)</code></pre></div>
<pre><code>       fit     lwr     upr
1 27.21065 14.8107 39.6106</code></pre>
<p>The predicted <code>bmi</code> for this new subject is 27.61. The prediction interval shows the bounds of a 95% uncertainty interval for a predicted <code>bmi</code> for an individual female subject who gets 8 hours of sleep on average per evening. From the <code>predict</code> function applied to a linear model, we can get the prediction intervals for any new data points in this manner.</p>
</div>
<div id="confidence-interval-for-an-average-prediction" class="section level3">
<h3><span class="header-section-number">2.12.2</span> Confidence Interval for an Average Prediction</h3>
<ul>
<li>What do we predict for the <strong>average body mass index of a population of subjects</strong> who are female and sleep for 8 hours?</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(c2_m4, <span class="dt">newdata =</span> c2_new1, <span class="dt">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="dt">level =</span> <span class="fl">0.95</span>)</code></pre></div>
<pre><code>       fit      lwr      upr
1 27.21065 26.57328 27.84801</code></pre>
<ul>
<li>How does this result compare to the prediction interval?</li>
</ul>
</div>
<div id="fitting-multiple-individual-predictions-to-new-data" class="section level3">
<h3><span class="header-section-number">2.12.3</span> Fitting Multiple Individual Predictions to New Data</h3>
<ul>
<li>How does our prediction change for a respondent if they instead get 7, or 9 hours of sleep? What if they are male, instead of female?</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_new2 &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">subjectid =</span> <span class="dv">1001</span><span class="op">:</span><span class="dv">1006</span>, <span class="dt">female =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">sleephrs =</span> <span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>))
pred2 &lt;-<span class="st"> </span><span class="kw">predict</span>(c2_m4, <span class="dt">newdata =</span> c2_new2, <span class="dt">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="dt">level =</span> <span class="fl">0.95</span>) <span class="op">%&gt;%</span><span class="st"> </span>tbl_df

result2 &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(c2_new2, pred2)
result2</code></pre></div>
<pre><code># A tibble: 6 x 6
  subjectid female sleephrs   fit   lwr   upr
      &lt;int&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
1      1001   1.00     7.00  27.5  15.1  39.9
2      1002   1.00     8.00  27.2  14.8  39.6
3      1003   1.00     9.00  26.9  14.5  39.3
4      1004   0        7.00  28.4  16.0  40.8
5      1005   0        8.00  28.5  16.1  40.9
6      1006   0        9.00  28.7  16.2  41.1</code></pre>
<p>The <code>result2</code> tibble contains predictions for each scenario.</p>
<ul>
<li>Which has a bigger impact on these predictions and prediction intervals? A one category change in <code>female</code> or a one hour change in <code>sleephrs</code>?</li>
</ul>
</div>
<div id="simulation-to-represent-predictive-uncertainty-in-model-4" class="section level3">
<h3><span class="header-section-number">2.12.4</span> Simulation to represent predictive uncertainty in Model 4</h3>
<p>Suppose we want to predict the <code>bmi</code> of a female subject who sleeps for eight hours per night. As we have seen, we can do this automatically for a linear model like this one, using the <code>predict</code> function applied to the linear model, but a simulation prediction can also be done. Recall the detail of <code>c2_m4</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m4</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female * sleephrs, data = smartcle2)

Coefficients:
    (Intercept)           female         sleephrs  female:sleephrs  
        27.2661           2.5263           0.1569          -0.4797  </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(c2_m4)</code></pre></div>
<pre><code>    r.squared adj.r.squared    sigma statistic    p.value df    logLik
1 0.008341404   0.005006229 6.309685   2.50104 0.05818038  4 -2919.873
       AIC      BIC deviance df.residual
1 5849.747 5873.736 35512.42         892</code></pre>
<p>We see that the residual standard error for our <code>bmi</code> predictions with this model is 6.31.</p>
<p>For a female respondent sleeping eight hours, recall that our point estimate (predicted value) of <code>bmi</code> is 27.21</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(c2_m4, <span class="dt">newdata =</span> c2_new1, <span class="dt">interval =</span> <span class="st">&quot;prediction&quot;</span>, <span class="dt">level =</span> <span class="fl">0.95</span>)</code></pre></div>
<pre><code>       fit     lwr     upr
1 27.21065 14.8107 39.6106</code></pre>
<p>The standard deviation is 6.31, so we could summarize the predictive distribution with a command that tells R to draw 1000 random numbers from a normal distribution with mean 27.21 and standard deviation 6.31. Let’s summarize that and get a quick picture.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">432094</span>)
pred.sim &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1000</span>, <span class="fl">27.21</span>, <span class="fl">6.31</span>)
<span class="kw">hist</span>(pred.sim, <span class="dt">col =</span> <span class="st">&quot;royalblue&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(pred.sim)</code></pre></div>
<pre><code>[1] 27.41856</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">quantile</span>(pred.sim, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</code></pre></div>
<pre><code>    2.5%    97.5% 
14.48487 40.16778 </code></pre>
<p>How do these results compare to the prediction interval of (14.81, 39.61) that we generated earlier?</p>
</div>
</div>
<div id="centering-the-model" class="section level2">
<h2><span class="header-section-number">2.13</span> Centering the model</h2>
<p>Our model <code>c2_m4</code> has four predictors (the constant, <code>sleephrs</code>, <code>female</code> and their interaction) but just two inputs (<code>female</code> and <code>sleephrs</code>.) If we <strong>center</strong> the quantitative input <code>sleephrs</code> before building the model, we get a more interpretable interaction term.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2_c &lt;-<span class="st"> </span>smartcle2 <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">sleephrs_c =</span> sleephrs <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(sleephrs))

c2_m4_c &lt;-<span class="st"> </span><span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>female <span class="op">*</span><span class="st"> </span>sleephrs_c, <span class="dt">data =</span> smartcle2_c)

<span class="kw">summary</span>(c2_m4_c)</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female * sleephrs_c, data = smartcle2_c)

Residuals:
    Min      1Q  Median      3Q     Max 
-15.498  -4.179  -1.035   2.830  38.204 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        28.3681     0.3274  86.658   &lt;2e-16 ***
female             -0.8420     0.4280  -1.967   0.0495 *  
sleephrs_c          0.1569     0.2294   0.684   0.4940    
female:sleephrs_c  -0.4797     0.2931  -1.636   0.1021    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 6.31 on 892 degrees of freedom
Multiple R-squared:  0.008341,  Adjusted R-squared:  0.005006 
F-statistic: 2.501 on 3 and 892 DF,  p-value: 0.05818</code></pre>
<p>What has changed as compared to the original <code>c2_m4</code>?</p>
<ul>
<li>Our original model was <code>bmi</code> = 27.26 + 2.53 <code>female</code> + 0.16 <code>sleephrs</code> - 0.48 <code>female</code> x <code>sleephrs</code></li>
<li>Our new model is <code>bmi</code> = 28.37 - 0.84 <code>female</code> + 0.16 centered <code>sleephrs</code> - 0.48 <code>female</code> x centered <code>sleephrs</code>.</li>
</ul>
<p>So our new model on centered data is:</p>
<ul>
<li>28.37 + 0.16 centered <code>sleephrs_c</code> for male subjects, and</li>
<li>(28.37 - 0.84) + (0.16 - 0.48) centered <code>sleephrs_c</code>, or 27.53 - 0.32 centered <code>sleephrs_c</code> for female subjects.</li>
</ul>
<p>In our new (centered <code>sleephrs_c</code>) model,</p>
<ul>
<li>the main effect of <code>female</code> now corresponds to a predictive difference (female - male) in <code>bmi</code> with <code>sleephrs</code> at its mean value, 7.02 hours,</li>
<li>the intercept term is now the predicted <code>bmi</code> for a male respondent who sleeps an average number of hours, and</li>
<li>the product term corresponds to the change in the slope of centered <code>sleephrs_c</code> on <code>bmi</code> for a female rather than a male subject, while</li>
<li>the residual standard deviation and the R-squared values remain unchanged from the model before centering.</li>
</ul>
<div id="plot-of-model-4-on-centered-sleephrs-c2_m4_c" class="section level3">
<h3><span class="header-section-number">2.13.1</span> Plot of Model 4 on Centered <code>sleephrs</code>: <code>c2_m4_c</code></h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2_c, <span class="kw">aes</span>(<span class="dt">x =</span> sleephrs_c, <span class="dt">y =</span> bmi, <span class="dt">group =</span> female, <span class="dt">col =</span> <span class="kw">factor</span>(female))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">guides</span>(<span class="dt">color =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Sleep Hours, centered&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Body Mass Index&quot;</span>,
         <span class="dt">title =</span> <span class="st">&quot;Model `c2_m4` on centered data&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>(<span class="op">~</span><span class="st"> </span>female, <span class="dt">labeller =</span> label_both)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
</div>
<div id="rescaling-an-input-by-subtracting-the-mean-and-dividing-by-2-standard-deviations" class="section level2">
<h2><span class="header-section-number">2.14</span> Rescaling an input by subtracting the mean and dividing by 2 standard deviations</h2>
<p>Centering helped us interpret the main effects in the regression, but it still leaves a scaling problem.</p>
<ul>
<li>The <code>female</code> coefficient estimate is much larger than that of <code>sleephrs</code>, but this is misleading, considering that we are comparing the complete change in one variable (sex = female or not) to a 1-hour change in average sleep.</li>
<li><span class="citation">Gelman and Hill (<a href="#ref-GelmanHill2007">2007</a>)</span> recommend all continuous predictors be scaled by dividing by 2 standard deviations, so that:
<ul>
<li>a 1-unit change in the rescaled predictor corresponds to a change from 1 standard deviation below the mean, to 1 standard deviation above.</li>
<li>an unscaled binary (1/0) predictor with 50% probability of occurring will be exactly comparable to a rescaled continuous predictor done in this way.</li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">smartcle2_rescale &lt;-<span class="st"> </span>smartcle2 <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">sleephrs_z =</span> (sleephrs <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(sleephrs))<span class="op">/</span>(<span class="dv">2</span><span class="op">*</span><span class="kw">sd</span>(sleephrs)))</code></pre></div>
<div id="refitting-model-c2_m4-to-the-rescaled-data" class="section level3">
<h3><span class="header-section-number">2.14.1</span> Refitting model <code>c2_m4</code> to the rescaled data</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m4_z &lt;-<span class="st"> </span><span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>female <span class="op">*</span><span class="st"> </span>sleephrs_z, <span class="dt">data =</span> smartcle2_rescale)

<span class="kw">summary</span>(c2_m4_z)</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female * sleephrs_z, data = smartcle2_rescale)

Residuals:
    Min      1Q  Median      3Q     Max 
-15.498  -4.179  -1.035   2.830  38.204 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        28.3681     0.3274  86.658   &lt;2e-16 ***
female             -0.8420     0.4280  -1.967   0.0495 *  
sleephrs_z          0.4637     0.6778   0.684   0.4940    
female:sleephrs_z  -1.4173     0.8661  -1.636   0.1021    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 6.31 on 892 degrees of freedom
Multiple R-squared:  0.008341,  Adjusted R-squared:  0.005006 
F-statistic: 2.501 on 3 and 892 DF,  p-value: 0.05818</code></pre>
</div>
<div id="interpreting-the-model-on-rescaled-data" class="section level3">
<h3><span class="header-section-number">2.14.2</span> Interpreting the model on rescaled data</h3>
<p>What has changed as compared to the original <code>c2_m4</code>?</p>
<ul>
<li>Our original model was <code>bmi</code> = 27.26 + 2.53 <code>female</code> + 0.16 <code>sleephrs</code> - 0.48 <code>female</code> x <code>sleephrs</code></li>
<li>Our model on centered <code>sleephrs</code> was <code>bmi</code> = 28.37 - 0.84 <code>female</code> + 0.16 centered <code>sleephrs_c</code> - 0.48 <code>female</code> x centered <code>sleephrs_c</code>.</li>
<li>Our new model on rescaled <code>sleephrs</code> is <code>bmi</code> = 28.37 - 0.84 <code>female</code> + 0.46 rescaled <code>sleephrs_z</code> - 1.42 <code>female</code> x rescaled <code>sleephrs_z</code>.</li>
</ul>
<p>So our rescaled model is:</p>
<ul>
<li>28.37 + 0.46 rescaled <code>sleephrs_z</code> for male subjects, and</li>
<li>(28.37 - 0.84) + (0.46 - 1.42) rescaled <code>sleephrs_z</code>, or 27.53 - 0.96 rescaled <code>sleephrs_z</code> for female subjects.</li>
</ul>
<p>In this new rescaled (<code>sleephrs_z</code>) model, then,</p>
<ul>
<li>the main effect of <code>female</code>, -0.84, still corresponds to a predictive difference (female - male) in <code>bmi</code> with <code>sleephrs</code> at its mean value, 7.02 hours,</li>
<li>the intercept term is still the predicted <code>bmi</code> for a male respondent who sleeps an average number of hours, and</li>
<li>the residual standard deviation and the R-squared values remain unchanged,</li>
</ul>
<p>as before, but now we also have that:</p>
<ul>
<li>the coefficient of <code>sleephrs_z</code> indicates the predictive difference in <code>bmi</code> associated with a change in <code>sleephrs</code> of 2 standard deviations (from one standard deviation below the mean of 7.02 to one standard deviation above 7.02.)
<ul>
<li>Since the standard deviation of <code>sleephrs</code> is 1.48, this corresponds to a change from 5.54 hours per night to 8.50 hours per night.</li>
</ul></li>
<li>the coefficient of the product term (-1.42) corresponds to the change in the coefficient of <code>sleephrs_z</code> for females as compared to males.</li>
</ul>
</div>
<div id="plot-of-model-on-rescaled-data" class="section level3">
<h3><span class="header-section-number">2.14.3</span> Plot of model on rescaled data</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(smartcle2_rescale, <span class="kw">aes</span>(<span class="dt">x =</span> sleephrs_z, <span class="dt">y =</span> bmi, 
                              <span class="dt">group =</span> female, <span class="dt">col =</span> <span class="kw">factor</span>(female))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">size =</span> <span class="fl">1.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_color_discrete</span>(<span class="dt">name =</span> <span class="st">&quot;Is subject female?&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Sleep Hours, standardized (2 sd)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Body Mass Index&quot;</span>,
         <span class="dt">title =</span> <span class="st">&quot;Model `c2_m4_z` on rescaled data&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
</div>
<div id="c2_m5-what-if-we-add-more-variables" class="section level2">
<h2><span class="header-section-number">2.15</span> <code>c2_m5</code>: What if we add more variables?</h2>
<p>We can boost our R<sup>2</sup> a bit, to over 5%, by adding in two new variables, related to whether or not the subject (in the past 30 days) used the internet, and on how many days the subject drank alcoholic beverages.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m5 &lt;-<span class="st"> </span><span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>female <span class="op">+</span><span class="st"> </span>exerany <span class="op">+</span><span class="st"> </span>sleephrs <span class="op">+</span><span class="st"> </span>internet30 <span class="op">+</span><span class="st"> </span>alcdays,
         <span class="dt">data =</span> smartcle2)
<span class="kw">summary</span>(c2_m5)</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female + exerany + sleephrs + internet30 + 
    alcdays, data = smartcle2)

Residuals:
    Min      1Q  Median      3Q     Max 
-16.147  -3.997  -0.856   2.487  35.965 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 30.84066    1.18458  26.035  &lt; 2e-16 ***
female      -1.28801    0.42805  -3.009   0.0027 ** 
exerany     -2.42161    0.49853  -4.858 1.40e-06 ***
sleephrs    -0.14118    0.13988  -1.009   0.3131    
internet30   1.38916    0.54252   2.561   0.0106 *  
alcdays     -0.10460    0.02595  -4.030 6.04e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 6.174 on 890 degrees of freedom
Multiple R-squared:  0.05258,   Adjusted R-squared:  0.04726 
F-statistic: 9.879 on 5 and 890 DF,  p-value: 3.304e-09</code></pre>
<ol style="list-style-type: decimal">
<li>Here’s the ANOVA for this model. What can we study with this?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(c2_m5)</code></pre></div>
<pre><code>Analysis of Variance Table

Response: bmi
            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
female       1    156  155.61  4.0818   0.04365 *  
exerany      1    897  896.93 23.5283 1.453e-06 ***
sleephrs     1     33   32.90  0.8631   0.35313    
internet30   1    178  178.33  4.6779   0.03082 *  
alcdays      1    619  619.26 16.2443 6.044e-05 ***
Residuals  890  33928   38.12                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Consider the revised output below. Now what can we study?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(<span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>exerany <span class="op">+</span><span class="st"> </span>internet30 <span class="op">+</span><span class="st"> </span>alcdays <span class="op">+</span><span class="st"> </span>female <span class="op">+</span><span class="st"> </span>sleephrs,
         <span class="dt">data =</span> smartcle2))</code></pre></div>
<pre><code>Analysis of Variance Table

Response: bmi
            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
exerany      1    795  795.46 20.8664 5.618e-06 ***
internet30   1    212  211.95  5.5599 0.0185925 *  
alcdays      1    486  486.03 12.7496 0.0003752 ***
female       1    351  350.75  9.2010 0.0024891 ** 
sleephrs     1     39   38.83  1.0186 0.3131176    
Residuals  890  33928   38.12                      
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>What does the output below let us conclude?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(<span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>exerany <span class="op">+</span><span class="st"> </span>internet30 <span class="op">+</span><span class="st"> </span>alcdays <span class="op">+</span><span class="st"> </span>female <span class="op">+</span><span class="st"> </span>sleephrs, 
         <span class="dt">data =</span> smartcle2),
      <span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>exerany <span class="op">+</span><span class="st"> </span>female <span class="op">+</span><span class="st"> </span>alcdays, 
         <span class="dt">data =</span> smartcle2))</code></pre></div>
<pre><code>Analysis of Variance Table

Model 1: bmi ~ exerany + internet30 + alcdays + female + sleephrs
Model 2: bmi ~ exerany + female + alcdays
  Res.Df   RSS Df Sum of Sq      F  Pr(&gt;F)  
1    890 33928                              
2    892 34221 -2    -293.2 3.8456 0.02173 *
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>What does it mean for the models to be “nested”?</li>
</ol>
</div>
<div id="c2_m6-would-adding-self-reported-health-help" class="section level2">
<h2><span class="header-section-number">2.16</span> <code>c2_m6</code>: Would adding self-reported health help?</h2>
<p>And we can do even a bit better than that by adding in a multi-categorical measure: self-reported general health.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m6 &lt;-<span class="st"> </span><span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>female <span class="op">+</span><span class="st"> </span>exerany <span class="op">+</span><span class="st"> </span>sleephrs <span class="op">+</span><span class="st"> </span>internet30 <span class="op">+</span><span class="st"> </span>alcdays <span class="op">+</span><span class="st"> </span>genhealth,
         <span class="dt">data =</span> smartcle2)
<span class="kw">summary</span>(c2_m6)</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female + exerany + sleephrs + internet30 + 
    alcdays + genhealth, data = smartcle2)

Residuals:
    Min      1Q  Median      3Q     Max 
-16.331  -3.813  -0.838   2.679  34.166 

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         26.49498    1.31121  20.206  &lt; 2e-16 ***
female              -0.85520    0.41969  -2.038 0.041879 *  
exerany             -1.61968    0.50541  -3.205 0.001400 ** 
sleephrs            -0.12719    0.13613  -0.934 0.350368    
internet30           2.02498    0.53898   3.757 0.000183 ***
alcdays             -0.08431    0.02537  -3.324 0.000925 ***
genhealth2_VeryGood  2.10537    0.59408   3.544 0.000415 ***
genhealth3_Good      4.08245    0.60739   6.721 3.22e-11 ***
genhealth4_Fair      4.99213    0.80178   6.226 7.37e-10 ***
genhealth5_Poor      3.11025    1.12614   2.762 0.005866 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 5.993 on 886 degrees of freedom
Multiple R-squared:  0.1115,    Adjusted R-squared:  0.1024 
F-statistic: 12.35 on 9 and 886 DF,  p-value: &lt; 2.2e-16</code></pre>
<ol style="list-style-type: decimal">
<li><p>If Harry and Marty have the same values of <code>female</code>, <code>exerany</code>, <code>sleephrs</code>, <code>internet30</code> and <code>alcdays</code>, but Harry rates his health as Good, and Marty rates his as Fair, then what is the difference in the predictions? Who is predicted to have a larger BMI, and by how much?</p></li>
<li><p>What does this normal probability plot of the residuals suggest?</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(c2_m6, <span class="dt">which =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/c2_m6_residuals_normality-1.png" width="672" /></p>
</div>
<div id="c2_m7-what-if-we-added-days-of-work-missed" class="section level2">
<h2><span class="header-section-number">2.17</span> <code>c2_m7</code>: What if we added days of work missed?</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">c2_m7 &lt;-<span class="st"> </span><span class="kw">lm</span>(bmi <span class="op">~</span><span class="st"> </span>female <span class="op">+</span><span class="st"> </span>exerany <span class="op">+</span><span class="st"> </span>sleephrs <span class="op">+</span><span class="st"> </span>internet30 <span class="op">+</span><span class="st"> </span>alcdays <span class="op">+</span><span class="st"> </span>
<span class="st">                </span>genhealth <span class="op">+</span><span class="st"> </span>physhealth <span class="op">+</span><span class="st"> </span>menthealth,
         <span class="dt">data =</span> smartcle2)
<span class="kw">summary</span>(c2_m7)</code></pre></div>
<pre><code>
Call:
lm(formula = bmi ~ female + exerany + sleephrs + internet30 + 
    alcdays + genhealth + physhealth + menthealth, data = smartcle2)

Residuals:
    Min      1Q  Median      3Q     Max 
-16.060  -3.804  -0.890   2.794  33.972 

Coefficients:
                    Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         25.88208    1.31854  19.629  &lt; 2e-16 ***
female              -0.96435    0.41908  -2.301 0.021616 *  
exerany             -1.43171    0.50635  -2.828 0.004797 ** 
sleephrs            -0.08033    0.13624  -0.590 0.555583    
internet30           2.00267    0.53759   3.725 0.000207 ***
alcdays             -0.07997    0.02528  -3.163 0.001614 ** 
genhealth2_VeryGood  2.09533    0.59238   3.537 0.000425 ***
genhealth3_Good      3.90949    0.60788   6.431 2.07e-10 ***
genhealth4_Fair      4.27152    0.83986   5.086 4.47e-07 ***
genhealth5_Poor      1.26021    1.31556   0.958 0.338361    
physhealth           0.06088    0.03005   2.026 0.043064 *  
menthealth           0.06636    0.03177   2.089 0.037021 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 5.964 on 884 degrees of freedom
Multiple R-squared:  0.1219,    Adjusted R-squared:  0.111 
F-statistic: 11.16 on 11 and 884 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="key-regression-assumptions-for-building-effective-prediction-models" class="section level2">
<h2><span class="header-section-number">2.18</span> Key Regression Assumptions for Building Effective Prediction Models</h2>
<ol style="list-style-type: decimal">
<li>Validity - the data you are analyzing should map to the research question you are trying to answer.
<ul>
<li>The outcome should accurately reflect the phenomenon of interest.</li>
<li>The model should include all relevant predictors. (It can be difficult to decide which predictors are necessary, and what to do with predictors that have large standard errors.)</li>
<li>The model should generalize to all of the cases to which it will be applied.</li>
<li>Can the available data answer our question reliably?</li>
</ul></li>
<li>Additivity and linearity - most important assumption of a regression model is that its deterministic component is a linear function of the predictors. We often think about transformations in this setting.</li>
<li>Independence of errors - errors from the prediction line are independent of each other</li>
<li>Equal variance of errors - if this is violated, we can more efficiently estimate paramaters using <em>weighted least squares</em> approaches, where each point is weighted inversely proportional to its variance, but this doesn’t affect the coefficients much, if at all.</li>
<li>Normality of errors - not generally important for estimating the regression line</li>
</ol>
<div id="checking-assumptions-in-model-c2_m7" class="section level3">
<h3><span class="header-section-number">2.18.1</span> Checking Assumptions in model <code>c2_m7</code></h3>
<ol style="list-style-type: decimal">
<li>How does the assumption of linearity behind this model look?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(c2_m7, <span class="dt">which =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/residual_plot1_c2_m7-1.png" width="672" /></p>
<p>We see no strong signs of serious non-linearity here. There’s no obvious curve in the plot, for example.</p>
<ol start="2" style="list-style-type: decimal">
<li>What can we conclude from the plot below?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(c2_m7, <span class="dt">which =</span> <span class="dv">5</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/residual_plot5_c2_m7-1.png" width="672" /></p>
<p>This plot can help us identify points with large standardized residuals, large leverage values, and large influence on the model (as indicated by large values of Cook’s distance.) In this case, I see no signs of any points used in the model with especially large influence, although there are some poorly fitted points (with especially large standardized residuals.)</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-GelmanHill2007">
<p>Gelman, Andrew, and Jennifer Hill. 2007. <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em>. New York: Cambridge University Press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="building-table-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analysis-of-variance-and-analysis-of-covariance.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-smartcle1_linear.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
