<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Data Science for Biological, Medical and Health Research: Notes for 432</title>
  <meta name="description" content="These are the Course Notes for 432.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Data Science for Biological, Medical and Health Research: Notes for 432" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are the Course Notes for 432." />
  <meta name="github-repo" content="thomaselove/432-notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Science for Biological, Medical and Health Research: Notes for 432" />
  
  <meta name="twitter:description" content="These are the Course Notes for 432." />
  

<meta name="author" content="Thomas E. Love, Ph.D.">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="logistic-regression-the-foundations.html">
<link rel="next" href="logistic-regression-and-the-smartcle1-data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">432 Course Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="r-packages-used-in-these-notes.html"><a href="r-packages-used-in-these-notes.html"><i class="fa fa-check"></i>R Packages used in these notes</a></li>
<li class="chapter" data-level="" data-path="data-used-in-these-notes.html"><a href="data-used-in-these-notes.html"><i class="fa fa-check"></i>Data used in these notes</a></li>
<li class="chapter" data-level="" data-path="special-functions-used-in-these-notes.html"><a href="special-functions-used-in-these-notes.html"><i class="fa fa-check"></i>Special Functions used in these notes</a></li>
<li class="chapter" data-level="1" data-path="building-table-1.html"><a href="building-table-1.html"><i class="fa fa-check"></i><b>1</b> Building Table 1</a><ul>
<li class="chapter" data-level="1.1" data-path="building-table-1.html"><a href="building-table-1.html#two-examples-from-the-new-england-journal-of-medicine"><i class="fa fa-check"></i><b>1.1</b> Two examples from the <em>New England Journal of Medicine</em></a><ul>
<li class="chapter" data-level="1.1.1" data-path="building-table-1.html"><a href="building-table-1.html#a-simple-table-1"><i class="fa fa-check"></i><b>1.1.1</b> A simple Table 1</a></li>
<li class="chapter" data-level="1.1.2" data-path="building-table-1.html"><a href="building-table-1.html#a-group-comparison"><i class="fa fa-check"></i><b>1.1.2</b> A group comparison</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="building-table-1.html"><a href="building-table-1.html#the-mr-clean-trial"><i class="fa fa-check"></i><b>1.2</b> The MR CLEAN trial</a></li>
<li class="chapter" data-level="1.3" data-path="building-table-1.html"><a href="building-table-1.html#simulated-fakestroke-data"><i class="fa fa-check"></i><b>1.3</b> Simulated <code>fakestroke</code> data</a></li>
<li class="chapter" data-level="1.4" data-path="building-table-1.html"><a href="building-table-1.html#building-table-1-for-fakestroke-attempt-1"><i class="fa fa-check"></i><b>1.4</b> Building Table 1 for <code>fakestroke</code>: Attempt 1</a><ul>
<li class="chapter" data-level="1.4.1" data-path="building-table-1.html"><a href="building-table-1.html#some-of-this-is-very-useful-and-other-parts-need-to-be-fixed."><i class="fa fa-check"></i><b>1.4.1</b> Some of this is very useful, and other parts need to be fixed.</a></li>
<li class="chapter" data-level="1.4.2" data-path="building-table-1.html"><a href="building-table-1.html#fakestroke-cleaning-up-categorical-variables"><i class="fa fa-check"></i><b>1.4.2</b> <code>fakestroke</code> Cleaning Up Categorical Variables</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="building-table-1.html"><a href="building-table-1.html#fakestroke-table-1-attempt-2"><i class="fa fa-check"></i><b>1.5</b> <code>fakestroke</code> Table 1: Attempt 2</a><ul>
<li class="chapter" data-level="1.5.1" data-path="building-table-1.html"><a href="building-table-1.html#what-summaries-should-we-show"><i class="fa fa-check"></i><b>1.5.1</b> What summaries should we show?</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="building-table-1.html"><a href="building-table-1.html#obtaining-a-more-detailed-summary"><i class="fa fa-check"></i><b>1.6</b> Obtaining a more detailed Summary</a></li>
<li class="chapter" data-level="1.7" data-path="building-table-1.html"><a href="building-table-1.html#exporting-the-completed-table-1-from-r-to-excel-or-word"><i class="fa fa-check"></i><b>1.7</b> Exporting the Completed Table 1 from R to Excel or Word</a><ul>
<li class="chapter" data-level="1.7.1" data-path="building-table-1.html"><a href="building-table-1.html#approach-a-save-and-open-in-excel"><i class="fa fa-check"></i><b>1.7.1</b> Approach A: Save and open in Excel</a></li>
<li class="chapter" data-level="1.7.2" data-path="building-table-1.html"><a href="building-table-1.html#approach-b-produce-the-table-so-you-can-cut-and-paste-it"><i class="fa fa-check"></i><b>1.7.2</b> Approach B: Produce the Table so you can cut and paste it</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="building-table-1.html"><a href="building-table-1.html#a-controlled-biological-experiment---the-blood-brain-barrier"><i class="fa fa-check"></i><b>1.8</b> A Controlled Biological Experiment - The Blood-Brain Barrier</a></li>
<li class="chapter" data-level="1.9" data-path="building-table-1.html"><a href="building-table-1.html#the-bloodbrain.csv-file"><i class="fa fa-check"></i><b>1.9</b> The <code>bloodbrain.csv</code> file</a></li>
<li class="chapter" data-level="1.10" data-path="building-table-1.html"><a href="building-table-1.html#a-table-1-for-bloodbrain"><i class="fa fa-check"></i><b>1.10</b> A Table 1 for <code>bloodbrain</code></a><ul>
<li class="chapter" data-level="1.10.1" data-path="building-table-1.html"><a href="building-table-1.html#generate-final-table-1-for-bloodbrain"><i class="fa fa-check"></i><b>1.10.1</b> Generate final Table 1 for <code>bloodbrain</code></a></li>
<li class="chapter" data-level="1.10.2" data-path="building-table-1.html"><a href="building-table-1.html#a-more-finished-version-after-cleanup-in-word"><i class="fa fa-check"></i><b>1.10.2</b> A More Finished Version (after Cleanup in Word)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html"><i class="fa fa-check"></i><b>2</b> Linear Regression on a small SMART data set</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#brfss-and-smart"><i class="fa fa-check"></i><b>2.1</b> BRFSS and SMART</a><ul>
<li class="chapter" data-level="2.1.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#key-resources"><i class="fa fa-check"></i><b>2.1.1</b> Key resources</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-smartcle1-data-cookbook"><i class="fa fa-check"></i><b>2.2</b> The <code>smartcle1</code> data: Cookbook</a></li>
<li class="chapter" data-level="2.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#smartcle2-omitting-missing-observations-complete-case-analyses"><i class="fa fa-check"></i><b>2.3</b> <code>smartcle2</code>: Omitting Missing Observations: Complete-Case Analyses</a></li>
<li class="chapter" data-level="2.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#summarizing-the-smartcle2-data-numerically"><i class="fa fa-check"></i><b>2.4</b> Summarizing the <code>smartcle2</code> data numerically</a><ul>
<li class="chapter" data-level="2.4.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-new-toy-the-skim-function"><i class="fa fa-check"></i><b>2.4.1</b> The New Toy: The <code>skim</code> function</a></li>
<li class="chapter" data-level="2.4.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-usual-summary-for-a-data-frame"><i class="fa fa-check"></i><b>2.4.2</b> The usual <code>summary</code> for a data frame</a></li>
<li class="chapter" data-level="2.4.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-describe-function-in-hmisc"><i class="fa fa-check"></i><b>2.4.3</b> The <code>describe</code> function in <code>Hmisc</code></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#counting-as-exploratory-data-analysis"><i class="fa fa-check"></i><b>2.5</b> Counting as exploratory data analysis</a><ul>
<li class="chapter" data-level="2.5.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-respondents-had-exercised-in-the-past-30-days-did-this-vary-by-sex"><i class="fa fa-check"></i><b>2.5.1</b> How many respondents had exercised in the past 30 days? Did this vary by sex?</a></li>
<li class="chapter" data-level="2.5.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#whats-the-distribution-of-sleephrs"><i class="fa fa-check"></i><b>2.5.2</b> What’s the distribution of <code>sleephrs</code>?</a></li>
<li class="chapter" data-level="2.5.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#whats-the-distribution-of-bmi"><i class="fa fa-check"></i><b>2.5.3</b> What’s the distribution of <code>BMI</code>?</a></li>
<li class="chapter" data-level="2.5.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-of-the-respondents-have-a-bmi-below-30"><i class="fa fa-check"></i><b>2.5.4</b> How many of the respondents have a BMI below 30?</a></li>
<li class="chapter" data-level="2.5.5" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-many-of-the-respondents-who-have-a-bmi-30-exercised"><i class="fa fa-check"></i><b>2.5.5</b> How many of the respondents who have a BMI &lt; 30 exercised?</a></li>
<li class="chapter" data-level="2.5.6" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#is-obesity-associated-with-sex-in-these-data"><i class="fa fa-check"></i><b>2.5.6</b> Is obesity associated with sex, in these data?</a></li>
<li class="chapter" data-level="2.5.7" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#comparing-sleephrs-summaries-by-obesity-status"><i class="fa fa-check"></i><b>2.5.7</b> Comparing <code>sleephrs</code> summaries by obesity status</a></li>
<li class="chapter" data-level="2.5.8" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#the-skim-function-within-a-pipe"><i class="fa fa-check"></i><b>2.5.8</b> The <code>skim</code> function within a pipe</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#first-modeling-attempt-can-bmi-predict-physhealth"><i class="fa fa-check"></i><b>2.6</b> First Modeling Attempt: Can <code>bmi</code> predict <code>physhealth</code>?</a><ul>
<li class="chapter" data-level="2.6.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-a-simple-regression-model"><i class="fa fa-check"></i><b>2.6.1</b> Fitting a Simple Regression Model</a></li>
<li class="chapter" data-level="2.6.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#model-summary-for-a-simple-one-predictor-regression"><i class="fa fa-check"></i><b>2.6.2</b> Model Summary for a Simple (One-Predictor) Regression</a></li>
<li class="chapter" data-level="2.6.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#using-the-broom-package"><i class="fa fa-check"></i><b>2.6.3</b> Using the <code>broom</code> package</a></li>
<li class="chapter" data-level="2.6.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#how-does-the-model-do-residuals-vs.fitted-values"><i class="fa fa-check"></i><b>2.6.4</b> How does the model do? (Residuals vs. Fitted Values)</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#a-new-small-study-predicting-bmi"><i class="fa fa-check"></i><b>2.7</b> A New Small Study: Predicting BMI</a><ul>
<li class="chapter" data-level="2.7.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#does-female-predict-bmi-well"><i class="fa fa-check"></i><b>2.7.1</b> Does <code>female</code> predict <code>bmi</code> well?</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m1-a-simple-t-test-model"><i class="fa fa-check"></i><b>2.8</b> <code>c2_m1</code>: A simple t-test model</a></li>
<li class="chapter" data-level="2.9" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m2-adding-another-predictor-two-way-anova-without-interaction"><i class="fa fa-check"></i><b>2.9</b> <code>c2_m2</code>: Adding another predictor (two-way ANOVA without interaction)</a></li>
<li class="chapter" data-level="2.10" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m3-adding-the-interaction-term-two-way-anova-with-interaction"><i class="fa fa-check"></i><b>2.10</b> <code>c2_m3</code>: Adding the interaction term (Two-way ANOVA with interaction)</a></li>
<li class="chapter" data-level="2.11" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m4-using-female-and-sleephrs-in-a-model-for-bmi"><i class="fa fa-check"></i><b>2.11</b> <code>c2_m4</code>: Using <code>female</code> and <code>sleephrs</code> in a model for <code>bmi</code></a></li>
<li class="chapter" data-level="2.12" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#making-predictions-with-a-linear-regression-model"><i class="fa fa-check"></i><b>2.12</b> Making Predictions with a Linear Regression Model</a><ul>
<li class="chapter" data-level="2.12.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-an-individual-prediction-and-95-prediction-interval"><i class="fa fa-check"></i><b>2.12.1</b> Fitting an Individual Prediction and 95% Prediction Interval</a></li>
<li class="chapter" data-level="2.12.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#confidence-interval-for-an-average-prediction"><i class="fa fa-check"></i><b>2.12.2</b> Confidence Interval for an Average Prediction</a></li>
<li class="chapter" data-level="2.12.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#fitting-multiple-individual-predictions-to-new-data"><i class="fa fa-check"></i><b>2.12.3</b> Fitting Multiple Individual Predictions to New Data</a></li>
<li class="chapter" data-level="2.12.4" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#simulation-to-represent-predictive-uncertainty-in-model-4"><i class="fa fa-check"></i><b>2.12.4</b> Simulation to represent predictive uncertainty in Model 4</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#centering-the-model"><i class="fa fa-check"></i><b>2.13</b> Centering the model</a><ul>
<li class="chapter" data-level="2.13.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#plot-of-model-4-on-centered-sleephrs-c2_m4_c"><i class="fa fa-check"></i><b>2.13.1</b> Plot of Model 4 on Centered <code>sleephrs</code>: <code>c2_m4_c</code></a></li>
</ul></li>
<li class="chapter" data-level="2.14" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#rescaling-an-input-by-subtracting-the-mean-and-dividing-by-2-standard-deviations"><i class="fa fa-check"></i><b>2.14</b> Rescaling an input by subtracting the mean and dividing by 2 standard deviations</a><ul>
<li class="chapter" data-level="2.14.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#refitting-model-c2_m4-to-the-rescaled-data"><i class="fa fa-check"></i><b>2.14.1</b> Refitting model <code>c2_m4</code> to the rescaled data</a></li>
<li class="chapter" data-level="2.14.2" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#interpreting-the-model-on-rescaled-data"><i class="fa fa-check"></i><b>2.14.2</b> Interpreting the model on rescaled data</a></li>
<li class="chapter" data-level="2.14.3" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#plot-of-model-on-rescaled-data"><i class="fa fa-check"></i><b>2.14.3</b> Plot of model on rescaled data</a></li>
</ul></li>
<li class="chapter" data-level="2.15" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m5-what-if-we-add-more-variables"><i class="fa fa-check"></i><b>2.15</b> <code>c2_m5</code>: What if we add more variables?</a></li>
<li class="chapter" data-level="2.16" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m6-would-adding-self-reported-health-help"><i class="fa fa-check"></i><b>2.16</b> <code>c2_m6</code>: Would adding self-reported health help?</a></li>
<li class="chapter" data-level="2.17" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#c2_m7-what-if-we-added-the-menthealth-variable"><i class="fa fa-check"></i><b>2.17</b> <code>c2_m7</code>: What if we added the <code>menthealth</code> variable?</a></li>
<li class="chapter" data-level="2.18" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#key-regression-assumptions-for-building-effective-prediction-models"><i class="fa fa-check"></i><b>2.18</b> Key Regression Assumptions for Building Effective Prediction Models</a><ul>
<li class="chapter" data-level="2.18.1" data-path="linear-regression-on-a-small-smart-data-set.html"><a href="linear-regression-on-a-small-smart-data-set.html#checking-assumptions-in-model-c2_m7"><i class="fa fa-check"></i><b>2.18.1</b> Checking Assumptions in model <code>c2_m7</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>3</b> Analysis of Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-bonding-data-a-designed-dental-experiment"><i class="fa fa-check"></i><b>3.1</b> The <code>bonding</code> data: A Designed Dental Experiment</a></li>
<li class="chapter" data-level="3.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-one-factor-analysis-of-variance"><i class="fa fa-check"></i><b>3.2</b> A One-Factor Analysis of Variance</a><ul>
<li class="chapter" data-level="3.2.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#look-at-the-data"><i class="fa fa-check"></i><b>3.2.1</b> Look at the Data!</a></li>
<li class="chapter" data-level="3.2.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#table-of-summary-statistics"><i class="fa fa-check"></i><b>3.2.2</b> Table of Summary Statistics</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-two-way-anova-looking-at-two-factors"><i class="fa fa-check"></i><b>3.3</b> A Two-Way ANOVA: Looking at Two Factors</a></li>
<li class="chapter" data-level="3.4" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-means-plot-with-standard-deviations-to-check-for-interaction"><i class="fa fa-check"></i><b>3.4</b> A Means Plot (with standard deviations) to check for interaction</a><ul>
<li class="chapter" data-level="3.4.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#skimming-the-data-after-grouping-by-resin-and-light"><i class="fa fa-check"></i><b>3.4.1</b> Skimming the data after grouping by <code>resin</code> and <code>light</code></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#fitting-the-two-way-anova-model-with-interaction"><i class="fa fa-check"></i><b>3.5</b> Fitting the Two-Way ANOVA model with Interaction</a><ul>
<li class="chapter" data-level="3.5.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-anova-table-for-our-model"><i class="fa fa-check"></i><b>3.5.1</b> The ANOVA table for our model</a></li>
<li class="chapter" data-level="3.5.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#is-the-interaction-important"><i class="fa fa-check"></i><b>3.5.2</b> Is the interaction important?</a></li>
<li class="chapter" data-level="3.5.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#interpreting-the-interaction"><i class="fa fa-check"></i><b>3.5.3</b> Interpreting the Interaction</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#comparing-individual-combinations-of-resin-and-light"><i class="fa fa-check"></i><b>3.6</b> Comparing Individual Combinations of <code>resin</code> and <code>light</code></a></li>
<li class="chapter" data-level="3.7" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-bonding-model-without-interaction"><i class="fa fa-check"></i><b>3.7</b> The <code>bonding</code> model without Interaction</a></li>
<li class="chapter" data-level="3.8" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#cortisol-a-hypothetical-clinical-trial"><i class="fa fa-check"></i><b>3.8</b> <code>cortisol</code>: A Hypothetical Clinical Trial</a><ul>
<li class="chapter" data-level="3.8.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#codebook-and-raw-data-for-cortisol"><i class="fa fa-check"></i><b>3.8.1</b> Codebook and Raw Data for <code>cortisol</code></a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#creating-a-factor-combining-sex-and-waist"><i class="fa fa-check"></i><b>3.9</b> Creating a factor combining sex and waist</a></li>
<li class="chapter" data-level="3.10" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-means-plot-for-the-cortisol-trial-with-standard-errors"><i class="fa fa-check"></i><b>3.10</b> A Means Plot for the <code>cortisol</code> trial (with standard errors)</a></li>
<li class="chapter" data-level="3.11" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-two-way-anova-model-for-cortisol-with-interaction"><i class="fa fa-check"></i><b>3.11</b> A Two-Way ANOVA model for <code>cortisol</code> with Interaction</a></li>
<li class="chapter" data-level="3.12" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#a-two-way-anova-model-for-cortisol-without-interaction"><i class="fa fa-check"></i><b>3.12</b> A Two-Way ANOVA model for <code>cortisol</code> without Interaction</a><ul>
<li class="chapter" data-level="3.12.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-graph"><i class="fa fa-check"></i><b>3.12.1</b> The Graph</a></li>
<li class="chapter" data-level="3.12.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-anova-model"><i class="fa fa-check"></i><b>3.12.2</b> The ANOVA Model</a></li>
<li class="chapter" data-level="3.12.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#the-regression-summary"><i class="fa fa-check"></i><b>3.12.3</b> The Regression Summary</a></li>
<li class="chapter" data-level="3.12.4" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#tukey-hsd-comparisons"><i class="fa fa-check"></i><b>3.12.4</b> Tukey HSD Comparisons</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html"><i class="fa fa-check"></i><b>4</b> Analysis of Covariance</a><ul>
<li class="chapter" data-level="4.1" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#an-emphysema-study"><i class="fa fa-check"></i><b>4.1</b> An Emphysema Study</a><ul>
<li class="chapter" data-level="4.1.1" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#codebook"><i class="fa fa-check"></i><b>4.1.1</b> Codebook</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#does-sex-affect-the-mean-change-in-theophylline"><i class="fa fa-check"></i><b>4.2</b> Does <code>sex</code> affect the mean change in theophylline?</a></li>
<li class="chapter" data-level="4.3" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#is-there-an-association-between-age-and-sex-in-this-study"><i class="fa fa-check"></i><b>4.3</b> Is there an association between <code>age</code> and <code>sex</code> in this study?</a></li>
<li class="chapter" data-level="4.4" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#adding-a-quantitative-covariate-age-to-the-model"><i class="fa fa-check"></i><b>4.4</b> Adding a quantitative covariate, <code>age</code>, to the model</a><ul>
<li class="chapter" data-level="4.4.1" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#the-ancova-model"><i class="fa fa-check"></i><b>4.4.1</b> The ANCOVA model</a></li>
<li class="chapter" data-level="4.4.2" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#the-ancova-table"><i class="fa fa-check"></i><b>4.4.2</b> The ANCOVA Table</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#rerunning-the-ancova-model-after-simple-imputation"><i class="fa fa-check"></i><b>4.5</b> Rerunning the ANCOVA model after simple imputation</a></li>
<li class="chapter" data-level="4.6" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#looking-at-a-factor-covariate-interaction"><i class="fa fa-check"></i><b>4.6</b> Looking at a factor-covariate interaction</a></li>
<li class="chapter" data-level="4.7" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html#centering-the-covariate-to-facilitate-ancova-interpretation"><i class="fa fa-check"></i><b>4.7</b> Centering the Covariate to Facilitate ANCOVA Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html"><i class="fa fa-check"></i><b>5</b> Missing Data Mechanisms and Single Imputation</a><ul>
<li class="chapter" data-level="5.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#a-toy-example"><i class="fa fa-check"></i><b>5.1</b> A Toy Example</a><ul>
<li class="chapter" data-level="5.1.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#how-many-missing-values-do-we-have-in-each-column"><i class="fa fa-check"></i><b>5.1.1</b> How many missing values do we have in each column?</a></li>
<li class="chapter" data-level="5.1.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#what-is-the-pattern-of-missing-data"><i class="fa fa-check"></i><b>5.1.2</b> What is the pattern of missing data?</a></li>
<li class="chapter" data-level="5.1.3" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#how-can-we-identify-the-subjects-with-missing-data"><i class="fa fa-check"></i><b>5.1.3</b> How can we identify the subjects with missing data?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#missing-data-mechanisms"><i class="fa fa-check"></i><b>5.2</b> Missing-data mechanisms</a></li>
<li class="chapter" data-level="5.3" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#options-for-dealing-with-missingness"><i class="fa fa-check"></i><b>5.3</b> Options for Dealing with Missingness</a></li>
<li class="chapter" data-level="5.4" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#complete-case-and-available-case-analyses"><i class="fa fa-check"></i><b>5.4</b> Complete Case (and Available Case) analyses</a></li>
<li class="chapter" data-level="5.5" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#single-imputation"><i class="fa fa-check"></i><b>5.5</b> Single Imputation</a></li>
<li class="chapter" data-level="5.6" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#multiple-imputation"><i class="fa fa-check"></i><b>5.6</b> Multiple Imputation</a></li>
<li class="chapter" data-level="5.7" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#building-a-complete-case-analysis"><i class="fa fa-check"></i><b>5.7</b> Building a Complete Case Analysis</a></li>
<li class="chapter" data-level="5.8" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#single-imputation-with-the-mean-or-mode"><i class="fa fa-check"></i><b>5.8</b> Single Imputation with the Mean or Mode</a></li>
<li class="chapter" data-level="5.9" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#doing-single-imputation-with-simputation"><i class="fa fa-check"></i><b>5.9</b> Doing Single Imputation with <code>simputation</code></a><ul>
<li class="chapter" data-level="5.9.1" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#mirroring-our-prior-approach-imputing-meansmediansmodes"><i class="fa fa-check"></i><b>5.9.1</b> Mirroring Our Prior Approach (imputing means/medians/modes)</a></li>
<li class="chapter" data-level="5.9.2" data-path="missing-data-mechanisms-and-single-imputation.html"><a href="missing-data-mechanisms-and-single-imputation.html#using-a-model-to-impute-sbp.before-and-diabetes"><i class="fa fa-check"></i><b>5.9.2</b> Using a model to impute <code>sbp.before</code> and <code>diabetes</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html"><i class="fa fa-check"></i><b>6</b> A Study of Prostate Cancer</a><ul>
<li class="chapter" data-level="6.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#data-load-and-background"><i class="fa fa-check"></i><b>6.1</b> Data Load and Background</a></li>
<li class="chapter" data-level="6.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#code-book"><i class="fa fa-check"></i><b>6.2</b> Code Book</a></li>
<li class="chapter" data-level="6.3" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#additions-for-later-use"><i class="fa fa-check"></i><b>6.3</b> Additions for Later Use</a></li>
<li class="chapter" data-level="6.4" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#fitting-and-evaluating-a-two-predictor-model"><i class="fa fa-check"></i><b>6.4</b> Fitting and Evaluating a Two-Predictor Model</a><ul>
<li class="chapter" data-level="6.4.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#using-tidy"><i class="fa fa-check"></i><b>6.4.1</b> Using <code>tidy</code></a></li>
<li class="chapter" data-level="6.4.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#interpretation"><i class="fa fa-check"></i><b>6.4.2</b> Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#exploring-model-c5_prost_a"><i class="fa fa-check"></i><b>6.5</b> Exploring Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="6.5.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#summary-for-model-c5_prost_a"><i class="fa fa-check"></i><b>6.5.1</b> <code>summary</code> for Model <code>c5_prost_A</code></a></li>
<li class="chapter" data-level="6.5.2" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#adjusted-r2"><i class="fa fa-check"></i><b>6.5.2</b> Adjusted R<sup>2</sup></a></li>
<li class="chapter" data-level="6.5.3" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#coefficient-confidence-intervals"><i class="fa fa-check"></i><b>6.5.3</b> Coefficient Confidence Intervals</a></li>
<li class="chapter" data-level="6.5.4" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#anova-for-model-c5_prost_a"><i class="fa fa-check"></i><b>6.5.4</b> ANOVA for Model <code>c5_prost_A</code></a></li>
<li class="chapter" data-level="6.5.5" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#residuals-fitted-values-and-standard-errors-with-augment"><i class="fa fa-check"></i><b>6.5.5</b> Residuals, Fitted Values and Standard Errors with <code>augment</code></a></li>
<li class="chapter" data-level="6.5.6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#making-predictions-with-c5_prost_a"><i class="fa fa-check"></i><b>6.5.6</b> Making Predictions with <code>c5_prost_A</code></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#plotting-model-c5_prost_a"><i class="fa fa-check"></i><b>6.6</b> Plotting Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="6.6.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#residual-plots-of-c5_prost_a"><i class="fa fa-check"></i><b>6.6.1</b> Residual Plots of <code>c5_prost_A</code></a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#cross-validation-of-model-c5_prost_a"><i class="fa fa-check"></i><b>6.7</b> Cross-Validation of Model <code>c5_prost_A</code></a><ul>
<li class="chapter" data-level="6.7.1" data-path="a-study-of-prostate-cancer.html"><a href="a-study-of-prostate-cancer.html#cross-validated-summaries-of-prediction-quality"><i class="fa fa-check"></i><b>6.7.1</b> Cross-Validated Summaries of Prediction Quality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html"><i class="fa fa-check"></i><b>7</b> Stepwise Variable Selection</a><ul>
<li class="chapter" data-level="7.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#strategy-for-model-selection"><i class="fa fa-check"></i><b>7.1</b> Strategy for Model Selection</a><ul>
<li class="chapter" data-level="7.1.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#how-do-we-choose-potential-subsets-of-predictors"><i class="fa fa-check"></i><b>7.1.1</b> How Do We Choose Potential Subsets of Predictors?</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#a-kitchen-sink-model-model-c5_prost_ks"><i class="fa fa-check"></i><b>7.2</b> A “Kitchen Sink” Model (Model <code>c5_prost_ks</code>)</a></li>
<li class="chapter" data-level="7.3" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#sequential-variable-selection-stepwise-approaches"><i class="fa fa-check"></i><b>7.3</b> Sequential Variable Selection: Stepwise Approaches</a><ul>
<li class="chapter" data-level="7.3.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#the-big-problems-with-stepwise-regression"><i class="fa fa-check"></i><b>7.3.1</b> The Big Problems with Stepwise Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#forward-selection-with-the-step-function"><i class="fa fa-check"></i><b>7.4</b> Forward Selection with the <code>step</code> function</a></li>
<li class="chapter" data-level="7.5" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#backward-elimination-using-the-step-function"><i class="fa fa-check"></i><b>7.5</b> Backward Elimination using the <code>step</code> function</a></li>
<li class="chapter" data-level="7.6" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#allen-cady-modified-backward-elimination"><i class="fa fa-check"></i><b>7.6</b> Allen-Cady Modified Backward Elimination</a><ul>
<li class="chapter" data-level="7.6.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#demonstration-of-the-allen-cady-approach"><i class="fa fa-check"></i><b>7.6.1</b> Demonstration of the Allen-Cady approach</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#summarizing-the-results"><i class="fa fa-check"></i><b>7.7</b> Summarizing the Results</a><ul>
<li class="chapter" data-level="7.7.1" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#in-sample-testing-and-summaries"><i class="fa fa-check"></i><b>7.7.1</b> In-Sample Testing and Summaries</a></li>
<li class="chapter" data-level="7.7.2" data-path="stepwise-variable-selection.html"><a href="stepwise-variable-selection.html#validating-the-results-of-the-various-models"><i class="fa fa-check"></i><b>7.7.2</b> Validating the Results of the Various Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><i class="fa fa-check"></i><b>8</b> “Best Subsets” Variable Selection in our Prostate Cancer Study</a><ul>
<li class="chapter" data-level="8.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#four-key-summaries-well-use-to-evaluate-potential-models"><i class="fa fa-check"></i><b>8.1</b> Four Key Summaries We’ll Use to Evaluate Potential Models</a></li>
<li class="chapter" data-level="8.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#using-regsubsets-in-the-leaps-package"><i class="fa fa-check"></i><b>8.2</b> Using <code>regsubsets</code> in the <code>leaps</code> package</a><ul>
<li class="chapter" data-level="8.2.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#identifying-the-models-with-which-and-outmat"><i class="fa fa-check"></i><b>8.2.1</b> Identifying the models with <code>which</code> and <code>outmat</code></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#calculating-bias-corrected-aic"><i class="fa fa-check"></i><b>8.3</b> Calculating bias-corrected AIC</a><ul>
<li class="chapter" data-level="8.3.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#calculation-of-aic.c-in-our-setting"><i class="fa fa-check"></i><b>8.3.1</b> Calculation of aic.c in our setting</a></li>
<li class="chapter" data-level="8.3.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-uncorrected-aic-provides-no-more-useful-information-here"><i class="fa fa-check"></i><b>8.3.2</b> The Uncorrected AIC provides no more useful information here</a></li>
<li class="chapter" data-level="8.3.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#building-a-tibble-containing-the-necessary-information"><i class="fa fa-check"></i><b>8.3.3</b> Building a Tibble containing the necessary information</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#plotting-the-best-subsets-results-using-ggplot2"><i class="fa fa-check"></i><b>8.4</b> Plotting the Best Subsets Results using <code>ggplot2</code></a><ul>
<li class="chapter" data-level="8.4.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-adjusted-r2-plot"><i class="fa fa-check"></i><b>8.4.1</b> The Adjusted R<sup>2</sup> Plot</a></li>
<li class="chapter" data-level="8.4.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#mallows-c_p"><i class="fa fa-check"></i><b>8.4.2</b> Mallows’ <span class="math inline">\(C_p\)</span></a></li>
<li class="chapter" data-level="8.4.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-c_p-plot"><i class="fa fa-check"></i><b>8.4.3</b> The <span class="math inline">\(C_p\)</span> Plot</a></li>
<li class="chapter" data-level="8.4.4" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#all-subsets-regression-and-information-criteria"><i class="fa fa-check"></i><b>8.4.4</b> “All Subsets” Regression and Information Criteria</a></li>
<li class="chapter" data-level="8.4.5" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-bias-corrected-aic-plot"><i class="fa fa-check"></i><b>8.4.5</b> The bias-corrected AIC plot</a></li>
<li class="chapter" data-level="8.4.6" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#the-bic-plot"><i class="fa fa-check"></i><b>8.4.6</b> The BIC plot</a></li>
<li class="chapter" data-level="8.4.7" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#all-four-plots-in-one-figure-via-ggplot2"><i class="fa fa-check"></i><b>8.4.7</b> All Four Plots in One Figure (via ggplot2)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#table-of-key-results"><i class="fa fa-check"></i><b>8.5</b> Table of Key Results</a></li>
<li class="chapter" data-level="8.6" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#models-worth-considering"><i class="fa fa-check"></i><b>8.6</b> Models Worth Considering?</a></li>
<li class="chapter" data-level="8.7" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#compare-these-candidate-models-in-sample"><i class="fa fa-check"></i><b>8.7</b> Compare these candidate models in-sample?</a><ul>
<li class="chapter" data-level="8.7.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#using-anova-to-compare-nested-models"><i class="fa fa-check"></i><b>8.7.1</b> Using <code>anova</code> to compare nested models</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#aic-and-bic-comparisons-within-the-training-sample"><i class="fa fa-check"></i><b>8.8</b> AIC and BIC comparisons, within the training sample</a></li>
<li class="chapter" data-level="8.9" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#cross-validation-of-candidate-models-out-of-sample"><i class="fa fa-check"></i><b>8.9</b> Cross-Validation of Candidate Models out of Sample</a><ul>
<li class="chapter" data-level="8.9.1" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#fold-cross-validation-of-model-m04"><i class="fa fa-check"></i><b>8.9.1</b> 20-fold Cross-Validation of model <code>m04</code></a></li>
<li class="chapter" data-level="8.9.2" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#fold-cross-validation-of-model-m07"><i class="fa fa-check"></i><b>8.9.2</b> 20-fold Cross-Validation of model <code>m07</code></a></li>
<li class="chapter" data-level="8.9.3" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#fold-cross-validation-of-model-m08"><i class="fa fa-check"></i><b>8.9.3</b> 20-fold Cross-Validation of model <code>m08</code></a></li>
<li class="chapter" data-level="8.9.4" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#comparing-the-results-of-the-cross-validations"><i class="fa fa-check"></i><b>8.9.4</b> Comparing the Results of the Cross-Validations</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="best-subsets-variable-selection-in-our-prostate-cancer-study.html"><a href="best-subsets-variable-selection-in-our-prostate-cancer-study.html#what-about-interaction-terms"><i class="fa fa-check"></i><b>8.10</b> What about Interaction Terms?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html"><i class="fa fa-check"></i><b>9</b> Adding Non-linear Terms to a Linear Regression Model</a><ul>
<li class="chapter" data-level="9.1" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#the-pollution-data"><i class="fa fa-check"></i><b>9.1</b> The <code>pollution</code> data</a></li>
<li class="chapter" data-level="9.2" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#fitting-a-straight-line-model-to-predict-y-from-x2"><i class="fa fa-check"></i><b>9.2</b> Fitting a straight line model to predict <code>y</code> from <code>x2</code></a></li>
<li class="chapter" data-level="9.3" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#quadratic-polynomial-model-to-predict-y-using-x2"><i class="fa fa-check"></i><b>9.3</b> Quadratic polynomial model to predict <code>y</code> using <code>x2</code></a><ul>
<li class="chapter" data-level="9.3.1" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#the-raw-quadratic-model"><i class="fa fa-check"></i><b>9.3.1</b> The raw quadratic model</a></li>
<li class="chapter" data-level="9.3.2" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#raw-quadratic-fit-after-centering-x2"><i class="fa fa-check"></i><b>9.3.2</b> Raw quadratic fit after centering <code>x2</code></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#orthogonal-polynomials"><i class="fa fa-check"></i><b>9.4</b> Orthogonal Polynomials</a></li>
<li class="chapter" data-level="9.5" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#fit-a-cubic-polynomial-to-predict-y-from-x3"><i class="fa fa-check"></i><b>9.5</b> Fit a cubic polynomial to predict <code>y</code> from <code>x3</code></a></li>
<li class="chapter" data-level="9.6" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#fitting-a-restricted-cubic-spline-in-a-linear-regression"><i class="fa fa-check"></i><b>9.6</b> Fitting a restricted cubic spline in a linear regression</a></li>
<li class="chapter" data-level="9.7" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#spending-degrees-of-freedom"><i class="fa fa-check"></i><b>9.7</b> “Spending” Degrees of Freedom</a><ul>
<li class="chapter" data-level="9.7.1" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#overfitting-and-limits-on-the-of-predictors"><i class="fa fa-check"></i><b>9.7.1</b> Overfitting and Limits on the # of Predictors</a></li>
<li class="chapter" data-level="9.7.2" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#the-importance-of-collinearity"><i class="fa fa-check"></i><b>9.7.2</b> The Importance of Collinearity</a></li>
<li class="chapter" data-level="9.7.3" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#collinearity-in-an-explanatory-model"><i class="fa fa-check"></i><b>9.7.3</b> Collinearity in an Explanatory Model</a></li>
<li class="chapter" data-level="9.7.4" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#collinearity-in-a-prediction-model"><i class="fa fa-check"></i><b>9.7.4</b> Collinearity in a Prediction Model</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#spending-df-on-non-linearity-the-spearman-rho2-plot"><i class="fa fa-check"></i><b>9.8</b> Spending DF on Non-Linearity: The Spearman <span class="math inline">\(\rho^2\)</span> Plot</a><ul>
<li class="chapter" data-level="9.8.1" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#fitting-a-big-model-to-the-pollution-data"><i class="fa fa-check"></i><b>9.8.1</b> Fitting a Big Model to the <code>pollution</code> data</a></li>
<li class="chapter" data-level="9.8.2" data-path="adding-non-linear-terms-to-a-linear-regression-model.html"><a href="adding-non-linear-terms-to-a-linear-regression-model.html#limitations-of-lm-for-fitting-complex-linear-regression-models"><i class="fa fa-check"></i><b>9.8.2</b> Limitations of <code>lm</code> for fitting complex linear regression models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html"><i class="fa fa-check"></i><b>10</b> Using <code>ols</code> from the <code>rms</code> package to fit linear models</a><ul>
<li class="chapter" data-level="10.1" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#fitting-a-model-with-ols"><i class="fa fa-check"></i><b>10.1</b> Fitting a model with <code>ols</code></a><ul>
<li class="chapter" data-level="10.1.1" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#the-model-likelihood-ratio-test"><i class="fa fa-check"></i><b>10.1.1</b> The Model Likelihood Ratio Test</a></li>
<li class="chapter" data-level="10.1.2" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#the-g-statistic"><i class="fa fa-check"></i><b>10.1.2</b> The g statistic</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#anova-for-an-ols-model"><i class="fa fa-check"></i><b>10.2</b> ANOVA for an <code>ols</code> model</a></li>
<li class="chapter" data-level="10.3" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#effect-estimates"><i class="fa fa-check"></i><b>10.3</b> Effect Estimates</a><ul>
<li class="chapter" data-level="10.3.1" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#simultaneous-confidence-intervals"><i class="fa fa-check"></i><b>10.3.1</b> Simultaneous Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#the-predict-function-for-an-ols-model"><i class="fa fa-check"></i><b>10.4</b> The <code>Predict</code> function for an <code>ols</code> model</a></li>
<li class="chapter" data-level="10.5" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#checking-influence-via-dfbeta"><i class="fa fa-check"></i><b>10.5</b> Checking Influence via <code>dfbeta</code></a><ul>
<li class="chapter" data-level="10.5.1" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#using-the-residuals-command-for-dfbetas"><i class="fa fa-check"></i><b>10.5.1</b> Using the <code>residuals</code> command for <code>dfbetas</code></a></li>
<li class="chapter" data-level="10.5.2" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#using-the-residuals-command-for-other-summaries"><i class="fa fa-check"></i><b>10.5.2</b> Using the <code>residuals</code> command for other summaries</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#model-validation-and-correcting-for-optimism"><i class="fa fa-check"></i><b>10.6</b> Model Validation and Correcting for Optimism</a></li>
<li class="chapter" data-level="10.7" data-path="using-ols-from-the-rms-package-to-fit-linear-models.html"><a href="using-ols-from-the-rms-package-to-fit-linear-models.html#building-a-nomogram-for-our-model"><i class="fa fa-check"></i><b>10.7</b> Building a Nomogram for Our Model</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html"><i class="fa fa-check"></i><b>11</b> Other Variable Selection Strategies</a><ul>
<li class="chapter" data-level="11.1" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#why-not-use-stepwise-procedures"><i class="fa fa-check"></i><b>11.1</b> Why not use stepwise procedures?</a></li>
<li class="chapter" data-level="11.2" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#ridge-regression"><i class="fa fa-check"></i><b>11.2</b> Ridge Regression</a><ul>
<li class="chapter" data-level="11.2.1" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#assessing-a-ridge-regression-approach"><i class="fa fa-check"></i><b>11.2.1</b> Assessing a Ridge Regression Approach</a></li>
<li class="chapter" data-level="11.2.2" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#the-lm.ridge-plot---where-do-coefficients-stabilize"><i class="fa fa-check"></i><b>11.2.2</b> The <code>lm.ridge</code> plot - where do coefficients stabilize?</a></li>
<li class="chapter" data-level="11.2.3" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#ridge-regression-the-bottom-line"><i class="fa fa-check"></i><b>11.2.3</b> Ridge Regression: The Bottom Line</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#the-lasso"><i class="fa fa-check"></i><b>11.3</b> The Lasso</a><ul>
<li class="chapter" data-level="11.3.1" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#consequences-of-the-lasso-approach"><i class="fa fa-check"></i><b>11.3.1</b> Consequences of the Lasso Approach</a></li>
<li class="chapter" data-level="11.3.2" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#how-the-lasso-works"><i class="fa fa-check"></i><b>11.3.2</b> How The Lasso Works</a></li>
<li class="chapter" data-level="11.3.3" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#cross-validation-with-the-lasso"><i class="fa fa-check"></i><b>11.3.3</b> Cross-Validation with the Lasso</a></li>
<li class="chapter" data-level="11.3.4" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#what-value-of-the-key-fraction-minimizes-cross-validated-mse"><i class="fa fa-check"></i><b>11.3.4</b> What value of the key fraction minimizes cross-validated MSE?</a></li>
<li class="chapter" data-level="11.3.5" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#coefficients-for-the-model-identified-by-the-cross-validation"><i class="fa fa-check"></i><b>11.3.5</b> Coefficients for the Model Identified by the Cross-Validation</a></li>
<li class="chapter" data-level="11.3.6" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#obtaining-fitted-values-from-lasso"><i class="fa fa-check"></i><b>11.3.6</b> Obtaining Fitted Values from Lasso</a></li>
<li class="chapter" data-level="11.3.7" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#complete-set-of-fitted-values-from-the-lasso"><i class="fa fa-check"></i><b>11.3.7</b> Complete Set of Fitted Values from the Lasso</a></li>
<li class="chapter" data-level="11.3.8" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#when-is-the-lasso-most-useful"><i class="fa fa-check"></i><b>11.3.8</b> When is the Lasso Most Useful?</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="other-variable-selection-strategies.html"><a href="other-variable-selection-strategies.html#applying-the-lasso-to-the-pollution-data"><i class="fa fa-check"></i><b>11.4</b> Applying the Lasso to the <code>pollution</code> data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html"><i class="fa fa-check"></i><b>12</b> Logistic Regression: The Foundations</a><ul>
<li class="chapter" data-level="12.1" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#a-first-attempt-a-linear-probability-model"><i class="fa fa-check"></i><b>12.1</b> A First Attempt: A Linear Probability Model</a></li>
<li class="chapter" data-level="12.2" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#logistic-regression"><i class="fa fa-check"></i><b>12.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="12.3" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#the-logistic-regression-model"><i class="fa fa-check"></i><b>12.3</b> The Logistic Regression Model</a></li>
<li class="chapter" data-level="12.4" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#the-link-function"><i class="fa fa-check"></i><b>12.4</b> The Link Function</a></li>
<li class="chapter" data-level="12.5" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#the-logit-or-log-odds"><i class="fa fa-check"></i><b>12.5</b> The logit or log odds</a></li>
<li class="chapter" data-level="12.6" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#interpreting-the-coefficients-of-a-logistic-regression-model"><i class="fa fa-check"></i><b>12.6</b> Interpreting the Coefficients of a Logistic Regression Model</a></li>
<li class="chapter" data-level="12.7" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#the-logistic-regression-has-non-constant-variance"><i class="fa fa-check"></i><b>12.7</b> The Logistic Regression has non-constant variance</a></li>
<li class="chapter" data-level="12.8" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#fitting-a-logistic-regression-model-to-our-simulated-data"><i class="fa fa-check"></i><b>12.8</b> Fitting a Logistic Regression Model to our Simulated Data</a></li>
<li class="chapter" data-level="12.9" data-path="logistic-regression-the-foundations.html"><a href="logistic-regression-the-foundations.html#plotting-the-logistic-regression-model"><i class="fa fa-check"></i><b>12.9</b> Plotting the Logistic Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html"><i class="fa fa-check"></i><b>13</b> Logistic Regression and the <code>resect</code> data</a><ul>
<li class="chapter" data-level="13.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#the-resect-data"><i class="fa fa-check"></i><b>13.1</b> The <code>resect</code> data</a></li>
<li class="chapter" data-level="13.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#running-a-simple-logistic-regression-model"><i class="fa fa-check"></i><b>13.2</b> Running A Simple Logistic Regression Model</a><ul>
<li class="chapter" data-level="13.2.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#logistic-regression-can-be-harder-than-linear-regression"><i class="fa fa-check"></i><b>13.2.1</b> Logistic Regression Can Be Harder than Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#logistic-regression-using-glm"><i class="fa fa-check"></i><b>13.3</b> Logistic Regression using <code>glm</code></a><ul>
<li class="chapter" data-level="13.3.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-coefficients-of-a-logistic-regression-model-1"><i class="fa fa-check"></i><b>13.3.1</b> Interpreting the Coefficients of a Logistic Regression Model</a></li>
<li class="chapter" data-level="13.3.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#using-predict-to-describe-the-models-fits"><i class="fa fa-check"></i><b>13.3.2</b> Using <code>predict</code> to describe the model’s fits</a></li>
<li class="chapter" data-level="13.3.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#odds-ratio-interpretation-of-coefficients"><i class="fa fa-check"></i><b>13.3.3</b> Odds Ratio interpretation of Coefficients</a></li>
<li class="chapter" data-level="13.3.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-rest-of-the-model-output-from-glm"><i class="fa fa-check"></i><b>13.3.4</b> Interpreting the rest of the model output from <code>glm</code></a></li>
<li class="chapter" data-level="13.3.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#deviance-and-comparing-our-model-to-the-null-model"><i class="fa fa-check"></i><b>13.3.5</b> Deviance and Comparing Our Model to the Null Model</a></li>
<li class="chapter" data-level="13.3.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#using-glance-with-a-logistic-regression-model"><i class="fa fa-check"></i><b>13.3.6</b> Using <code>glance</code> with a logistic regression model</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-model-summary"><i class="fa fa-check"></i><b>13.4</b> Interpreting the Model Summary</a><ul>
<li class="chapter" data-level="13.4.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#wald-z-tests-for-coefficients-in-a-logistic-regression"><i class="fa fa-check"></i><b>13.4.1</b> Wald Z tests for Coefficients in a Logistic Regression</a></li>
<li class="chapter" data-level="13.4.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#confidence-intervals-for-the-coefficients"><i class="fa fa-check"></i><b>13.4.2</b> Confidence Intervals for the Coefficients</a></li>
<li class="chapter" data-level="13.4.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#deviance-residuals"><i class="fa fa-check"></i><b>13.4.3</b> Deviance Residuals</a></li>
<li class="chapter" data-level="13.4.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#dispersion-parameter"><i class="fa fa-check"></i><b>13.4.4</b> Dispersion Parameter</a></li>
<li class="chapter" data-level="13.4.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#fisher-scoring-iterations"><i class="fa fa-check"></i><b>13.4.5</b> Fisher Scoring iterations</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-a-simple-logistic-regression-model"><i class="fa fa-check"></i><b>13.5</b> Plotting a Simple Logistic Regression Model</a><ul>
<li class="chapter" data-level="13.5.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#using-augment-to-capture-the-fitted-probabilities"><i class="fa fa-check"></i><b>13.5.1</b> Using <code>augment</code> to capture the fitted probabilities</a></li>
<li class="chapter" data-level="13.5.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-a-logistic-regression-models-fitted-values"><i class="fa fa-check"></i><b>13.5.2</b> Plotting a Logistic Regression Model’s Fitted Values</a></li>
<li class="chapter" data-level="13.5.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-a-simple-logistic-model-using-binomial_smooth"><i class="fa fa-check"></i><b>13.5.3</b> Plotting a Simple Logistic Model using <code>binomial_smooth</code></a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#how-well-does-model-a-classify-subjects"><i class="fa fa-check"></i><b>13.6</b> How well does Model A classify subjects?</a></li>
<li class="chapter" data-level="13.7" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#receiver-operating-characteristic-curve-analysis"><i class="fa fa-check"></i><b>13.7</b> Receiver Operating Characteristic Curve Analysis</a><ul>
<li class="chapter" data-level="13.7.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-area-under-the-roc-curve"><i class="fa fa-check"></i><b>13.7.1</b> Interpreting the Area under the ROC curve</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#the-roc-plot-for-res_moda"><i class="fa fa-check"></i><b>13.8</b> The ROC Plot for <code>res_modA</code></a><ul>
<li class="chapter" data-level="13.8.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#another-way-to-plot-the-roc-curve"><i class="fa fa-check"></i><b>13.8.1</b> Another way to plot the ROC Curve</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#assessing-residual-plots-from-model-a"><i class="fa fa-check"></i><b>13.9</b> Assessing Residual Plots from Model A</a></li>
<li class="chapter" data-level="13.10" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#model-b-a-kitchen-sink-logistic-regression-model"><i class="fa fa-check"></i><b>13.10</b> Model B: A “Kitchen Sink” Logistic Regression Model</a><ul>
<li class="chapter" data-level="13.10.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#comparing-model-a-to-model-b"><i class="fa fa-check"></i><b>13.10.1</b> Comparing Model A to Model B</a></li>
<li class="chapter" data-level="13.10.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-model-b"><i class="fa fa-check"></i><b>13.10.2</b> Interpreting Model B</a></li>
</ul></li>
<li class="chapter" data-level="13.11" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-model-b"><i class="fa fa-check"></i><b>13.11</b> Plotting Model B</a><ul>
<li class="chapter" data-level="13.11.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#using-augment-to-capture-the-fitted-probabilities-1"><i class="fa fa-check"></i><b>13.11.1</b> Using <code>augment</code> to capture the fitted probabilities</a></li>
<li class="chapter" data-level="13.11.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-model-b-fits-by-observed-mortality"><i class="fa fa-check"></i><b>13.11.2</b> Plotting Model B Fits by Observed Mortality</a></li>
<li class="chapter" data-level="13.11.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#the-roc-curve-for-model-b"><i class="fa fa-check"></i><b>13.11.3</b> The ROC curve for Model B</a></li>
<li class="chapter" data-level="13.11.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#residuals-leverage-and-influence"><i class="fa fa-check"></i><b>13.11.4</b> Residuals, Leverage and Influence</a></li>
</ul></li>
<li class="chapter" data-level="13.12" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#logistic-regression-using-lrm"><i class="fa fa-check"></i><b>13.12</b> Logistic Regression using <code>lrm</code></a><ul>
<li class="chapter" data-level="13.12.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-nagelkerke-r2"><i class="fa fa-check"></i><b>13.12.1</b> Interpreting Nagelkerke R<sup>2</sup></a></li>
<li class="chapter" data-level="13.12.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#interpreting-the-c-statistic-and-plotting-the-roc-curve"><i class="fa fa-check"></i><b>13.12.2</b> Interpreting the C statistic and Plotting the ROC Curve</a></li>
<li class="chapter" data-level="13.12.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#the-c-statistic-and-somers-d"><i class="fa fa-check"></i><b>13.12.3</b> The C statistic and Somers’ D</a></li>
<li class="chapter" data-level="13.12.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#validating-the-logistic-regression-model-summary-statistics"><i class="fa fa-check"></i><b>13.12.4</b> Validating the Logistic Regression Model Summary Statistics</a></li>
<li class="chapter" data-level="13.12.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-the-summary-of-the-lrm-approach"><i class="fa fa-check"></i><b>13.12.5</b> Plotting the Summary of the <code>lrm</code> approach</a></li>
<li class="chapter" data-level="13.12.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plot-in-sample-predictions-for-model-c"><i class="fa fa-check"></i><b>13.12.6</b> Plot In-Sample Predictions for Model C</a></li>
<li class="chapter" data-level="13.12.7" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#anova-from-the-lrm-approach"><i class="fa fa-check"></i><b>13.12.7</b> ANOVA from the <code>lrm</code> approach</a></li>
<li class="chapter" data-level="13.12.8" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#are-any-points-particularly-influential"><i class="fa fa-check"></i><b>13.12.8</b> Are any points particularly influential?</a></li>
<li class="chapter" data-level="13.12.9" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#a-nomogram-for-model-c"><i class="fa fa-check"></i><b>13.12.9</b> A Nomogram for Model C</a></li>
</ul></li>
<li class="chapter" data-level="13.13" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#model-d-an-augmented-kitchen-sink-model"><i class="fa fa-check"></i><b>13.13</b> Model D: An Augmented Kitchen Sink Model</a><ul>
<li class="chapter" data-level="13.13.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#spearman-rho2-plot"><i class="fa fa-check"></i><b>13.13.1</b> Spearman <span class="math inline">\(\rho^2\)</span> Plot</a></li>
<li class="chapter" data-level="13.13.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#fitting-model-d-using-lrm"><i class="fa fa-check"></i><b>13.13.2</b> Fitting Model D using <code>lrm</code></a></li>
<li class="chapter" data-level="13.13.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#assessing-model-d-using-lrms-tools"><i class="fa fa-check"></i><b>13.13.3</b> Assessing Model D using <code>lrm</code>’s tools</a></li>
<li class="chapter" data-level="13.13.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#anova-and-wald-tests-for-model-d"><i class="fa fa-check"></i><b>13.13.4</b> ANOVA and Wald Tests for Model D</a></li>
<li class="chapter" data-level="13.13.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#effect-sizes-in-model-d"><i class="fa fa-check"></i><b>13.13.5</b> Effect Sizes in Model D</a></li>
<li class="chapter" data-level="13.13.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plot-in-sample-predictions-for-model-d"><i class="fa fa-check"></i><b>13.13.6</b> Plot In-Sample Predictions for Model D</a></li>
<li class="chapter" data-level="13.13.7" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plotting-the-roc-curve-for-model-d"><i class="fa fa-check"></i><b>13.13.7</b> Plotting the ROC curve for Model D</a></li>
<li class="chapter" data-level="13.13.8" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#validation-of-model-d-summaries"><i class="fa fa-check"></i><b>13.13.8</b> Validation of Model D summaries</a></li>
</ul></li>
<li class="chapter" data-level="13.14" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#model-e-fitting-a-reduced-model-in-light-of-model-d"><i class="fa fa-check"></i><b>13.14</b> Model E: Fitting a Reduced Model in light of Model D</a><ul>
<li class="chapter" data-level="13.14.1" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#a-plot-comparing-the-two-intubation-groups"><i class="fa fa-check"></i><b>13.14.1</b> A Plot comparing the two intubation groups</a></li>
<li class="chapter" data-level="13.14.2" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#nomogram-for-model-e"><i class="fa fa-check"></i><b>13.14.2</b> Nomogram for Model E</a></li>
<li class="chapter" data-level="13.14.3" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#effect-sizes-from-model-e"><i class="fa fa-check"></i><b>13.14.3</b> Effect Sizes from Model E</a></li>
<li class="chapter" data-level="13.14.4" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#plot-in-sample-predictions-for-model-e"><i class="fa fa-check"></i><b>13.14.4</b> Plot In-Sample Predictions for Model E</a></li>
<li class="chapter" data-level="13.14.5" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#anova-for-model-e"><i class="fa fa-check"></i><b>13.14.5</b> ANOVA for Model E</a></li>
<li class="chapter" data-level="13.14.6" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#validation-of-model-e"><i class="fa fa-check"></i><b>13.14.6</b> Validation of Model E</a></li>
<li class="chapter" data-level="13.14.7" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#do-any-points-seem-particularly-influential"><i class="fa fa-check"></i><b>13.14.7</b> Do any points seem particularly influential?</a></li>
<li class="chapter" data-level="13.14.8" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#fitting-model-e-using-glm-to-get-plots-about-influence"><i class="fa fa-check"></i><b>13.14.8</b> Fitting Model E using <code>glm</code> to get plots about influence</a></li>
</ul></li>
<li class="chapter" data-level="13.15" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#concordance-comparing-model-c-d-and-es-predictions"><i class="fa fa-check"></i><b>13.15</b> Concordance: Comparing Model C, D and E’s predictions</a></li>
<li class="chapter" data-level="13.16" data-path="logistic-regression-and-the-resect-data.html"><a href="logistic-regression-and-the-resect-data.html#conclusions"><i class="fa fa-check"></i><b>13.16</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html"><i class="fa fa-check"></i><b>14</b> Logistic Regression and the <code>smartcle1</code> data</a><ul>
<li class="chapter" data-level="14.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#the-smartcle1-data"><i class="fa fa-check"></i><b>14.1</b> The <code>smartcle1</code> data</a></li>
<li class="chapter" data-level="14.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#thinking-about-non-linear-terms"><i class="fa fa-check"></i><b>14.2</b> Thinking About Non-Linear Terms</a></li>
<li class="chapter" data-level="14.3" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#a-first-model-for-exerany-complete-case-analysis"><i class="fa fa-check"></i><b>14.3</b> A First Model for <code>exerany</code> (Complete Case Analysis)</a></li>
<li class="chapter" data-level="14.4" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#building-a-larger-model-spearman-rho2-plot"><i class="fa fa-check"></i><b>14.4</b> Building a Larger Model: Spearman <span class="math inline">\(\rho^2\)</span> Plot</a></li>
<li class="chapter" data-level="14.5" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#a-second-model-for-exerany-complete-cases"><i class="fa fa-check"></i><b>14.5</b> A Second Model for <code>exerany</code> (Complete Cases)</a></li>
<li class="chapter" data-level="14.6" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#dealing-with-missing-data-via-simple-imputation"><i class="fa fa-check"></i><b>14.6</b> Dealing with Missing Data via Simple Imputation</a><ul>
<li class="chapter" data-level="14.6.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#omit-cases-where-the-outcome-is-missing"><i class="fa fa-check"></i><b>14.6.1</b> Omit cases where the outcome is missing</a></li>
<li class="chapter" data-level="14.6.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plot-the-remaining-missingness"><i class="fa fa-check"></i><b>14.6.2</b> Plot the remaining missingness</a></li>
<li class="chapter" data-level="14.6.3" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#use-simple-imputation-build-a-new-data-set"><i class="fa fa-check"></i><b>14.6.3</b> Use simple imputation, build a new data set</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#refitting-model-1-with-simply-imputed-data"><i class="fa fa-check"></i><b>14.7</b> Refitting Model 1 with simply imputed data</a><ul>
<li class="chapter" data-level="14.7.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#validating-summary-statistics"><i class="fa fa-check"></i><b>14.7.1</b> Validating Summary Statistics</a></li>
<li class="chapter" data-level="14.7.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#anova-for-the-model"><i class="fa fa-check"></i><b>14.7.2</b> ANOVA for the model</a></li>
<li class="chapter" data-level="14.7.3" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#summarizing-effect-size"><i class="fa fa-check"></i><b>14.7.3</b> Summarizing Effect Size</a></li>
<li class="chapter" data-level="14.7.4" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plotting-the-model-with-ggplot-and-predict"><i class="fa fa-check"></i><b>14.7.4</b> Plotting the Model with <code>ggplot</code> and <code>Predict</code></a></li>
<li class="chapter" data-level="14.7.5" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plotting-the-model-with-a-nomogram"><i class="fa fa-check"></i><b>14.7.5</b> Plotting the model with a nomogram</a></li>
<li class="chapter" data-level="14.7.6" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#checking-the-goodness-of-fit-of-our-model"><i class="fa fa-check"></i><b>14.7.6</b> Checking the Goodness of Fit of our model</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#refitting-model-2-with-simply-imputed-data"><i class="fa fa-check"></i><b>14.8</b> Refitting Model 2 with simply imputed data</a><ul>
<li class="chapter" data-level="14.8.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#validating-summary-statistics-1"><i class="fa fa-check"></i><b>14.8.1</b> Validating Summary Statistics</a></li>
<li class="chapter" data-level="14.8.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#anova-for-the-model-1"><i class="fa fa-check"></i><b>14.8.2</b> ANOVA for the model</a></li>
<li class="chapter" data-level="14.8.3" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#summarizing-effect-size-1"><i class="fa fa-check"></i><b>14.8.3</b> Summarizing Effect Size</a></li>
<li class="chapter" data-level="14.8.4" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plotting-the-model-with-ggplot-and-predict-1"><i class="fa fa-check"></i><b>14.8.4</b> Plotting the Model with <code>ggplot</code> and <code>Predict</code></a></li>
<li class="chapter" data-level="14.8.5" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#plotting-the-model-with-a-nomogram-1"><i class="fa fa-check"></i><b>14.8.5</b> Plotting the model with a nomogram</a></li>
<li class="chapter" data-level="14.8.6" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#checking-the-goodness-of-fit-of-our-model-1"><i class="fa fa-check"></i><b>14.8.6</b> Checking the Goodness of Fit of our model</a></li>
</ul></li>
<li class="chapter" data-level="14.9" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#comparing-model-2-to-model-1-after-simple-imputation"><i class="fa fa-check"></i><b>14.9</b> Comparing Model 2 to Model 1 after simple imputation</a><ul>
<li class="chapter" data-level="14.9.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#comparison-by-analysis-of-deviance"><i class="fa fa-check"></i><b>14.9.1</b> Comparison by Analysis of Deviance</a></li>
<li class="chapter" data-level="14.9.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#comparing-aic-and-bic"><i class="fa fa-check"></i><b>14.9.2</b> Comparing AIC and BIC</a></li>
</ul></li>
<li class="chapter" data-level="14.10" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#dealing-with-missing-data-via-multiple-imputation"><i class="fa fa-check"></i><b>14.10</b> Dealing with Missing Data via Multiple Imputation</a><ul>
<li class="chapter" data-level="14.10.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#using-aregimpute-to-fit-a-multiple-imputation-model"><i class="fa fa-check"></i><b>14.10.1</b> Using <code>aregImpute</code> to fit a multiple imputation model</a></li>
</ul></li>
<li class="chapter" data-level="14.11" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#combining-the-imputation-and-outcome-models"><i class="fa fa-check"></i><b>14.11</b> Combining the Imputation and Outcome Models</a><ul>
<li class="chapter" data-level="14.11.1" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#model-1-with-multiple-imputation"><i class="fa fa-check"></i><b>14.11.1</b> Model 1 with Multiple Imputation</a></li>
<li class="chapter" data-level="14.11.2" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#model-2-with-multiple-imputation"><i class="fa fa-check"></i><b>14.11.2</b> Model 2 with Multiple Imputation</a></li>
</ul></li>
<li class="chapter" data-level="14.12" data-path="logistic-regression-and-the-smartcle1-data.html"><a href="logistic-regression-and-the-smartcle1-data.html#models-with-and-without-imputation"><i class="fa fa-check"></i><b>14.12</b> Models with and without Imputation</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html"><i class="fa fa-check"></i><b>15</b> Linear Regression and the <code>smartcle1</code> data</a><ul>
<li class="chapter" data-level="15.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#the-smartcle1-data-1"><i class="fa fa-check"></i><b>15.1</b> The <code>smartcle1</code> data</a></li>
<li class="chapter" data-level="15.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#thinking-about-non-linear-terms-1"><i class="fa fa-check"></i><b>15.2</b> Thinking About Non-Linear Terms</a></li>
<li class="chapter" data-level="15.3" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#a-first-model-for-sleephrs-complete-case-analysis"><i class="fa fa-check"></i><b>15.3</b> A First Model for <code>sleephrs</code> (Complete Case Analysis)</a></li>
<li class="chapter" data-level="15.4" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#building-a-larger-model-spearman-rho2-plot-1"><i class="fa fa-check"></i><b>15.4</b> Building a Larger Model: Spearman <span class="math inline">\(\rho^2\)</span> Plot</a></li>
<li class="chapter" data-level="15.5" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#a-second-model-for-sleephrs-complete-cases"><i class="fa fa-check"></i><b>15.5</b> A Second Model for <code>sleephrs</code> (Complete Cases)</a></li>
<li class="chapter" data-level="15.6" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#dealing-with-missing-data-via-simple-imputation-1"><i class="fa fa-check"></i><b>15.6</b> Dealing with Missing Data via Simple Imputation</a><ul>
<li class="chapter" data-level="15.6.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#omit-cases-where-the-outcome-is-missing-1"><i class="fa fa-check"></i><b>15.6.1</b> Omit cases where the outcome is missing</a></li>
<li class="chapter" data-level="15.6.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#plot-the-remaining-missingness-1"><i class="fa fa-check"></i><b>15.6.2</b> Plot the remaining missingness</a></li>
<li class="chapter" data-level="15.6.3" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#use-simple-imputation-build-a-new-data-set-1"><i class="fa fa-check"></i><b>15.6.3</b> Use simple imputation, build a new data set</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#refitting-model-a-with-simply-imputed-data"><i class="fa fa-check"></i><b>15.7</b> Refitting Model A with simply imputed data</a><ul>
<li class="chapter" data-level="15.7.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#validating-summary-statistics-2"><i class="fa fa-check"></i><b>15.7.1</b> Validating Summary Statistics</a></li>
<li class="chapter" data-level="15.7.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#anova-for-the-model-2"><i class="fa fa-check"></i><b>15.7.2</b> ANOVA for the model</a></li>
<li class="chapter" data-level="15.7.3" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#summarizing-effect-size-2"><i class="fa fa-check"></i><b>15.7.3</b> Summarizing Effect Size</a></li>
<li class="chapter" data-level="15.7.4" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#plotting-the-model-with-ggplot-and-predict-2"><i class="fa fa-check"></i><b>15.7.4</b> Plotting the Model with <code>ggplot</code> and <code>Predict</code></a></li>
<li class="chapter" data-level="15.7.5" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#plotting-the-model-with-a-nomogram-2"><i class="fa fa-check"></i><b>15.7.5</b> Plotting the model with a nomogram</a></li>
<li class="chapter" data-level="15.7.6" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#residual-plots-for-mod.a2"><i class="fa fa-check"></i><b>15.7.6</b> Residual Plots for mod.A2</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#refitting-model-b-with-simply-imputed-data"><i class="fa fa-check"></i><b>15.8</b> Refitting Model B with simply imputed data</a><ul>
<li class="chapter" data-level="15.8.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#validating-summary-statistics-3"><i class="fa fa-check"></i><b>15.8.1</b> Validating Summary Statistics</a></li>
<li class="chapter" data-level="15.8.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#anova-for-the-model-3"><i class="fa fa-check"></i><b>15.8.2</b> ANOVA for the model</a></li>
<li class="chapter" data-level="15.8.3" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#summarizing-effect-size-3"><i class="fa fa-check"></i><b>15.8.3</b> Summarizing Effect Size</a></li>
<li class="chapter" data-level="15.8.4" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#plotting-the-model-with-ggplot-and-predict-3"><i class="fa fa-check"></i><b>15.8.4</b> Plotting the Model with <code>ggplot</code> and <code>Predict</code></a></li>
</ul></li>
<li class="chapter" data-level="15.9" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#comparing-model-b.2-to-model-a.2-after-simple-imputation"><i class="fa fa-check"></i><b>15.9</b> Comparing Model B.2 to Model A.2 after simple imputation</a><ul>
<li class="chapter" data-level="15.9.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#comparison-by-analysis-of-variance"><i class="fa fa-check"></i><b>15.9.1</b> Comparison by Analysis of Variance</a></li>
<li class="chapter" data-level="15.9.2" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#comparing-aic-and-bic-1"><i class="fa fa-check"></i><b>15.9.2</b> Comparing AIC and BIC</a></li>
</ul></li>
<li class="chapter" data-level="15.10" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#dealing-with-missing-data-via-multiple-imputation-1"><i class="fa fa-check"></i><b>15.10</b> Dealing with Missing Data via Multiple Imputation</a><ul>
<li class="chapter" data-level="15.10.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#using-aregimpute-to-fit-a-multiple-imputation-model-1"><i class="fa fa-check"></i><b>15.10.1</b> Using <code>aregImpute</code> to fit a multiple imputation model</a></li>
</ul></li>
<li class="chapter" data-level="15.11" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#combining-the-imputation-and-outcome-models-1"><i class="fa fa-check"></i><b>15.11</b> Combining the Imputation and Outcome Models</a><ul>
<li class="chapter" data-level="15.11.1" data-path="linear-regression-and-the-smartcle1-data.html"><a href="linear-regression-and-the-smartcle1-data.html#model-a-with-multiple-imputation"><i class="fa fa-check"></i><b>15.11.1</b> Model A with Multiple Imputation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html"><i class="fa fa-check"></i><b>16</b> Colorectal Cancer Screening and Some Special Cases</a><ul>
<li class="chapter" data-level="16.1" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#logistic-regression-for-aggregated-data"><i class="fa fa-check"></i><b>16.1</b> Logistic Regression for Aggregated Data</a><ul>
<li class="chapter" data-level="16.1.1" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#colorectal-cancer-screening-data"><i class="fa fa-check"></i><b>16.1.1</b> Colorectal Cancer Screening Data</a></li>
<li class="chapter" data-level="16.1.2" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#fitting-a-logistic-regression-model-to-proportion-data"><i class="fa fa-check"></i><b>16.1.2</b> Fitting a Logistic Regression Model to Proportion Data</a></li>
<li class="chapter" data-level="16.1.3" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#fitting-a-logistic-regression-model-to-counts-of-successes-and-failures"><i class="fa fa-check"></i><b>16.1.3</b> Fitting a Logistic Regression Model to Counts of Successes and Failures</a></li>
<li class="chapter" data-level="16.1.4" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#how-does-one-address-this-problem-in-rms"><i class="fa fa-check"></i><b>16.1.4</b> How does one address this problem in <code>rms</code>?</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#probit-regression"><i class="fa fa-check"></i><b>16.2</b> Probit Regression</a><ul>
<li class="chapter" data-level="16.2.1" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#colorectal-cancer-screening-data-on-individuals"><i class="fa fa-check"></i><b>16.2.1</b> Colorectal Cancer Screening Data on Individuals</a></li>
<li class="chapter" data-level="16.2.2" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#a-logistic-regression-model"><i class="fa fa-check"></i><b>16.2.2</b> A logistic regression model</a></li>
<li class="chapter" data-level="16.2.3" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#predicting-status-for-harry-and-sally"><i class="fa fa-check"></i><b>16.2.3</b> Predicting status for Harry and Sally</a></li>
<li class="chapter" data-level="16.2.4" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#a-probit-regression-model"><i class="fa fa-check"></i><b>16.2.4</b> A probit regression model</a></li>
<li class="chapter" data-level="16.2.5" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#interpreting-the-probit-models-coefficients"><i class="fa fa-check"></i><b>16.2.5</b> Interpreting the Probit Model’s Coefficients</a></li>
<li class="chapter" data-level="16.2.6" data-path="colorectal-cancer-screening-and-some-special-cases.html"><a href="colorectal-cancer-screening-and-some-special-cases.html#what-about-harry-and-sally"><i class="fa fa-check"></i><b>16.2.6</b> What about Harry and Sally?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html"><i class="fa fa-check"></i><b>17</b> Cleaning the BRFSS SMART Data</a><ul>
<li class="chapter" data-level="17.1" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#key-resources-1"><i class="fa fa-check"></i><b>17.1</b> Key resources</a></li>
<li class="chapter" data-level="17.2" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#ingesting-the-raw-data"><i class="fa fa-check"></i><b>17.2</b> Ingesting The Raw Data</a></li>
<li class="chapter" data-level="17.3" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#the-national-data"><i class="fa fa-check"></i><b>17.3</b> The National Data</a></li>
<li class="chapter" data-level="17.4" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#cleaning-the-brfss-data"><i class="fa fa-check"></i><b>17.4</b> Cleaning the BRFSS Data</a><ul>
<li class="chapter" data-level="17.4.1" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#health-status-1-item"><i class="fa fa-check"></i><b>17.4.1</b> Health Status (1 item)</a></li>
<li class="chapter" data-level="17.4.2" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#healthy-days---health-related-quality-of-life-3-items"><i class="fa fa-check"></i><b>17.4.2</b> Healthy Days - Health-Related Quality of Life (3 items)</a></li>
<li class="chapter" data-level="17.4.3" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#health-care-access-4-items"><i class="fa fa-check"></i><b>17.4.3</b> Health Care Access (4 items)</a></li>
<li class="chapter" data-level="17.4.4" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#exercise-1-item"><i class="fa fa-check"></i><b>17.4.4</b> Exercise (1 item)</a></li>
<li class="chapter" data-level="17.4.5" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#inadequate-sleep-1-item"><i class="fa fa-check"></i><b>17.4.5</b> Inadequate Sleep (1 item)</a></li>
<li class="chapter" data-level="17.4.6" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#chronic-health-conditions-13-items"><i class="fa fa-check"></i><b>17.4.6</b> Chronic Health Conditions (13 items)</a></li>
<li class="chapter" data-level="17.4.7" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#oral-health-2-items"><i class="fa fa-check"></i><b>17.4.7</b> Oral Health (2 items)</a></li>
<li class="chapter" data-level="17.4.8" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#demographics-23-items"><i class="fa fa-check"></i><b>17.4.8</b> Demographics (23 items)</a></li>
<li class="chapter" data-level="17.4.9" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#tobacco-use-5-items"><i class="fa fa-check"></i><b>17.4.9</b> Tobacco Use (5 items)</a></li>
<li class="chapter" data-level="17.4.10" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#e-cigarettes-2-items"><i class="fa fa-check"></i><b>17.4.10</b> E-Cigarettes (2 items)</a></li>
<li class="chapter" data-level="17.4.11" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#alcohol-consumption-4-items"><i class="fa fa-check"></i><b>17.4.11</b> Alcohol Consumption (4 items)</a></li>
<li class="chapter" data-level="17.4.12" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#immunization-4-items"><i class="fa fa-check"></i><b>17.4.12</b> Immunization (4 items)</a></li>
<li class="chapter" data-level="17.4.13" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#falls-2-items"><i class="fa fa-check"></i><b>17.4.13</b> Falls (2 items)</a></li>
<li class="chapter" data-level="17.4.14" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#seatbelt-use-1-item"><i class="fa fa-check"></i><b>17.4.14</b> Seatbelt Use (1 item)</a></li>
<li class="chapter" data-level="17.4.15" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#drinking-and-driving-1-item"><i class="fa fa-check"></i><b>17.4.15</b> Drinking and Driving (1 item)</a></li>
<li class="chapter" data-level="17.4.16" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#breast-and-cervical-cancer-screening-7-items"><i class="fa fa-check"></i><b>17.4.16</b> Breast and Cervical Cancer Screening (7 items)</a></li>
<li class="chapter" data-level="17.4.17" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#prostate-cancer-screening-6-items"><i class="fa fa-check"></i><b>17.4.17</b> Prostate Cancer Screening (6 items)</a></li>
<li class="chapter" data-level="17.4.18" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#colorectal-cancer-screening-5-items"><i class="fa fa-check"></i><b>17.4.18</b> Colorectal Cancer Screening (5 items)</a></li>
<li class="chapter" data-level="17.4.19" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#hivaids-3-items"><i class="fa fa-check"></i><b>17.4.19</b> HIV/AIDS (3 items)</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#creating-some-quantitative-variables-from-thin-air"><i class="fa fa-check"></i><b>17.5</b> Creating Some Quantitative Variables from Thin Air</a><ul>
<li class="chapter" data-level="17.5.1" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#age_imp-creating-age-data-out-of-thin-air"><i class="fa fa-check"></i><b>17.5.1</b> <code>age_imp</code>: Creating Age Data out of Thin Air</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#clean-data-in-the-state-of-ohio"><i class="fa fa-check"></i><b>17.6</b> Clean Data in the State of Ohio</a></li>
<li class="chapter" data-level="17.7" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#clean-cleveland-elyria-data"><i class="fa fa-check"></i><b>17.7</b> Clean Cleveland-Elyria Data</a><ul>
<li class="chapter" data-level="17.7.1" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#cleveland---elyria-raw-data"><i class="fa fa-check"></i><b>17.7.1</b> Cleveland - Elyria Raw Data</a></li>
<li class="chapter" data-level="17.7.2" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#clean-data---larger"><i class="fa fa-check"></i><b>17.7.2</b> Clean Data - Larger</a></li>
<li class="chapter" data-level="17.7.3" data-path="cleaning-the-brfss-smart-data.html"><a href="cleaning-the-brfss-smart-data.html#creation-of-the-smartcle1.csv-data"><i class="fa fa-check"></i><b>17.7.3</b> Creation of the <code>smartcle1.csv</code> data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html"><i class="fa fa-check"></i><b>18</b> Modeling a Count Outcome in Ohio SMART</a><ul>
<li class="chapter" data-level="18.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#preliminaries"><i class="fa fa-check"></i><b>18.1</b> Preliminaries</a></li>
<li class="chapter" data-level="18.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-subset-of-the-ohio-smart-data"><i class="fa fa-check"></i><b>18.2</b> A subset of the Ohio SMART data</a><ul>
<li class="chapter" data-level="18.2.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#is-age-group-associated-with-physhealth"><i class="fa fa-check"></i><b>18.2.1</b> Is age group associated with <code>physhealth</code>?</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#exploratory-data-analysis-in-the-18-49-group"><i class="fa fa-check"></i><b>18.3</b> Exploratory Data Analysis (in the 18-49 group)</a><ul>
<li class="chapter" data-level="18.3.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#build-a-subset-of-those-ages-18-49"><i class="fa fa-check"></i><b>18.3.1</b> Build a subset of those ages 18-49</a></li>
<li class="chapter" data-level="18.3.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#distribution-of-the-outcome"><i class="fa fa-check"></i><b>18.3.2</b> Distribution of the Outcome</a></li>
<li class="chapter" data-level="18.3.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#initial-scatterplot-matrix"><i class="fa fa-check"></i><b>18.3.3</b> Initial Scatterplot Matrix</a></li>
<li class="chapter" data-level="18.3.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#dropping-the-subject-with-an-unreasonably-large-bmi"><i class="fa fa-check"></i><b>18.3.4</b> Dropping the subject with an unreasonably large <code>bmi</code></a></li>
<li class="chapter" data-level="18.3.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#revised-final-scatterplot-matrix"><i class="fa fa-check"></i><b>18.3.5</b> Revised (Final) Scatterplot Matrix</a></li>
<li class="chapter" data-level="18.3.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#summary-of-the-final-subset-of-data"><i class="fa fa-check"></i><b>18.3.6</b> Summary of the final subset of data</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#modeling-strategies-explored-here"><i class="fa fa-check"></i><b>18.4</b> Modeling Strategies Explored Here</a><ul>
<li class="chapter" data-level="18.4.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#what-will-we-demonstrate"><i class="fa fa-check"></i><b>18.4.1</b> What Will We Demonstrate?</a></li>
<li class="chapter" data-level="18.4.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#extra-data-file-for-harry-and-sally"><i class="fa fa-check"></i><b>18.4.2</b> Extra Data File for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-ols-approach"><i class="fa fa-check"></i><b>18.5</b> The OLS Approach</a><ul>
<li class="chapter" data-level="18.5.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation"><i class="fa fa-check"></i><b>18.5.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.5.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients"><i class="fa fa-check"></i><b>18.5.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.5.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors"><i class="fa fa-check"></i><b>18.5.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.5.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals"><i class="fa fa-check"></i><b>18.5.4</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.5.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values"><i class="fa fa-check"></i><b>18.5.5</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.5.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions"><i class="fa fa-check"></i><b>18.5.6</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.5.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally"><i class="fa fa-check"></i><b>18.5.7</b> Predictions for Harry and Sally</a></li>
<li class="chapter" data-level="18.5.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#notes"><i class="fa fa-check"></i><b>18.5.8</b> Notes</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#ols-model-on-logphyshealth-1-days"><i class="fa fa-check"></i><b>18.6</b> OLS model on log(<code>physhealth</code> + 1) days</a><ul>
<li class="chapter" data-level="18.6.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-1"><i class="fa fa-check"></i><b>18.6.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.6.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-1"><i class="fa fa-check"></i><b>18.6.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.6.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-1"><i class="fa fa-check"></i><b>18.6.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.6.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-1"><i class="fa fa-check"></i><b>18.6.4</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.6.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values-1"><i class="fa fa-check"></i><b>18.6.5</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.6.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#getting-r2-on-the-scale-of-physhealth"><i class="fa fa-check"></i><b>18.6.6</b> Getting R<sup>2</sup> on the scale of <code>physhealth</code></a></li>
<li class="chapter" data-level="18.6.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-1"><i class="fa fa-check"></i><b>18.6.7</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.6.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-1"><i class="fa fa-check"></i><b>18.6.8</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-poisson-regression-model"><i class="fa fa-check"></i><b>18.7</b> A Poisson Regression Model</a><ul>
<li class="chapter" data-level="18.7.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-2"><i class="fa fa-check"></i><b>18.7.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.7.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-2"><i class="fa fa-check"></i><b>18.7.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.7.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-2"><i class="fa fa-check"></i><b>18.7.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.7.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#correcting-for-overdispersion-with-coeftestcoefci"><i class="fa fa-check"></i><b>18.7.4</b> Correcting for Overdispersion with <code>coeftest</code>/<code>coefci</code></a></li>
<li class="chapter" data-level="18.7.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-2"><i class="fa fa-check"></i><b>18.7.5</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.7.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-see-the-fit-of-a-count-regression-model"><i class="fa fa-check"></i><b>18.7.6</b> Rootogram: see the fit of a count regression model</a></li>
<li class="chapter" data-level="18.7.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values-2"><i class="fa fa-check"></i><b>18.7.7</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.7.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-2"><i class="fa fa-check"></i><b>18.7.8</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.7.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#using-glm.diag.plots-from-the-boot-package"><i class="fa fa-check"></i><b>18.7.9</b> Using <code>glm.diag.plots</code> from the <code>boot</code> package</a></li>
<li class="chapter" data-level="18.7.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-2"><i class="fa fa-check"></i><b>18.7.10</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#overdispersion-in-a-poisson-model"><i class="fa fa-check"></i><b>18.8</b> Overdispersion in a Poisson Model</a><ul>
<li class="chapter" data-level="18.8.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-for-overdispersion"><i class="fa fa-check"></i><b>18.8.1</b> Testing for Overdispersion?</a></li>
</ul></li>
<li class="chapter" data-level="18.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#fitting-the-quasi-poisson-model"><i class="fa fa-check"></i><b>18.9</b> Fitting the Quasi-Poisson Model</a><ul>
<li class="chapter" data-level="18.9.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-3"><i class="fa fa-check"></i><b>18.9.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.9.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-3"><i class="fa fa-check"></i><b>18.9.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.9.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-3"><i class="fa fa-check"></i><b>18.9.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.9.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-3"><i class="fa fa-check"></i><b>18.9.4</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.9.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values-3"><i class="fa fa-check"></i><b>18.9.5</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.9.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-3"><i class="fa fa-check"></i><b>18.9.6</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.9.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-3"><i class="fa fa-check"></i><b>18.9.7</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#poisson-and-quasi-poisson-models-using-glm-from-the-rms-package"><i class="fa fa-check"></i><b>18.10</b> Poisson and Quasi-Poisson models using <code>Glm</code> from the <code>rms</code> package</a><ul>
<li class="chapter" data-level="18.10.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#refitting-the-original-poisson-regression-with-glm"><i class="fa fa-check"></i><b>18.10.1</b> Refitting the original Poisson regression with <code>Glm</code></a></li>
<li class="chapter" data-level="18.10.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#refitting-the-overdispersed-poisson-regression-with-glm"><i class="fa fa-check"></i><b>18.10.2</b> Refitting the overdispersed Poisson regression with <code>Glm</code></a></li>
<li class="chapter" data-level="18.10.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#anova-on-a-glm-fit"><i class="fa fa-check"></i><b>18.10.3</b> ANOVA on a <code>Glm</code> fit</a></li>
<li class="chapter" data-level="18.10.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#ggplots-from-glm-fit"><i class="fa fa-check"></i><b>18.10.4</b> ggplots from <code>Glm</code> fit</a></li>
<li class="chapter" data-level="18.10.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#summary-of-a-glm-fit"><i class="fa fa-check"></i><b>18.10.5</b> Summary of a <code>Glm</code> fit</a></li>
<li class="chapter" data-level="18.10.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#plot-of-the-summary"><i class="fa fa-check"></i><b>18.10.6</b> Plot of the Summary</a></li>
<li class="chapter" data-level="18.10.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#nomogram-of-a-glm-fit"><i class="fa fa-check"></i><b>18.10.7</b> Nomogram of a <code>Glm</code> fit</a></li>
</ul></li>
<li class="chapter" data-level="18.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#negative-binomial-model"><i class="fa fa-check"></i><b>18.11</b> Negative Binomial Model</a><ul>
<li class="chapter" data-level="18.11.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-4"><i class="fa fa-check"></i><b>18.11.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.11.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-with-the-raw-poisson-model"><i class="fa fa-check"></i><b>18.11.2</b> Comparison with the (raw) Poisson model</a></li>
<li class="chapter" data-level="18.11.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-4"><i class="fa fa-check"></i><b>18.11.3</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.11.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpretation-of-coefficients-in-terms-of-irrs"><i class="fa fa-check"></i><b>18.11.4</b> Interpretation of Coefficients in terms of IRRs</a></li>
<li class="chapter" data-level="18.11.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-4"><i class="fa fa-check"></i><b>18.11.5</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.11.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-4"><i class="fa fa-check"></i><b>18.11.6</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.11.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-negative-binomial-model"><i class="fa fa-check"></i><b>18.11.7</b> Rootogram for Negative Binomial model</a></li>
<li class="chapter" data-level="18.11.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#simulating-what-the-negative-binomial-model-predicts"><i class="fa fa-check"></i><b>18.11.8</b> Simulating what the Negative Binomial model predicts</a></li>
<li class="chapter" data-level="18.11.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-loglikelihood-values-4"><i class="fa fa-check"></i><b>18.11.9</b> Specify the R<sup>2</sup> and log(likelihood) values</a></li>
<li class="chapter" data-level="18.11.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-4"><i class="fa fa-check"></i><b>18.11.10</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.11.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-4"><i class="fa fa-check"></i><b>18.11.11</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.12" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-problem-too-few-zeros"><i class="fa fa-check"></i><b>18.12</b> The Problem: Too Few Zeros</a></li>
<li class="chapter" data-level="18.13" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-zero-inflated-poisson-regression-model"><i class="fa fa-check"></i><b>18.13</b> The Zero-Inflated Poisson Regression Model</a><ul>
<li class="chapter" data-level="18.13.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-null-model"><i class="fa fa-check"></i><b>18.13.1</b> Comparison to a null model</a></li>
<li class="chapter" data-level="18.13.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-poisson-model-with-the-vuong-test"><i class="fa fa-check"></i><b>18.13.2</b> Comparison to a Poisson Model with the Vuong test</a></li>
<li class="chapter" data-level="18.13.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-5"><i class="fa fa-check"></i><b>18.13.3</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.13.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-5"><i class="fa fa-check"></i><b>18.13.4</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.13.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-5"><i class="fa fa-check"></i><b>18.13.5</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.13.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-5"><i class="fa fa-check"></i><b>18.13.6</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.13.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#modeled-number-of-zero-counts"><i class="fa fa-check"></i><b>18.13.7</b> Modeled Number of Zero Counts</a></li>
<li class="chapter" data-level="18.13.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-zip-model"><i class="fa fa-check"></i><b>18.13.8</b> Rootogram for ZIP model</a></li>
<li class="chapter" data-level="18.13.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values"><i class="fa fa-check"></i><b>18.13.9</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.13.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-5"><i class="fa fa-check"></i><b>18.13.10</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.13.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-5"><i class="fa fa-check"></i><b>18.13.11</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.14" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-zero-inflated-negative-binomial-regression-model"><i class="fa fa-check"></i><b>18.14</b> The Zero-Inflated Negative Binomial Regression Model</a><ul>
<li class="chapter" data-level="18.14.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-null-model-1"><i class="fa fa-check"></i><b>18.14.1</b> Comparison to a null model</a></li>
<li class="chapter" data-level="18.14.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-negative-binomial-model-vuong-test"><i class="fa fa-check"></i><b>18.14.2</b> Comparison to a Negative Binomial Model: Vuong test</a></li>
<li class="chapter" data-level="18.14.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-6"><i class="fa fa-check"></i><b>18.14.3</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.14.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-6"><i class="fa fa-check"></i><b>18.14.4</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.14.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-6"><i class="fa fa-check"></i><b>18.14.5</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.14.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-6"><i class="fa fa-check"></i><b>18.14.6</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.14.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#modeled-number-of-zero-counts-1"><i class="fa fa-check"></i><b>18.14.7</b> Modeled Number of Zero Counts</a></li>
<li class="chapter" data-level="18.14.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-zero-inflated-negative-binomial-model"><i class="fa fa-check"></i><b>18.14.8</b> Rootogram for Zero-Inflated Negative Binomial model</a></li>
<li class="chapter" data-level="18.14.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values-1"><i class="fa fa-check"></i><b>18.14.9</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.14.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-6"><i class="fa fa-check"></i><b>18.14.10</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.14.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-6"><i class="fa fa-check"></i><b>18.14.11</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.15" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-hurdle-model-with-poisson"><i class="fa fa-check"></i><b>18.15</b> A “hurdle” model (with Poisson)</a><ul>
<li class="chapter" data-level="18.15.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-null-model-2"><i class="fa fa-check"></i><b>18.15.1</b> Comparison to a null model</a></li>
<li class="chapter" data-level="18.15.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-poisson-model-vuong-test"><i class="fa fa-check"></i><b>18.15.2</b> Comparison to a Poisson Model: Vuong test</a></li>
<li class="chapter" data-level="18.15.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-zero-inflated-poisson-model-vuong-test"><i class="fa fa-check"></i><b>18.15.3</b> Comparison to a Zero-Inflated Poisson Model: Vuong test</a></li>
<li class="chapter" data-level="18.15.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-7"><i class="fa fa-check"></i><b>18.15.4</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.15.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-7"><i class="fa fa-check"></i><b>18.15.5</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.15.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-7"><i class="fa fa-check"></i><b>18.15.6</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.15.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-7"><i class="fa fa-check"></i><b>18.15.7</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.15.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#modeled-number-of-zero-counts-2"><i class="fa fa-check"></i><b>18.15.8</b> Modeled Number of Zero Counts</a></li>
<li class="chapter" data-level="18.15.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-hurdle-model"><i class="fa fa-check"></i><b>18.15.9</b> Rootogram for Hurdle Model</a></li>
<li class="chapter" data-level="18.15.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#understanding-the-modeled-counts-in-detail"><i class="fa fa-check"></i><b>18.15.10</b> Understanding the Modeled Counts in Detail</a></li>
<li class="chapter" data-level="18.15.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values-2"><i class="fa fa-check"></i><b>18.15.11</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.15.12" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-7"><i class="fa fa-check"></i><b>18.15.12</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.15.13" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-7"><i class="fa fa-check"></i><b>18.15.13</b> Predictions for Harry and Sally</a></li>
</ul></li>
<li class="chapter" data-level="18.16" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-hurdle-model-with-negative-binomial-for-overdispersion"><i class="fa fa-check"></i><b>18.16</b> A “hurdle” model (with negative binomial for overdispersion)</a><ul>
<li class="chapter" data-level="18.16.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-null-model-3"><i class="fa fa-check"></i><b>18.16.1</b> Comparison to a null model</a></li>
<li class="chapter" data-level="18.16.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-negative-binomial-model-vuong-test-1"><i class="fa fa-check"></i><b>18.16.2</b> Comparison to a Negative Binomial Model: Vuong test</a></li>
<li class="chapter" data-level="18.16.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparison-to-a-zero-inflated-nb-model-vuong-test"><i class="fa fa-check"></i><b>18.16.3</b> Comparison to a Zero-Inflated NB Model: Vuong test</a></li>
<li class="chapter" data-level="18.16.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#comparing-the-hurdle-models-with-aic-and-bic"><i class="fa fa-check"></i><b>18.16.4</b> Comparing the Hurdle Models with AIC and BIC</a></li>
<li class="chapter" data-level="18.16.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-8"><i class="fa fa-check"></i><b>18.16.5</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.16.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-8"><i class="fa fa-check"></i><b>18.16.6</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.16.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-8"><i class="fa fa-check"></i><b>18.16.7</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.16.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-8"><i class="fa fa-check"></i><b>18.16.8</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.16.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#rootogram-for-nb-hurdle-model"><i class="fa fa-check"></i><b>18.16.9</b> Rootogram for NB Hurdle Model</a></li>
<li class="chapter" data-level="18.16.10" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values-3"><i class="fa fa-check"></i><b>18.16.10</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.16.11" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-8"><i class="fa fa-check"></i><b>18.16.11</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.16.12" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-8"><i class="fa fa-check"></i><b>18.16.12</b> Predictions for Harry and Sally</a></li>
<li class="chapter" data-level="18.16.13" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#note-fitting-a-different-hurdle-model-for-counts-and-przero"><i class="fa fa-check"></i><b>18.16.13</b> Note: Fitting a Different Hurdle Model for Counts and Pr(zero)</a></li>
<li class="chapter" data-level="18.16.14" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#hanging-rootogram-for-this-new-hurdle-model"><i class="fa fa-check"></i><b>18.16.14</b> Hanging Rootogram for this new Hurdle Model</a></li>
</ul></li>
<li class="chapter" data-level="18.17" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#a-tobit-censored-regression-model"><i class="fa fa-check"></i><b>18.17</b> A Tobit (Censored) Regression Model</a><ul>
<li class="chapter" data-level="18.17.1" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#the-fitted-equation-9"><i class="fa fa-check"></i><b>18.17.1</b> The Fitted Equation</a></li>
<li class="chapter" data-level="18.17.2" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#interpreting-the-coefficients-9"><i class="fa fa-check"></i><b>18.17.2</b> Interpreting the Coefficients</a></li>
<li class="chapter" data-level="18.17.3" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#testing-the-predictors-9"><i class="fa fa-check"></i><b>18.17.3</b> Testing the Predictors</a></li>
<li class="chapter" data-level="18.17.4" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#store-fitted-values-and-residuals-9"><i class="fa fa-check"></i><b>18.17.4</b> Store fitted values and residuals</a></li>
<li class="chapter" data-level="18.17.5" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#building-something-like-a-rootogram"><i class="fa fa-check"></i><b>18.17.5</b> Building Something Like a Rootogram</a></li>
<li class="chapter" data-level="18.17.6" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#tables-of-the-observed-and-fitted-physhealth-from-tobit"><i class="fa fa-check"></i><b>18.17.6</b> Tables of the Observed and Fitted <code>physhealth</code> from Tobit</a></li>
<li class="chapter" data-level="18.17.7" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#specify-the-r2-and-log-likelihood-values-4"><i class="fa fa-check"></i><b>18.17.7</b> Specify the R<sup>2</sup> and log (likelihood) values</a></li>
<li class="chapter" data-level="18.17.8" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#check-model-assumptions-9"><i class="fa fa-check"></i><b>18.17.8</b> Check model assumptions</a></li>
<li class="chapter" data-level="18.17.9" data-path="modeling-a-count-outcome-in-ohio-smart.html"><a href="modeling-a-count-outcome-in-ohio-smart.html#predictions-for-harry-and-sally-9"><i class="fa fa-check"></i><b>18.17.9</b> Predictions for Harry and Sally</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><i class="fa fa-check"></i><b>19</b> Modeling an Ordinal Categorical Outcome in Ohio SMART</a><ul>
<li class="chapter" data-level="19.1" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#preliminaries-1"><i class="fa fa-check"></i><b>19.1</b> Preliminaries</a></li>
<li class="chapter" data-level="19.2" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#a-subset-of-the-ohio-smart-data-1"><i class="fa fa-check"></i><b>19.2</b> A subset of the Ohio SMART data</a><ul>
<li class="chapter" data-level="19.2.1" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#several-ways-of-storing-multi-categorical-data"><i class="fa fa-check"></i><b>19.2.1</b> Several Ways of Storing Multi-Categorical data</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#building-cross-tabulations"><i class="fa fa-check"></i><b>19.3</b> Building Cross-Tabulations</a><ul>
<li class="chapter" data-level="19.3.1" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#using-base-table-functions"><i class="fa fa-check"></i><b>19.3.1</b> Using base <code>table</code> functions</a></li>
<li class="chapter" data-level="19.3.2" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#using-xtabs"><i class="fa fa-check"></i><b>19.3.2</b> Using <code>xtabs</code></a></li>
<li class="chapter" data-level="19.3.3" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#storing-a-table-in-a-tibble"><i class="fa fa-check"></i><b>19.3.3</b> Storing a table in a tibble</a></li>
<li class="chapter" data-level="19.3.4" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#using-crosstable-from-the-gmodels-package"><i class="fa fa-check"></i><b>19.3.4</b> Using <code>CrossTable</code> from the <code>gmodels</code> package</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#graphing-categorical-data"><i class="fa fa-check"></i><b>19.4</b> Graphing Categorical Data</a><ul>
<li class="chapter" data-level="19.4.1" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#a-bar-chart-for-a-single-variable"><i class="fa fa-check"></i><b>19.4.1</b> A Bar Chart for a Single Variable</a></li>
<li class="chapter" data-level="19.4.2" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#a-counts-chart-for-a-2-way-cross-tabulation"><i class="fa fa-check"></i><b>19.4.2</b> A Counts Chart for a 2-Way Cross-Tabulation</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#building-a-model-for-genh-using-sleephrs"><i class="fa fa-check"></i><b>19.5</b> Building a Model for <code>genh</code> using <code>sleephrs</code></a><ul>
<li class="chapter" data-level="19.5.1" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#a-little-eda"><i class="fa fa-check"></i><b>19.5.1</b> A little EDA</a></li>
<li class="chapter" data-level="19.5.2" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#describing-the-proportional-odds-cumulative-logit-model"><i class="fa fa-check"></i><b>19.5.2</b> Describing the Proportional-Odds Cumulative Logit Model</a></li>
<li class="chapter" data-level="19.5.3" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#fitting-a-proportional-odds-logistic-regression-with-polr"><i class="fa fa-check"></i><b>19.5.3</b> Fitting a Proportional Odds Logistic Regression with <code>polr</code></a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#interpreting-model-m1"><i class="fa fa-check"></i><b>19.6</b> Interpreting Model <code>m1</code></a><ul>
<li class="chapter" data-level="19.6.1" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#looking-at-predictions"><i class="fa fa-check"></i><b>19.6.1</b> Looking at Predictions</a></li>
<li class="chapter" data-level="19.6.2" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#making-predictions-for-harry-and-sally-with-predict"><i class="fa fa-check"></i><b>19.6.2</b> Making Predictions for Harry (and Sally) with <code>predict</code></a></li>
<li class="chapter" data-level="19.6.3" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#predicting-the-actual-classification-of-genh"><i class="fa fa-check"></i><b>19.6.3</b> Predicting the actual classification of <code>genh</code></a></li>
<li class="chapter" data-level="19.6.4" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#a-cross-tabuation-of-predictions"><i class="fa fa-check"></i><b>19.6.4</b> A Cross-Tabuation of Predictions?</a></li>
<li class="chapter" data-level="19.6.5" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#the-fitted-model-equations"><i class="fa fa-check"></i><b>19.6.5</b> The Fitted Model Equations</a></li>
<li class="chapter" data-level="19.6.6" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#interpreting-the-sleephrs-coefficient"><i class="fa fa-check"></i><b>19.6.6</b> Interpreting the <code>sleephrs</code> coefficient</a></li>
<li class="chapter" data-level="19.6.7" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#exponentiating-the-slope-coefficient-to-facilitate-interpretation"><i class="fa fa-check"></i><b>19.6.7</b> Exponentiating the Slope Coefficient to facilitate Interpretation</a></li>
<li class="chapter" data-level="19.6.8" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#comparison-to-a-null-model-4"><i class="fa fa-check"></i><b>19.6.8</b> Comparison to a Null Model</a></li>
</ul></li>
<li class="chapter" data-level="19.7" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#the-assumption-of-proportional-odds"><i class="fa fa-check"></i><b>19.7</b> The Assumption of Proportional Odds</a><ul>
<li class="chapter" data-level="19.7.1" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#testing-the-proportional-odds-assumption"><i class="fa fa-check"></i><b>19.7.1</b> Testing the Proportional Odds Assumption</a></li>
</ul></li>
<li class="chapter" data-level="19.8" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#can-model-m1-be-fit-using-rms-tools"><i class="fa fa-check"></i><b>19.8</b> Can model <code>m1</code> be fit using <code>rms</code> tools?</a></li>
<li class="chapter" data-level="19.9" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#building-a-three-predictor-model"><i class="fa fa-check"></i><b>19.9</b> Building a Three-Predictor Model</a><ul>
<li class="chapter" data-level="19.9.1" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#scatterplot-matrix"><i class="fa fa-check"></i><b>19.9.1</b> Scatterplot Matrix</a></li>
<li class="chapter" data-level="19.9.2" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#our-three-predictor-model-m2"><i class="fa fa-check"></i><b>19.9.2</b> Our Three-Predictor Model, <code>m2</code></a></li>
<li class="chapter" data-level="19.9.3" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#does-the-three-predictor-model-outperform-m1"><i class="fa fa-check"></i><b>19.9.3</b> Does the three-predictor model outperform <code>m1</code>?</a></li>
<li class="chapter" data-level="19.9.4" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#wald-tests-for-individual-predictors"><i class="fa fa-check"></i><b>19.9.4</b> Wald tests for individual predictors</a></li>
<li class="chapter" data-level="19.9.5" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#a-cross-tabuation-of-predictions-1"><i class="fa fa-check"></i><b>19.9.5</b> A Cross-Tabuation of Predictions?</a></li>
<li class="chapter" data-level="19.9.6" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#interpreting-the-effect-sizes"><i class="fa fa-check"></i><b>19.9.6</b> Interpreting the Effect Sizes</a></li>
<li class="chapter" data-level="19.9.7" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#quality-of-the-model-fit"><i class="fa fa-check"></i><b>19.9.7</b> Quality of the Model Fit</a></li>
<li class="chapter" data-level="19.9.8" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#validating-the-summary-statistics-in-m2_lrm"><i class="fa fa-check"></i><b>19.9.8</b> Validating the Summary Statistics in <code>m2_lrm</code></a></li>
<li class="chapter" data-level="19.9.9" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#testing-the-proportional-odds-assumption-1"><i class="fa fa-check"></i><b>19.9.9</b> Testing the Proportional Odds Assumption</a></li>
<li class="chapter" data-level="19.9.10" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#plotting-the-fitted-model"><i class="fa fa-check"></i><b>19.9.10</b> Plotting the Fitted Model</a></li>
</ul></li>
<li class="chapter" data-level="19.10" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#a-larger-model-including-income-group"><i class="fa fa-check"></i><b>19.10</b> A Larger Model, including income group</a><ul>
<li class="chapter" data-level="19.10.1" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#cross-tabulation-of-predictedobserved-classifications"><i class="fa fa-check"></i><b>19.10.1</b> Cross-Tabulation of Predicted/Observed Classifications</a></li>
<li class="chapter" data-level="19.10.2" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#nomogram-1"><i class="fa fa-check"></i><b>19.10.2</b> Nomogram</a></li>
<li class="chapter" data-level="19.10.3" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#using-predict-and-showing-mean-prediction-on-1-5-scale-1"><i class="fa fa-check"></i><b>19.10.3</b> Using Predict and showing mean prediction on 1-5 scale</a></li>
<li class="chapter" data-level="19.10.4" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#validating-the-summary-statistics-in-m3_lrm"><i class="fa fa-check"></i><b>19.10.4</b> Validating the Summary Statistics in <code>m3_lrm</code></a></li>
</ul></li>
<li class="chapter" data-level="19.11" data-path="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html"><a href="modeling-an-ordinal-categorical-outcome-in-ohio-smart.html#references-for-this-chapter"><i class="fa fa-check"></i><b>19.11</b> References for this Chapter</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>20</b> Analyzing Literary Styles with Multinomial Logistic Regression</a><ul>
<li class="chapter" data-level="20.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#the-authorship-example"><i class="fa fa-check"></i><b>20.1</b> The Authorship Example</a></li>
<li class="chapter" data-level="20.2" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#focus-on-11-key-words"><i class="fa fa-check"></i><b>20.2</b> Focus on 11 key words</a><ul>
<li class="chapter" data-level="20.2.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#side-by-side-boxplots"><i class="fa fa-check"></i><b>20.2.1</b> Side by Side Boxplots</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#a-multinomial-logistic-regression-model"><i class="fa fa-check"></i><b>20.3</b> A Multinomial Logistic Regression Model</a><ul>
<li class="chapter" data-level="20.3.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#testing-model-1"><i class="fa fa-check"></i><b>20.3.1</b> Testing Model 1</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#model-2"><i class="fa fa-check"></i><b>20.4</b> Model 2</a><ul>
<li class="chapter" data-level="20.4.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#comparing-model-2-to-model-1"><i class="fa fa-check"></i><b>20.4.1</b> Comparing Model 2 to Model 1</a></li>
<li class="chapter" data-level="20.4.2" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#testing-model-2"><i class="fa fa-check"></i><b>20.4.2</b> Testing Model 2</a></li>
<li class="chapter" data-level="20.4.3" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#a-little-history"><i class="fa fa-check"></i><b>20.4.3</b> A little history</a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#classification-table"><i class="fa fa-check"></i><b>20.5</b> Classification Table</a></li>
<li class="chapter" data-level="20.6" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#probability-curves-based-on-a-single-predictor"><i class="fa fa-check"></i><b>20.6</b> Probability Curves based on a Single Predictor</a><ul>
<li class="chapter" data-level="20.6.1" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#produce-the-plot-of-estimated-probabilities-based-on-been-counts"><i class="fa fa-check"></i><b>20.6.1</b> Produce the Plot of Estimated Probabilities based on “been” counts</a></li>
<li class="chapter" data-level="20.6.2" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#boxplot-of-been-counts"><i class="fa fa-check"></i><b>20.6.2</b> Boxplot of “been” counts</a></li>
<li class="chapter" data-level="20.6.3" data-path="analyzing-literary-styles-with-multinomial-logistic-regression.html"><a href="analyzing-literary-styles-with-multinomial-logistic-regression.html#quote-sources"><i class="fa fa-check"></i><b>20.6.3</b> Quote Sources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html"><i class="fa fa-check"></i><b>21</b> Exploring Time To Event / Survival Data</a><ul>
<li class="chapter" data-level="21.1" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#an-outline-of-key-topics-discussed-in-these-notes"><i class="fa fa-check"></i><b>21.1</b> An Outline of Key Topics Discussed in these Notes</a></li>
<li class="chapter" data-level="21.2" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#foundations-of-survival-analysis"><i class="fa fa-check"></i><b>21.2</b> Foundations of Survival Analysis</a><ul>
<li class="chapter" data-level="21.2.1" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#the-survival-function-st"><i class="fa fa-check"></i><b>21.2.1</b> The Survival Function, <span class="math inline">\(S(t)\)</span></a></li>
<li class="chapter" data-level="21.2.2" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#kaplan-meier-estimator-of-the-survival-function"><i class="fa fa-check"></i><b>21.2.2</b> Kaplan-Meier Estimator of the Survival Function</a></li>
<li class="chapter" data-level="21.2.3" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#creating-a-survival-object-in-r"><i class="fa fa-check"></i><b>21.2.3</b> Creating a Survival Object in R</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#a-first-example-recurrent-lobar-intracerebral-hemorrhage"><i class="fa fa-check"></i><b>21.3</b> A First Example: Recurrent Lobar Intracerebral Hemorrhage</a><ul>
<li class="chapter" data-level="21.3.1" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#building-a-survival-object"><i class="fa fa-check"></i><b>21.3.1</b> Building a Survival Object</a></li>
<li class="chapter" data-level="21.3.2" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#kaplan-meier-estimate-of-the-survival-function"><i class="fa fa-check"></i><b>21.3.2</b> Kaplan-Meier Estimate of the Survival Function</a></li>
<li class="chapter" data-level="21.3.3" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#the-kaplan-meier-plot-using-base-r"><i class="fa fa-check"></i><b>21.3.3</b> The Kaplan-Meier Plot, using Base R</a></li>
<li class="chapter" data-level="21.3.4" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#using-survminer-to-draw-survival-curves"><i class="fa fa-check"></i><b>21.3.4</b> Using <code>survminer</code> to draw survival curves</a></li>
<li class="chapter" data-level="21.3.5" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#a-fancy-k-m-plot-with-a-number-at-risk-table"><i class="fa fa-check"></i><b>21.3.5</b> A “Fancy” K-M Plot with a number at risk table</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#comparing-survival-across-the-two-genotypes"><i class="fa fa-check"></i><b>21.4</b> Comparing Survival Across the Two Genotypes</a><ul>
<li class="chapter" data-level="21.4.1" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#kaplan-meier-survival-function-estimates-by-genotype"><i class="fa fa-check"></i><b>21.4.1</b> Kaplan-Meier Survival Function Estimates, by Genotype</a></li>
<li class="chapter" data-level="21.4.2" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#plotting-the-k-m-comparison-with-ggsurvplot"><i class="fa fa-check"></i><b>21.4.2</b> Plotting the K-M comparison with <code>ggsurvplot</code></a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#testing-the-difference-between-two-survival-curves"><i class="fa fa-check"></i><b>21.5</b> Testing the difference between two survival curves</a><ul>
<li class="chapter" data-level="21.5.1" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#alternative-log-rank-tests"><i class="fa fa-check"></i><b>21.5.1</b> Alternative log rank tests</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#a-fancy-k-m-plot-with-a-number-at-risk-table-1"><i class="fa fa-check"></i><b>21.6</b> A “Fancy” K-M Plot with a number at risk table</a><ul>
<li class="chapter" data-level="21.6.1" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#customizing-the-kaplan-meier-plot-presentation-further"><i class="fa fa-check"></i><b>21.6.1</b> Customizing the Kaplan-Meier Plot Presentation Further</a></li>
</ul></li>
<li class="chapter" data-level="21.7" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#the-hazard-function"><i class="fa fa-check"></i><b>21.7</b> The Hazard Function</a><ul>
<li class="chapter" data-level="21.7.1" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#the-inverse-kaplan-meier-estimator-of-ht"><i class="fa fa-check"></i><b>21.7.1</b> The Inverse Kaplan-Meier Estimator of <span class="math inline">\(H(t)\)</span></a></li>
<li class="chapter" data-level="21.7.2" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#cumulative-hazard-function-from-inverse-k-m"><i class="fa fa-check"></i><b>21.7.2</b> Cumulative Hazard Function from Inverse K-M</a></li>
<li class="chapter" data-level="21.7.3" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#the-nelson-aalen-estimator-of-ht"><i class="fa fa-check"></i><b>21.7.3</b> The Nelson-Aalen Estimator of <span class="math inline">\(H(t)\)</span></a></li>
<li class="chapter" data-level="21.7.4" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#convert-wide-data-to-long"><i class="fa fa-check"></i><b>21.7.4</b> Convert Wide Data to Long</a></li>
<li class="chapter" data-level="21.7.5" data-path="exploring-time-to-event-survival-data.html"><a href="exploring-time-to-event-survival-data.html#plot-comparison-of-hazard-estimates"><i class="fa fa-check"></i><b>21.7.5</b> Plot Comparison of Hazard Estimates</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html"><i class="fa fa-check"></i><b>22</b> Cox Regression Models for Survival Data: Example 1</a><ul>
<li class="chapter" data-level="22.1" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#sources-used-in-building-this-material"><i class="fa fa-check"></i><b>22.1</b> Sources used in building this material</a></li>
<li class="chapter" data-level="22.2" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#fitting-a-cox-model-in-r-with-coxph"><i class="fa fa-check"></i><b>22.2</b> Fitting a Cox Model in R with <code>coxph</code></a><ul>
<li class="chapter" data-level="22.2.1" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#summarizing-the-fit"><i class="fa fa-check"></i><b>22.2.1</b> Summarizing the Fit</a></li>
<li class="chapter" data-level="22.2.2" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#glancing-at-the-model"><i class="fa fa-check"></i><b>22.2.2</b> Glancing at the model?</a></li>
<li class="chapter" data-level="22.2.3" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#plot-the-baseline-survival-function"><i class="fa fa-check"></i><b>22.2.3</b> Plot the baseline survival function</a></li>
<li class="chapter" data-level="22.2.4" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#plot-the-genotype-effect"><i class="fa fa-check"></i><b>22.2.4</b> Plot the genotype effect</a></li>
<li class="chapter" data-level="22.2.5" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#testing-the-key-assumption-proportional-hazards"><i class="fa fa-check"></i><b>22.2.5</b> Testing the Key Assumption: Proportional Hazards</a></li>
<li class="chapter" data-level="22.2.6" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#plotting-the-cox.zph-results-for-the-cfit-model"><i class="fa fa-check"></i><b>22.2.6</b> Plotting the <code>cox.zph</code> results for the <code>cfit</code> model</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#fitting-a-cox-model-using-cph-from-the-rms-package"><i class="fa fa-check"></i><b>22.3</b> Fitting a Cox Model using <code>cph</code> from the <code>rms</code> package</a><ul>
<li class="chapter" data-level="22.3.1" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#the-main-cph-results"><i class="fa fa-check"></i><b>22.3.1</b> The Main <code>cph</code> results</a></li>
<li class="chapter" data-level="22.3.2" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#using-anova-with-cph"><i class="fa fa-check"></i><b>22.3.2</b> Using <code>anova</code> with <code>cph</code></a></li>
<li class="chapter" data-level="22.3.3" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#effect-sizes-after-cph-fit"><i class="fa fa-check"></i><b>22.3.3</b> Effect Sizes after <code>cph</code> fit</a></li>
<li class="chapter" data-level="22.3.4" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#validating-cph-summaries"><i class="fa fa-check"></i><b>22.3.4</b> Validating <code>cph</code> summaries</a></li>
<li class="chapter" data-level="22.3.5" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#plotting-survival-functions-for-each-genotype"><i class="fa fa-check"></i><b>22.3.5</b> Plotting Survival Functions for each Genotype</a></li>
<li class="chapter" data-level="22.3.6" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#genotypes-effect-on-log-relative-hazard"><i class="fa fa-check"></i><b>22.3.6</b> Genotype’s effect on log relative hazard</a></li>
<li class="chapter" data-level="22.3.7" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#nomogram-of-our-simple-hem-model"><i class="fa fa-check"></i><b>22.3.7</b> Nomogram of our simple <code>hem</code> model</a></li>
<li class="chapter" data-level="22.3.8" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#assessing-the-proportional-hazards-assumption"><i class="fa fa-check"></i><b>22.3.8</b> Assessing the Proportional Hazards Assumption</a></li>
<li class="chapter" data-level="22.3.9" data-path="cox-regression-models-for-survival-data-example-1.html"><a href="cox-regression-models-for-survival-data-example-1.html#plot-to-check-ph-assumption"><i class="fa fa-check"></i><b>22.3.9</b> Plot to Check PH Assumption</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html"><i class="fa fa-check"></i><b>23</b> Cox Regression Models for Survival Data: Example 2</a><ul>
<li class="chapter" data-level="23.1" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#a-second-example-the-leukem-data"><i class="fa fa-check"></i><b>23.1</b> A Second Example: The <code>leukem</code> data</a><ul>
<li class="chapter" data-level="23.1.1" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#creating-our-response-a-survival-time-object"><i class="fa fa-check"></i><b>23.1.1</b> Creating our response: A survival time object</a></li>
<li class="chapter" data-level="23.1.2" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#models-well-fit"><i class="fa fa-check"></i><b>23.1.2</b> Models We’ll Fit</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#model-a-coxph-model-for-survival-time-using-age-at-diagnosis"><i class="fa fa-check"></i><b>23.2</b> Model A: <code>coxph</code> Model for Survival Time using <code>age</code> at diagnosis</a><ul>
<li class="chapter" data-level="23.2.1" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#plotting-the-survival-curve-implied-by-model-a"><i class="fa fa-check"></i><b>23.2.1</b> Plotting the Survival Curve implied by Model A</a></li>
<li class="chapter" data-level="23.2.2" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#testing-the-proportional-hazards-assumption"><i class="fa fa-check"></i><b>23.2.2</b> Testing the Proportional Hazards Assumption</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#building-model-a-with-cph-for-the-leukem-data"><i class="fa fa-check"></i><b>23.3</b> Building Model A with <code>cph</code> for the <code>leukem</code> data</a><ul>
<li class="chapter" data-level="23.3.1" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#plotting-the-age-effect-implied-by-our-model."><i class="fa fa-check"></i><b>23.3.1</b> Plotting the <code>age</code> effect implied by our model.</a></li>
<li class="chapter" data-level="23.3.2" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#survival-plots-kaplan-meier-of-the-age-effect"><i class="fa fa-check"></i><b>23.3.2</b> Survival Plots (Kaplan-Meier) of the <code>age</code> effect</a></li>
<li class="chapter" data-level="23.3.3" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#anova-test-for-the-cph-built-model-for-leukem"><i class="fa fa-check"></i><b>23.3.3</b> ANOVA test for the <code>cph</code>-built model for <code>leukem</code></a></li>
<li class="chapter" data-level="23.3.4" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#summarizing-the-effect-sizes-from-moda_cph"><i class="fa fa-check"></i><b>23.3.4</b> Summarizing the Effect Sizes from <code>modA_cph</code></a></li>
<li class="chapter" data-level="23.3.5" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#validating-the-cox-model-summary-statistics"><i class="fa fa-check"></i><b>23.3.5</b> Validating the Cox Model Summary Statistics</a></li>
<li class="chapter" data-level="23.3.6" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#looking-for-influential-points"><i class="fa fa-check"></i><b>23.3.6</b> Looking for Influential Points</a></li>
<li class="chapter" data-level="23.3.7" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#checking-the-proportional-hazards-assumption"><i class="fa fa-check"></i><b>23.3.7</b> Checking the Proportional Hazards Assumption</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#model-b-fitting-a-5-predictor-model-with-coxph"><i class="fa fa-check"></i><b>23.4</b> Model B: Fitting a 5-Predictor Model with <code>coxph</code></a><ul>
<li class="chapter" data-level="23.4.1" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#interpreting-the-results-from-model-b"><i class="fa fa-check"></i><b>23.4.1</b> Interpreting the Results from Model B</a></li>
<li class="chapter" data-level="23.4.2" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#plotting-the-survival-curve-implied-by-model-b"><i class="fa fa-check"></i><b>23.4.2</b> Plotting the Survival Curve implied by Model B</a></li>
<li class="chapter" data-level="23.4.3" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#plotting-the-cumulative-hazard-implied-by-model-b"><i class="fa fa-check"></i><b>23.4.3</b> Plotting the Cumulative Hazard implied by Model B</a></li>
<li class="chapter" data-level="23.4.4" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#testing-the-proportional-hazards-assumption-1"><i class="fa fa-check"></i><b>23.4.4</b> Testing the Proportional Hazards Assumption</a></li>
<li class="chapter" data-level="23.4.5" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#assessing-collinearity"><i class="fa fa-check"></i><b>23.4.5</b> Assessing Collinearity</a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#model-b2-a-stepwise-reduction-of-model-b"><i class="fa fa-check"></i><b>23.5</b> Model B2: A Stepwise Reduction of Model B</a><ul>
<li class="chapter" data-level="23.5.1" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#the-survival-curve-implied-by-model-b2"><i class="fa fa-check"></i><b>23.5.1</b> The Survival Curve implied by Model B2</a></li>
<li class="chapter" data-level="23.5.2" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#checking-proportional-hazards-for-model-b2"><i class="fa fa-check"></i><b>23.5.2</b> Checking Proportional Hazards for Model B2</a></li>
</ul></li>
<li class="chapter" data-level="23.6" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#model-c-using-a-spearman-plot-to-pick-a-model"><i class="fa fa-check"></i><b>23.6</b> Model C: Using a Spearman Plot to pick a model</a><ul>
<li class="chapter" data-level="23.6.1" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#fitting-model-c"><i class="fa fa-check"></i><b>23.6.1</b> Fitting Model C</a></li>
<li class="chapter" data-level="23.6.2" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#anova-for-model-c"><i class="fa fa-check"></i><b>23.6.2</b> ANOVA for Model C</a></li>
<li class="chapter" data-level="23.6.3" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#summarizing-model-c-effect-sizes"><i class="fa fa-check"></i><b>23.6.3</b> Summarizing Model C Effect Sizes</a></li>
<li class="chapter" data-level="23.6.4" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#plotting-the-diagnosis-age-effect-in-model-c"><i class="fa fa-check"></i><b>23.6.4</b> Plotting the diagnosis <code>age</code> effect in Model C</a></li>
<li class="chapter" data-level="23.6.5" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#survival-plot-associated-with-model-c"><i class="fa fa-check"></i><b>23.6.5</b> Survival Plot associated with Model C</a></li>
<li class="chapter" data-level="23.6.6" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#checking-the-proportional-hazards-assumption-1"><i class="fa fa-check"></i><b>23.6.6</b> Checking the Proportional Hazards Assumption</a></li>
<li class="chapter" data-level="23.6.7" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#model-c-nomogram"><i class="fa fa-check"></i><b>23.6.7</b> Model C Nomogram</a></li>
<li class="chapter" data-level="23.6.8" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#validating-model-cs-summary-statistics"><i class="fa fa-check"></i><b>23.6.8</b> Validating Model C’s Summary Statistics</a></li>
<li class="chapter" data-level="23.6.9" data-path="cox-regression-models-for-survival-data-example-2.html"><a href="cox-regression-models-for-survival-data-example-2.html#calibration-of-model-c-12-month-survival-estimates"><i class="fa fa-check"></i><b>23.6.9</b> Calibration of Model C (12-month survival estimates)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science for Biological, Medical and Health Research: Notes for 432</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression-and-the-resect-data" class="section level1">
<h1><span class="header-section-number">Chapter 13</span> Logistic Regression and the <code>resect</code> data</h1>
<div id="the-resect-data" class="section level2">
<h2><span class="header-section-number">13.1</span> The <code>resect</code> data</h2>
<p>My source for these data was <span class="citation">Riffenburgh (<a href="#ref-Riffenburgh2006">2006</a>)</span>. The data describe 134 patients who had undergone resection of the tracheal carina (most often this is done to address tumors in the trachea), and the <code>resect.csv</code> data file contains the following variables:</p>
<ul>
<li><code>id</code> = a patient ID #,</li>
<li><code>age</code>= the patient’s age at surgery,</li>
<li><code>prior</code> = prior tracheal surgery (1 = yes, 0 = no),</li>
<li><code>resection</code> = extent of the resection (in cm),</li>
<li><code>intubated</code> = whether intubation was required at the end of surgery (1 = yes, 0 = no), and</li>
<li><code>died</code> = the patient’s death status (1 = dead, 0 = alive).</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">resect <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(died) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">skim</span>(<span class="op">-</span>id)</code></pre></div>
<pre><code>Skim summary statistics
 n obs: 134 
 n variables: 6 
 group variables: died 

Variable type: integer 
 died  variable missing complete   n   mean    sd p0 p25 median p75 p100
    0       age       0      117 117 48.05  16.01  8  36     51  62   80
    0 intubated       0      117 117  0.068  0.25  0   0      0   0    1
    0     prior       0      117 117  0.24   0.43  0   0      0   0    1
    1       age       0       17  17 46.41  14.46 26  33     46  60   66
    1 intubated       0       17  17  0.65   0.49  0   0      1   1    1
    1     prior       0       17  17  0.35   0.49  0   0      0   1    1

Variable type: numeric 
 died  variable missing complete   n mean   sd p0 p25 median p75 p100
    0 resection       0      117 117 2.82 1.21  1 2      2.5 3.5    6
    1 resection       0       17  17 3.97 1     2 3.5    4   4.5    6</code></pre>
<p>We have no missing data, and 17 of the 134 patients died. Our goal will be to understand the characteristics of the patients, and how they relate to the binary outcome of interest, death.</p>
</div>
<div id="running-a-simple-logistic-regression-model" class="section level2">
<h2><span class="header-section-number">13.2</span> Running A Simple Logistic Regression Model</h2>
<p>In the most common scenario, a logistic regression model is used to predict a binary outcome (which can take on the values 0 or 1.) We will eventually fit a logistic regression model in two ways.</p>
<ol style="list-style-type: decimal">
<li>Through the <code>glm</code> function in the base package of R (similar to <code>lm</code> for linear regression)</li>
<li>Through the <code>lrm</code> function available in the <code>rms</code> package (similar to <code>ols</code> for linear regression)</li>
</ol>
<p>We’ll focus on the <code>glm</code> approach first, and save the <code>lrm</code> ideas for later in this Chapter.</p>
<div id="logistic-regression-can-be-harder-than-linear-regression" class="section level3">
<h3><span class="header-section-number">13.2.1</span> Logistic Regression Can Be Harder than Linear Regression</h3>
<ul>
<li>Logistic regression models are fitted using the method of maximum likelihood in <code>glm</code>, which requires multiple iterations until convergence is reached.</li>
<li>Logistic regression models are harder to interpret (for most people) than linear regressions.</li>
<li>Logistic regression models don’t have the same set of assumptions as linear models.</li>
<li>Logistic regression outcomes (yes/no) carry much less information than quantitative outcomes. As a result, fitting a reasonable logistic regression requires more data than a linear model of similar size.
<ul>
<li>The rule I learned in graduate school was that a logistic regression requires 100 observations to fit an intercept plus another 15 observations for each candidate predictor. That’s not terrible, but it’s a very large sample size.</li>
<li>Frank Harrell recommends that 96 observations + a function of the number of candidate predictors (which depends on the amount of variation in the predictors, but 15 x the number of such predictors isn’t too bad if the signal to noise ratio is pretty good) are required just to get reasonable confidence intervals around your predictions.
<ul>
<li>In a <a href="https://twitter.com/f2harrell/status/936230071219707913">twitter note</a>, Frank suggests that 96 + 8 times the number of candidate parameters might be reasonable so long as the smallest cell of interest (combination of an outcome and a split of the covariates) is 96 or more observations.</li>
</ul></li>
<li><span class="citation">Peduzzi et al. (<a href="#ref-Peduzzi1996">1996</a>)</span> suggest that if we let <span class="math inline">\(\pi\)</span> be the smaller of the proportions of “yes” or “no” cases in the population of interest, and <em>k</em> be the number of inputs under consideration, then <span class="math inline">\(N = 10k/\pi\)</span> is the minimum number of cases to include, except that if N &lt; 100 by this standard, you should increase it to 100, according to <span class="citation">Long (<a href="#ref-Long1997">1997</a>)</span>.
<ul>
<li>That suggests that if you have an outcome that happens 10% of the time, and you are running a model with 3 predictors, then you could get away with <span class="math inline">\((10 \times 3)/(0.10) = 300\)</span> observations, but if your outcome happened 40% of the time, you could get away with only <span class="math inline">\((10 \times 3)/(0.40) = 75\)</span> observations, which you’d round up to 100.</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="logistic-regression-using-glm" class="section level2">
<h2><span class="header-section-number">13.3</span> Logistic Regression using <code>glm</code></h2>
<p>We’ll begin by attempting to predict death based on the extent of the resection.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_modA &lt;-<span class="st"> </span><span class="kw">glm</span>(died <span class="op">~</span><span class="st"> </span>resection, <span class="dt">data=</span>resect, 
               <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>(<span class="dt">link=</span><span class="st">&quot;logit&quot;</span>))

res_modA</code></pre></div>
<pre><code>
Call:  glm(formula = died ~ resection, family = binomial(link = &quot;logit&quot;), 
    data = resect)

Coefficients:
(Intercept)    resection  
    -4.4337       0.7417  

Degrees of Freedom: 133 Total (i.e. Null);  132 Residual
Null Deviance:      101.9 
Residual Deviance: 89.49    AIC: 93.49</code></pre>
<p>Note that the <code>logit</code> link is the default approach with the <code>binomial</code> family, so we could also have used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_modA &lt;-<span class="st"> </span><span class="kw">glm</span>(died <span class="op">~</span><span class="st"> </span>resection, <span class="dt">data =</span> resect, 
                <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</code></pre></div>
<p>which yields the same model.</p>
<div id="interpreting-the-coefficients-of-a-logistic-regression-model-1" class="section level3">
<h3><span class="header-section-number">13.3.1</span> Interpreting the Coefficients of a Logistic Regression Model</h3>
<p>Our model is:</p>
<p><span class="math display">\[
logit(died = 1) = log\left(\frac{Pr(died = 1)}{1 - Pr(died = 1)}\right) = \beta_0 + \beta_1 x = -4.4337 + 0.7417 \times resection
\]</span></p>
<p>The predicted log odds of death for a subject with a resection of 4 cm is:</p>
<p><span class="math display">\[
log\left(\frac{Pr(died = 1)}{1 - Pr(died = 1)}\right) = -4.4337 + 0.7417 \times 4 = -1.467
\]</span></p>
<p>The predicted odds of death for a subject with a resection of 4 cm is thus:</p>
<p><span class="math display">\[
\frac{Pr(died = 1)}{1 - Pr(died = 1)} = e^{-4.4337 + 0.7417 \times 4} = e^{-1.467} = 0.2306
\]</span></p>
<p>Since the odds are less than 1, we should find that the probability of death is less than 1/2. With a little algebra, we see that the predicted probability of death for a subject with a resection of 4 cm is:</p>
<p><span class="math display">\[
Pr(died = 1) = \frac{e^{-4.4337 + 0.7417 \times 4}}{1 + e^{-4.4337 + 0.7417 \times 4}} = \frac{e^{-1.467}}{1 + e^{-1.467}} = \frac{0.2306}{1.2306} = 0.187
\]</span></p>
<p>In general, we can frame the model in terms of a statement about probabilities, like this:</p>
<p><span class="math display">\[
Pr(died = 1) = \frac{e^{\beta_0 + \beta_1 x}}{1 + {e^{\beta_0 + \beta_1 x}}} = \frac{e^{-4.4337 + 0.7417 \times resection}}{1 + e^{-4.4337 + 0.7417 \times resection}}
\]</span></p>
<p>and so by substituting in values for <code>resection</code>, we can estimate the model’s fitted probabilities of death.</p>
</div>
<div id="using-predict-to-describe-the-models-fits" class="section level3">
<h3><span class="header-section-number">13.3.2</span> Using <code>predict</code> to describe the model’s fits</h3>
<p>To obtain these fitted odds and probabilities in R, we can use the <code>predict</code> function.</p>
<ul>
<li>The default predictions are on the scale of the log odds. These predictions are also available through the <code>type = &quot;link&quot;</code> command within the <code>predict</code> function for a generalized linear model like logistic regression.</li>
<li>Here are the predicted log odds of death for a subject (Sally) with a 4 cm resection and a subject (Harry) who had a 5 cm resection.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(res_modA, <span class="dt">newdata =</span> <span class="kw">data_frame</span>(<span class="dt">resection =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">5</span>)))</code></pre></div>
<pre><code>         1          2 
-1.4669912 -0.7253027 </code></pre>
<ul>
<li>We can also obtain predictions for each subject on the original response (here, probability) scale, backing out of the logit link.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(res_modA, <span class="dt">newdata =</span> <span class="kw">data_frame</span>(<span class="dt">resection =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">5</span>)), 
        <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)</code></pre></div>
<pre><code>        1         2 
0.1874004 0.3262264 </code></pre>
<p>So the predicted probability of death is 0.187 for Sally, the subject with a 4 cm resection, and 0.326 for Harry, the subject with a 5 cm resection.</p>
</div>
<div id="odds-ratio-interpretation-of-coefficients" class="section level3">
<h3><span class="header-section-number">13.3.3</span> Odds Ratio interpretation of Coefficients</h3>
<p>Often, we will exponentiate the estimated slope coefficients of a logistic regression model to help us understand the impact of changing a predictor on the odds of our outcome.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(res_modA))</code></pre></div>
<pre><code>(Intercept)   resection 
 0.01186995  2.09947754 </code></pre>
<p>To interpret this finding, suppose we have two subjects, Harry and Sally. Harry had a resection that was 1 cm larger than Sally. This estimated coefficient suggests that the estimated odds for death associated with Harry is 2.099 times larger than the odds for death associated with Sally. In general, the odds ratio comparing two subjects who differ by 1 cm on the resection length is 2.099.</p>
<p>To illustrate, again let’s assume that Harry’s resection was 5 cm, and Sally’s was 4 cm. Then we have:</p>
<p><span class="math display">\[
log\left(\frac{Pr(Harry died)}{1 - Pr(Harry died)}\right) = -4.4337 + 0.7417 \times 5 = -0.7253, \\
log\left(\frac{Pr(Sally died)}{1 - Pr(Sally died)}\right) = -4.4337 + 0.7417 \times 4 = -1.4667.
\]</span></p>
<p>which implies that our estimated odds of death for Harry and Sally are:</p>
<p><span class="math display">\[
Odds(Harry died) = \frac{Pr(Harry died)}{1 - Pr(Harry died)} = e^{-4.4337 + 0.7417 \times 5} = e^{-0.7253} = 0.4842 \\
Odds(Sally died) = \frac{Pr(Sally died)}{1 - Pr(Sally died)} = e^{-4.4337 + 0.7417 \times 4} = e^{-1.4667} = 0.2307
\]</span></p>
<p>and so the odds ratio is:</p>
<p><span class="math display">\[
OR = \frac{Odds(Harry died)}{Odds(Sally died)} = \frac{0.4842}{0.2307} = 2.099
\]</span></p>
<ul>
<li>If the odds ratio was 1, that would mean that Harry and Sally had the same estimated odds of death, and thus the same estimated probability of death, despite having different sizes of resections.</li>
<li>Since the odds ratio is greater than 1, it means that Harry has a higher estimated odds of death than Sally, and thus that Harry has a higher estimated probability of death than Sally.</li>
<li>If the odds ratio was less than 1, it would mean that Harry had a lower estimated odds of death than Sally, and thus that Harry had a lower estimated probability of death than Sally.</li>
</ul>
<p>Remember that the odds ratio is a fraction describing two positive numbers (odds can only be non-negative) so that the smallest possible odds ratio is 0.</p>
</div>
<div id="interpreting-the-rest-of-the-model-output-from-glm" class="section level3">
<h3><span class="header-section-number">13.3.4</span> Interpreting the rest of the model output from <code>glm</code></h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_modA</code></pre></div>
<pre><code>
Call:  glm(formula = died ~ resection, family = &quot;binomial&quot;, data = resect)

Coefficients:
(Intercept)    resection  
    -4.4337       0.7417  

Degrees of Freedom: 133 Total (i.e. Null);  132 Residual
Null Deviance:      101.9 
Residual Deviance: 89.49    AIC: 93.49</code></pre>
<p>In addition to specifying the logistic regression coefficients, we are also presented with information on degrees of freedom, deviance (null and residual) and AIC.</p>
<ul>
<li>The degrees of freedom indicate the sample size.
<ul>
<li>Recall that we had <em>n</em> = 134 subjects in the data. The “Null” model includes only an intercept term (which uses 1 df) and we thus have <em>n</em> - 1 (here 133) degrees of freedom available for estimation.</li>
<li>In our <code>res_modA</code> model, a logistic regression is fit including a single slope (resection) and an intercept term. Each uses up one degree of freedom to build an estimate, so we have <em>n</em> - 2 = 134 - 2 = 132 residual df remaining.</li>
</ul></li>
<li>The AIC or Akaike Information Criterion (lower values are better) is also provided. This is helpful if we’re comparing multiple models for the same outcome.</li>
</ul>
</div>
<div id="deviance-and-comparing-our-model-to-the-null-model" class="section level3">
<h3><span class="header-section-number">13.3.5</span> Deviance and Comparing Our Model to the Null Model</h3>
<ul>
<li>The deviance (a measure of the model’s <em>lack of fit</em>) is available for both the null model (the model with only an intercept) and for our model (<code>res_modA</code>) predicting our outcome, mortality.</li>
<li>The deviance test, though available in R (see below) isn’t really a test of whether the model works well. Instead, it assumes the model is true, and then tests to see if the coefficients are detectably different from zero. So it isn’t of much practical use.
<ul>
<li>To compare the <code>deviance</code> statistics, we can subtract the residual deviance from the null deviance to describe the impact of our model on fit.</li>
<li>Null Deviance - Residual Deviance can be compared to a <span class="math inline">\(\chi^2\)</span> distribution with Null DF - Residual DF degrees of freedom to obtain a global test of the in-sample predictive power of our model.</li>
<li>We can see this comparison more directly by running <code>anova</code> on our model:</li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(res_modA)</code></pre></div>
<pre><code>Analysis of Deviance Table

Model: binomial, link: logit

Response: died

Terms added sequentially (first to last)

          Df Deviance Resid. Df Resid. Dev
NULL                        133    101.943
resection  1    12.45       132     89.493</code></pre>
<p>To complete a deviance test and obtain a <em>p</em> value, we can run the following code to estimate the probability that a chi-square distribution with a single degree of freedom would exhibit an improvement in deviance as large as 12.45.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pchisq</span>(<span class="fl">12.45</span>, <span class="dv">1</span>, <span class="dt">lower.tail =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>[1] 0.0004179918</code></pre>
<p>The <em>p</em> value for the deviance test here is about 0.0004. But, again, this isn’t a test of whether the model is any good - it assumes the model is true, and then tests some consequences.</p>
<ul>
<li>Specifically, it tests whether (if the model is TRUE) some of the model’s coefficients are non-zero.</li>
<li>That’s not so practically useful, so I discourage you from performing global tests of a logistic regression model with a deviance test.</li>
</ul>
</div>
<div id="using-glance-with-a-logistic-regression-model" class="section level3">
<h3><span class="header-section-number">13.3.6</span> Using <code>glance</code> with a logistic regression model</h3>
<p>We can use the <code>glance</code> function from the <code>broom</code> package to obtain the null and residual deviance and degrees of freedom. Note that the deviance for our model is related to the log likelihood by -2*<code>logLik</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(res_modA)</code></pre></div>
<pre><code>  null.deviance df.null    logLik      AIC     BIC deviance df.residual
1      101.9431     133 -44.74646 93.49292 99.2886 89.49292         132</code></pre>
<p>The <code>glance</code> result also provides the AIC, and the BIC (Bayes Information Criterion), each of which is helpful in understanding comparisons between multiple models for the same outcome (with smaller values of either criterion indicating better models.) The AIC is based on the deviance, but penalizes you for making the model more complicated. The BIC does the same sort of thing but with a different penalty.</p>
<p>Again we see that we have a null deviance of 101.94 on 133 degrees of freedom. Including the <code>resection</code> information in the model decreased the deviance to 89.49 points on 132 degrees of freedom, so that’s a decrease of 12.45 points while using one degree of freedom, a statistically significant reduction in deviance.</p>
</div>
</div>
<div id="interpreting-the-model-summary" class="section level2">
<h2><span class="header-section-number">13.4</span> Interpreting the Model Summary</h2>
<p>Let’s get a more detailed summary of our <code>res_modA</code> model, including 95% confidence intervals for the coefficients:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(res_modA)</code></pre></div>
<pre><code>
Call:
glm(formula = died ~ resection, family = &quot;binomial&quot;, data = resect)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.1844  -0.5435  -0.3823  -0.2663   2.4501  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -4.4337     0.8799  -5.039 4.67e-07 ***
resection     0.7417     0.2230   3.327 0.000879 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 101.943  on 133  degrees of freedom
Residual deviance:  89.493  on 132  degrees of freedom
AIC: 93.493

Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(res_modA, <span class="dt">level =</span> <span class="fl">0.95</span>)</code></pre></div>
<pre><code>Waiting for profiling to be done...</code></pre>
<pre><code>                2.5 %    97.5 %
(Intercept) -6.344472 -2.855856
resection    0.322898  1.208311</code></pre>
<p>Some elements of this summary are very familiar from our work with linear models.</p>
<ul>
<li>We still have a five-number summary of residuals, although these are called <em>deviance</em> residuals.</li>
<li>We have a table of coefficients with standard errors, and hypothesis tests, although these are Wald z-tests, rather than the t tests we saw in linear modeling.</li>
<li>We have a summary of global fit in the comparison of null deviance and residual deviance, but without a formal p value. And we have the AIC, as discussed above.</li>
<li>We also have some new items related to a <em>dispersion</em> parameter and to the number of Fisher Scoring Iterations.</li>
</ul>
<p>Let’s walk through each of these elements.</p>
<div id="wald-z-tests-for-coefficients-in-a-logistic-regression" class="section level3">
<h3><span class="header-section-number">13.4.1</span> Wald Z tests for Coefficients in a Logistic Regression</h3>
<p>The coefficients output provides the estimated coefficients, and their standard errors, plus a Wald Z statistic, which is just the estimated coefficient divided by its standard error. This is compared to a standard Normal distribution to obtain the two-tailed p values summarized in the <code>Pr(&gt;|z|)</code> column.</p>
<ul>
<li>The interesting result is <code>resection</code>, which has a Wald Z = 3.327, yielding a <em>p</em> value of 0.00088.</li>
<li>The hypotheses being tested here are H<sub>0</sub>: <code>resection</code> does not have an effect on the log odds of <code>died</code> vs. H<sub>A</sub>: <code>resection</code> does have such an effect.</li>
<li>Another way of stating this is that the <em>p</em> value assesses whether the estimated coefficient of <code>resection</code>, 0.7417, is statistically detectably different from 0. If the coefficient (on the logit scale) for <code>resection</code> was truly 0, this would mean that:
<ul>
<li>the log odds of death did not change based on the <code>resection</code> size,</li>
<li>the odds of death were unchanged based on the <code>resection</code> size (the odds ratio would be 1), and</li>
<li>the probability of death was unchanged based on the <code>resection</code> size.</li>
</ul></li>
</ul>
<p>In our case, we have a statistically detectable change in the log odds of <code>died</code> associated with changes in <code>resection</code>, according to this <em>p</em> value. We conclude that <code>resection</code> size is associated with a positive impact on death rates (death rates are generally higher for people with larger resections.)</p>
</div>
<div id="confidence-intervals-for-the-coefficients" class="section level3">
<h3><span class="header-section-number">13.4.2</span> Confidence Intervals for the Coefficients</h3>
<p>As in linear regression, we can obtain 95% confidence intervals (to get other levels, change the <code>level</code> parameter in <code>confint</code>) for the intercept and slope coefficients.</p>
<p>Here, we see, for example, that the coefficient of <code>resection</code> has a point estimate of 0.7417, and a confidence interval of (0.3229, 1.208). Since this is on the logit scale, it’s not that interpretable, but we will often exponentiate the model and its confidence interval to obtain a more interpretable result on the odds ratio scale.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(res_modA))</code></pre></div>
<pre><code>(Intercept)   resection 
 0.01186995  2.09947754 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">confint</span>(res_modA))</code></pre></div>
<pre><code>Waiting for profiling to be done...</code></pre>
<pre><code>                  2.5 %     97.5 %
(Intercept) 0.001756429 0.05750655
resection   1.381124459 3.34782604</code></pre>
<p>From this output, we can estimate the odds ratio for death associated with a 1 cm increase in resection size is 2.099, with a 95% CI of (1.38, 3.35). - If the odds ratio was 1, it would indicate that the odds of death did not change based on the change in resection size. - Here, it’s clear that the estimated odds of death will be larger (odds &gt; 1) for subjects with larger resection sizes. Larger odds of death also indicate larger probabilities of death. This confidence interval indicates that with 95% confidence, we conclude that increases in resection size are associated with statistically detectable increases in the odds of death. - If the odds ratio was less than 1 (remember that it cannot be less than 0) that would mean that subjects with larger resection sizes were associated with smaller estimated odds of death.</p>
</div>
<div id="deviance-residuals" class="section level3">
<h3><span class="header-section-number">13.4.3</span> Deviance Residuals</h3>
<p>In logistic regression, it’s certainly a good idea to check to see how well the model fits the data. However, there are a few different types of residuals. The residuals presented here by default are called deviance residuals. Other types of residuals are available for generalized linear models, such as Pearson residuals, working residuals, and response residuals. Logistic regression model diagnostics often make use of multiple types of residuals.</p>
<p>The deviance residuals for each individual subject sum up to the deviance statistic for the model, and describe the contribution of each point to the model likelihood function.</p>
<p>The deviance residual, <span class="math inline">\(d_i\)</span>, for the i<sup>th</sup> observation in a model predicting <span class="math inline">\(y_i\)</span> (a binary variable), with the estimate being <span class="math inline">\(\hat{\pi}_i\)</span> is:</p>
<p><span class="math display">\[
d_i = s_i \sqrt{-2 [y_i log \hat{\pi_i} + (1 - y_i) log(1 - \hat{\pi_i})]},
\]</span></p>
<p>where <span class="math inline">\(s_i\)</span> is 1 if <span class="math inline">\(y_i = 1\)</span> and <span class="math inline">\(s_i = -1\)</span> if <span class="math inline">\(y_i = 0\)</span>.</p>
<p>Again, the sum of the deviance residuals is the deviance.</p>
</div>
<div id="dispersion-parameter" class="section level3">
<h3><span class="header-section-number">13.4.4</span> Dispersion Parameter</h3>
<p>The dispersion parameter is taken to be 1 for <code>glm</code> fit using either the <code>binomial</code> or <code>Poisson</code> families. For other sorts of generalized linear models, the dispersion parameter will be of some importance in estimating standard errors sensibly.</p>
</div>
<div id="fisher-scoring-iterations" class="section level3">
<h3><span class="header-section-number">13.4.5</span> Fisher Scoring iterations</h3>
<p>The solution of a logistic regression model involves maximizing a likelihood function. Fisher’s scoring algorithm in our <code>res_modA</code> needed five iterations to perform the logistic regression fit. All that this tells you is that the model converged, and didn’t require a lot of time to do so.</p>
</div>
</div>
<div id="plotting-a-simple-logistic-regression-model" class="section level2">
<h2><span class="header-section-number">13.5</span> Plotting a Simple Logistic Regression Model</h2>
<p>Let’s plot the logistic regression model <code>res_modA</code> for <code>died</code> using the extent of the resection in terms of probabilities. We can use either of two different approaches:</p>
<ul>
<li>we can plot the fitted values from our specific model against the original data, using the <code>augment</code> function from the <code>broom</code> package, or</li>
<li>we can create a smooth function called <code>binomial_smooth</code> that plots a simple logistic model in an analogous way to <code>geom_smooth(method = &quot;lm&quot;)</code> for a simple linear regression.</li>
</ul>
<div id="using-augment-to-capture-the-fitted-probabilities" class="section level3">
<h3><span class="header-section-number">13.5.1</span> Using <code>augment</code> to capture the fitted probabilities</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_A_aug &lt;-<span class="st"> </span><span class="kw">augment</span>(res_modA, resect, 
                     <span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>)
<span class="kw">head</span>(res_A_aug)</code></pre></div>
<pre><code>  id age prior resection intubated died    .fitted    .se.fit     .resid
1  1  34     1       2.5         0    0 0.07046791 0.02562381 -0.3822929
2  2  57     0       5.0         0    0 0.32622637 0.08605551 -0.8886631
3  3  60     1       4.0         1    1 0.18740037 0.04269795  1.8300317
4  4  62     1       4.2         0    0 0.21104240 0.04871389 -0.6885386
5  5  28     0       6.0         1    1 0.50409637 0.14302982  1.1704596
6  6  52     0       3.0         0    0 0.09897375 0.02867196 -0.4565542
         .hat    .sigma      .cooksd .std.resid
1 0.010024061 0.8258481 0.0003876961 -0.3842235
2 0.033691765 0.8227475 0.0087350915 -0.9040227
3 0.011972088 0.8107264 0.0265893468  1.8410857
4 0.014252277 0.8243062 0.0019617278 -0.6934983
5 0.081835623 0.8196110 0.0477480056  1.2215077
6 0.009218619 0.8255581 0.0005157780 -0.4586733</code></pre>
<p>This approach augments the <code>resect</code> data set with fitted, residual and other summaries of each observation’s impact on the fit, using the “response” type of prediction, which yields the fitted probabilities in the <code>.fitted</code> column.</p>
</div>
<div id="plotting-a-logistic-regression-models-fitted-values" class="section level3">
<h3><span class="header-section-number">13.5.2</span> Plotting a Logistic Regression Model’s Fitted Values</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(res_A_aug, <span class="kw">aes</span>(<span class="dt">x =</span> resection, <span class="dt">y =</span> died)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="fl">0.05</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> resection, <span class="dt">y =</span> .fitted), 
              <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Logistic Regression from Model res_modA&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-165-1.png" width="672" /></p>
</div>
<div id="plotting-a-simple-logistic-model-using-binomial_smooth" class="section level3">
<h3><span class="header-section-number">13.5.3</span> Plotting a Simple Logistic Model using <code>binomial_smooth</code></h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">binomial_smooth &lt;-<span class="st"> </span><span class="cf">function</span>(...) {
  <span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;glm&quot;</span>, 
              <span class="dt">method.args =</span> <span class="kw">list</span>(<span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>), ...)
}

<span class="kw">ggplot</span>(resect, <span class="kw">aes</span>(<span class="dt">x =</span> resection, <span class="dt">y =</span> died)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">height =</span> <span class="fl">0.05</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">binomial_smooth</span>() <span class="op">+</span><span class="st"> </span>## ...smooth(se=FALSE) to leave out interval
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Logistic Regression from Model A&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-166-1.png" width="672" /></p>
<p>As expected, we see an increase in the model probability of death as the extent of the resection grows larger.</p>
</div>
</div>
<div id="how-well-does-model-a-classify-subjects" class="section level2">
<h2><span class="header-section-number">13.6</span> How well does Model A classify subjects?</h2>
<p>A natural question to ask is how well does our model classify patients in terms of likelihood of death.</p>
<p>We could specify a particular rule, for example: if the predicted probability of death is 0.5 or greater, then predict “Died”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_A_aug<span class="op">$</span>rule.<span class="dv">5</span> &lt;-<span class="st"> </span><span class="kw">ifelse</span>(res_A_aug<span class="op">$</span>.fitted <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>, 
                       <span class="st">&quot;Predict Died&quot;</span>, <span class="st">&quot;Predict Alive&quot;</span>)

<span class="kw">table</span>(res_A_aug<span class="op">$</span>rule.<span class="dv">5</span>, res_A_aug<span class="op">$</span>died)</code></pre></div>
<pre><code>               
                  0   1
  Predict Alive 114  16
  Predict Died    3   1</code></pre>
<p>And perhaps build the linked table of row probabilities which tells us, for example, that 87.69% of the patients predicted by the model to be alive actually did survive.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="dv">100</span><span class="op">*</span><span class="kw">prop.table</span>(
    <span class="kw">table</span>(res_A_aug<span class="op">$</span>rule.<span class="dv">5</span>, res_A_aug<span class="op">$</span>died), <span class="dv">1</span>), <span class="dv">2</span>)</code></pre></div>
<pre><code>               
                    0     1
  Predict Alive 87.69 12.31
  Predict Died  75.00 25.00</code></pre>
<p>Or the table of column probabilities which tell us, for example, that 97.44% of those who actually survived were predicted by the model to be alive.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="dv">100</span><span class="op">*</span><span class="kw">prop.table</span>(
    <span class="kw">table</span>(res_A_aug<span class="op">$</span>rule.<span class="dv">5</span>, res_A_aug<span class="op">$</span>died), <span class="dv">2</span>), <span class="dv">2</span>)</code></pre></div>
<pre><code>               
                    0     1
  Predict Alive 97.44 94.12
  Predict Died   2.56  5.88</code></pre>
<p>We’ll discuss various measures of concordance derived from this sort of classification later.</p>
</div>
<div id="receiver-operating-characteristic-curve-analysis" class="section level2">
<h2><span class="header-section-number">13.7</span> Receiver Operating Characteristic Curve Analysis</h2>
<p>One way to assess the predictive accuracy within the model development sample in a logistic regression is to consider an analyses based on the receiver operating characteristic (ROC) curve. ROC curves are commonly used in assessing diagnoses in medical settings, and in signal detection applications.</p>
<p>The accuracy of a “test” can be evaluated by considering two types of errors: false positives and false negatives.</p>
<p>In our <code>res_modA</code> model, we use <code>resection</code> size to predict whether the patient <code>died</code>. Suppose we established a value R, so that if the resection size was larger than R cm, we would predict that the patient <code>died</code>, and otherwise we would predict that the patient did not die.</p>
<p>A good outcome of our model’s “test”, then, would be when the resection size is larger than R for a patient who actually died. Another good outcome would be when the resection size is smaller than R for a patient who survived.</p>
<p>But we can make errors, too.</p>
<ul>
<li>A false positive error in this setting would occur when the resection size is larger than R (so we predict the patient dies) but in fact the patient does not die.</li>
<li>A false negative error in this case would occur when the resection size is smaller than R (so we predict the patient survives) but in fact the patient dies.</li>
</ul>
<p>Formally, the true positive fraction (TPF) for a specific resection cutoff <span class="math inline">\(R\)</span>, is the probability of a positive test (a prediction that the patient will die) among the people who have the outcome died = 1 (those who actually die).</p>
<p><span class="math display">\[
TPF(R) = Pr(resection &gt; R | subject died)
\]</span></p>
<p>Similarly, the false positive fraction (FPF) for a specific cutoff <span class="math inline">\(R\)</span> is the probability of a positive test (prediction that the patient will die) among the people with died = 0 (those who don’t actually die)</p>
<p><span class="math display">\[
FPF(R) = Pr(resection &gt; R | subject did not die)
\]</span></p>
<p>The True Positive Rate is referred to as the sensitivity of a diagnostic test, and the True Negative rate (1 - the False Positive rate) is referred to as the specificity of a diagnostic test.</p>
<p>Since the cutoff <span class="math inline">\(R\)</span> is not fixed in advanced, we can plot the value of TPF (on the y axis) against FPF (on the x axis) for all possible values of <span class="math inline">\(R\)</span>, and this is what the ROC curve is. Others refer to the Sensitivity on the Y axis, and 1-Specificity on the X axis, and this is the same idea.</p>
<p>Before we get too far into the weeds, let me show you some simple situations so you can understand what you might learn from the ROC curve. The web page <a href="http://blog.yhat.com/posts/roc-curves.html" class="uri">http://blog.yhat.com/posts/roc-curves.html</a> provides source materials.</p>
<div id="interpreting-the-area-under-the-roc-curve" class="section level3">
<h3><span class="header-section-number">13.7.1</span> Interpreting the Area under the ROC curve</h3>
<p>The AUC or Area under the ROC curve is the amount of space underneath the ROC curve. Often referred to as the c statistic, the AUC represents the quality of your TPR and FPR overall in a single number. The C statistic ranges from 0 to 1, with C = 0.5 for a prediction that is no better than random guessing, and C = 1 for a perfect prediction model.</p>
<p>Next, I’ll build a simulation to demonstrate several possible ROC curves in the sections that follow.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">432999</span>)
sim.temp &lt;-<span class="st"> </span><span class="kw">data_frame</span>(<span class="dt">x =</span> <span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">200</span>), 
                       <span class="dt">prob =</span> <span class="kw">exp</span>(x)<span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(x)), 
                       <span class="dt">y =</span> <span class="kw">as.numeric</span>(<span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="kw">runif</span>(<span class="dv">200</span>) <span class="op">&lt;</span><span class="st"> </span>prob))

sim.temp &lt;-<span class="st"> </span>sim.temp <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">p_guess =</span> <span class="dv">1</span>,
           <span class="dt">p_perfect =</span> y, 
           <span class="dt">p_bad =</span> <span class="kw">exp</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>x) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>x)),
           <span class="dt">p_ok =</span> prob <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>y)<span class="op">*</span><span class="kw">runif</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="fl">0.05</span>),
           <span class="dt">p_good =</span> prob <span class="op">+</span><span class="st"> </span>y<span class="op">*</span><span class="kw">runif</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="fl">0.27</span>))</code></pre></div>
<div id="what-if-we-are-guessing" class="section level4">
<h4><span class="header-section-number">13.7.1.1</span> What if we are guessing?</h4>
<p>If we’re guessing completely at random, then the model should correctly classify a subject (as died or not died) about 50% of the time, so the TPR and FPR will be equal. This yields a diagonal line in the ROC curve, and an area under the curve (C statistic) of 0.5.</p>
<p>There are several ways to do this on the web, but I’ll show this one, which has some bizarre code, but that’s a function of using a package called <code>ROCR</code> to do the work. It comes from <a href="http://blog.yhat.com/posts/roc-curves.html">this link</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_guess &lt;-<span class="st"> </span><span class="kw">prediction</span>(sim.temp<span class="op">$</span>p_guess, sim.temp<span class="op">$</span>y)
perf_guess &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_guess, <span class="dt">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)
auc_guess &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_guess, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)

auc_guess &lt;-<span class="st"> </span><span class="kw">round</span>(auc_guess<span class="op">@</span>y.values[[<span class="dv">1</span>]],<span class="dv">3</span>)
roc_guess &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fpr=</span><span class="kw">unlist</span>(perf_guess<span class="op">@</span>x.values),
                        <span class="dt">tpr=</span><span class="kw">unlist</span>(perf_guess<span class="op">@</span>y.values),
                        <span class="dt">model=</span><span class="st">&quot;GLM&quot;</span>)

<span class="kw">ggplot</span>(roc_guess, <span class="kw">aes</span>(<span class="dt">x=</span>fpr, <span class="dt">ymin=</span><span class="dv">0</span>, <span class="dt">ymax=</span>tpr)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>tpr), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;Guessing: ROC Curve w/ AUC=&quot;</span>, auc_guess)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-171-1.png" width="672" /></p>
</div>
<div id="what-if-we-classify-things-perfectly" class="section level4">
<h4><span class="header-section-number">13.7.1.2</span> What if we classify things perfectly?</h4>
<p>If we’re classifying subjects perfectly, then we have a TPR of 1 and an FPR of 0. That yields an ROC curve that looks like the upper and left edges of a box. If our model correctly classifies a subject (as died or not died) 100% of the time, the area under the curve (c statistic) will be 1.0. We’ll add in the diagonal line here (in a dashed black line) to show how this model compares to random guessing.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_perf &lt;-<span class="st"> </span><span class="kw">prediction</span>(sim.temp<span class="op">$</span>p_perfect, sim.temp<span class="op">$</span>y)
perf_perf &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_perf, <span class="dt">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)
auc_perf &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_perf, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)

auc_perf &lt;-<span class="st"> </span><span class="kw">round</span>(auc_perf<span class="op">@</span>y.values[[<span class="dv">1</span>]],<span class="dv">3</span>)
roc_perf &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fpr=</span><span class="kw">unlist</span>(perf_perf<span class="op">@</span>x.values),
                        <span class="dt">tpr=</span><span class="kw">unlist</span>(perf_perf<span class="op">@</span>y.values),
                        <span class="dt">model=</span><span class="st">&quot;GLM&quot;</span>)

<span class="kw">ggplot</span>(roc_perf, <span class="kw">aes</span>(<span class="dt">x=</span>fpr, <span class="dt">ymin=</span><span class="dv">0</span>, <span class="dt">ymax=</span>tpr)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>tpr), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;Perfect Prediction: ROC Curve w/ AUC=&quot;</span>, auc_perf)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-172-1.png" width="672" /></p>
</div>
<div id="what-does-worse-than-guessing-look-like" class="section level4">
<h4><span class="header-section-number">13.7.1.3</span> What does “worse than guessing” look like?</h4>
<p>A bad classifier will appear below and to the right of the diagonal line we’d see if we were completely guessing. Such a model will have a c statistic below 0.5, and will be valueless.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_bad &lt;-<span class="st"> </span><span class="kw">prediction</span>(sim.temp<span class="op">$</span>p_bad, sim.temp<span class="op">$</span>y)
perf_bad &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_bad, <span class="dt">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)
auc_bad &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_bad, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)

auc_bad &lt;-<span class="st"> </span><span class="kw">round</span>(auc_bad<span class="op">@</span>y.values[[<span class="dv">1</span>]],<span class="dv">3</span>)
roc_bad &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fpr=</span><span class="kw">unlist</span>(perf_bad<span class="op">@</span>x.values),
                        <span class="dt">tpr=</span><span class="kw">unlist</span>(perf_bad<span class="op">@</span>y.values),
                        <span class="dt">model=</span><span class="st">&quot;GLM&quot;</span>)

<span class="kw">ggplot</span>(roc_bad, <span class="kw">aes</span>(<span class="dt">x=</span>fpr, <span class="dt">ymin=</span><span class="dv">0</span>, <span class="dt">ymax=</span>tpr)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>tpr), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;A Bad Model: ROC Curve w/ AUC=&quot;</span>, auc_bad)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-173-1.png" width="672" /></p>
</div>
<div id="what-does-better-than-guessing-look-like" class="section level4">
<h4><span class="header-section-number">13.7.1.4</span> What does “better than guessing” look like?</h4>
<p>An “OK” classifier will appear above and to the left of the diagonal line we’d see if we were completely guessing. Such a model will have a c statistic above 0.5, and might have some value. The plot below shows a very fairly poor model, but at least it’s better than guessing.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_ok &lt;-<span class="st"> </span><span class="kw">prediction</span>(sim.temp<span class="op">$</span>p_ok, sim.temp<span class="op">$</span>y)
perf_ok &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_ok, <span class="dt">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)
auc_ok &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_ok, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)

auc_ok &lt;-<span class="st"> </span><span class="kw">round</span>(auc_ok<span class="op">@</span>y.values[[<span class="dv">1</span>]],<span class="dv">3</span>)
roc_ok &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fpr=</span><span class="kw">unlist</span>(perf_ok<span class="op">@</span>x.values),
                        <span class="dt">tpr=</span><span class="kw">unlist</span>(perf_ok<span class="op">@</span>y.values),
                        <span class="dt">model=</span><span class="st">&quot;GLM&quot;</span>)

<span class="kw">ggplot</span>(roc_ok, <span class="kw">aes</span>(<span class="dt">x=</span>fpr, <span class="dt">ymin=</span><span class="dv">0</span>, <span class="dt">ymax=</span>tpr)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>tpr), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;A Mediocre Model: ROC Curve w/ AUC=&quot;</span>, auc_ok)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-174-1.png" width="672" /></p>
<p>Sometimes people grasp for a rough guide as to the accuracy of a model’s predictions based on the area under the ROC curve. A common thought is to assess the C statistic much like you would a class grade.</p>
<table style="width:81%;">
<colgroup>
<col width="16%" />
<col width="63%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">C statistic</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.90 to 1.00</td>
<td>model does an excellent job at discriminating “yes” from “no” (A)</td>
</tr>
<tr class="even">
<td align="right">0.80 to 0.90</td>
<td>model does a good job (B)</td>
</tr>
<tr class="odd">
<td align="right">0.70 to 0.80</td>
<td>model does a fair job (C)</td>
</tr>
<tr class="even">
<td align="right">0.60 to 0.70</td>
<td>model does a poor job (D)</td>
</tr>
<tr class="odd">
<td align="right">0.50 to 0.60</td>
<td>model fails (F)</td>
</tr>
<tr class="even">
<td align="right">below 0.50</td>
<td>model is worse than random guessing</td>
</tr>
</tbody>
</table>
</div>
<div id="what-does-pretty-good-look-like" class="section level4">
<h4><span class="header-section-number">13.7.1.5</span> What does “pretty good” look like?</h4>
<p>A strong and good classifier will appear above and to the left of the diagonal line we’d see if we were completely guessing, often with a nice curve that is continually increasing and appears to be pulled up towards the top left. Such a model will have a c statistic well above 0.5, but not as large as 1. The plot below shows a stronger model, which appears substantially better than guessing.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_good &lt;-<span class="st"> </span><span class="kw">prediction</span>(sim.temp<span class="op">$</span>p_good, sim.temp<span class="op">$</span>y)
perf_good &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_good, <span class="dt">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)
auc_good &lt;-<span class="st"> </span><span class="kw">performance</span>(pred_good, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)

auc_good &lt;-<span class="st"> </span><span class="kw">round</span>(auc_good<span class="op">@</span>y.values[[<span class="dv">1</span>]],<span class="dv">3</span>)
roc_good &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fpr=</span><span class="kw">unlist</span>(perf_good<span class="op">@</span>x.values),
                        <span class="dt">tpr=</span><span class="kw">unlist</span>(perf_good<span class="op">@</span>y.values),
                        <span class="dt">model=</span><span class="st">&quot;GLM&quot;</span>)

<span class="kw">ggplot</span>(roc_good, <span class="kw">aes</span>(<span class="dt">x=</span>fpr, <span class="dt">ymin=</span><span class="dv">0</span>, <span class="dt">ymax=</span>tpr)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>tpr), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;A Pretty Good Model: ROC Curve w/ AUC=&quot;</span>, auc_good)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-175-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="the-roc-plot-for-res_moda" class="section level2">
<h2><span class="header-section-number">13.8</span> The ROC Plot for <code>res_modA</code></h2>
<p>Let me show you the ROC curve for our <code>res_modA</code> model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## requires ROCR package
prob &lt;-<span class="st"> </span><span class="kw">predict</span>(res_modA, resect, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
pred &lt;-<span class="st"> </span><span class="kw">prediction</span>(prob, resect<span class="op">$</span>died)
perf &lt;-<span class="st"> </span><span class="kw">performance</span>(pred, <span class="dt">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)
auc &lt;-<span class="st"> </span><span class="kw">performance</span>(pred, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)

auc &lt;-<span class="st"> </span><span class="kw">round</span>(auc<span class="op">@</span>y.values[[<span class="dv">1</span>]],<span class="dv">3</span>)
roc.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fpr=</span><span class="kw">unlist</span>(perf<span class="op">@</span>x.values),
                       <span class="dt">tpr=</span><span class="kw">unlist</span>(perf<span class="op">@</span>y.values),
                       <span class="dt">model=</span><span class="st">&quot;GLM&quot;</span>)

<span class="kw">ggplot</span>(roc.data, <span class="kw">aes</span>(<span class="dt">x=</span>fpr, <span class="dt">ymin=</span><span class="dv">0</span>, <span class="dt">ymax=</span>tpr)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>tpr), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;ROC Curve w/ AUC=&quot;</span>, auc)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-176-1.png" width="672" /></p>
<p>Based on the C statistic (AUC = 0.771) this would rank somewhere near the high end of a “fair” predictive model by this standard, not quite to the level of a “good” model.</p>
<div id="another-way-to-plot-the-roc-curve" class="section level3">
<h3><span class="header-section-number">13.8.1</span> Another way to plot the ROC Curve</h3>
<p>If we’ve loaded the <code>pROC</code> package, we can also use the following (admittedly simpler) approach to plot the ROC curve, without <code>ggplot2</code>, and to obtain the C statistic, and a 95% confidence interval around that C statistic.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## requires pROC package
roc.modA &lt;-<span class="st"> </span>
<span class="st">    </span><span class="kw">roc</span>(resect<span class="op">$</span>died <span class="op">~</span><span class="st"> </span><span class="kw">predict</span>(res_modA, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>),
        <span class="dt">ci =</span> <span class="ot">TRUE</span>)

roc.modA</code></pre></div>
<pre><code>
Call:
roc.formula(formula = resect$died ~ predict(res_modA, type = &quot;response&quot;),     ci = TRUE)

Data: predict(res_modA, type = &quot;response&quot;) in 117 controls (resect$died 0) &lt; 17 cases (resect$died 1).
Area under the curve: 0.7707
95% CI: 0.67-0.8715 (DeLong)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(roc.modA)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-177-1.png" width="672" /></p>
</div>
</div>
<div id="assessing-residual-plots-from-model-a" class="section level2">
<h2><span class="header-section-number">13.9</span> Assessing Residual Plots from Model A</h2>
<blockquote>
<p>Residuals are certainly less informative for logistic regression than they are for linear regression: not only do yes/no outcomes inherently contain less information than continuous ones, but the fact that the adjusted response depends on the fit hampers our ability to use residuals as external checks on the model.</p>
</blockquote>
<blockquote>
<p>This is mitigated to some extent, however, by the fact that we are also making fewer distributional assumptions in logistic regression, so there is no need to inspect residuals for, say, skewness or heteroskedasticity.</p>
</blockquote>
<ul>
<li>Patrick Breheny, University of Kentucky, <a href="https://web.as.uky.edu/statistics/users/pbreheny/760/S13/notes/3-26.pdf">Slides on GLM Residuals and Diagnostics</a></li>
</ul>
<p>The usual residual plots are available in R for a logistic regression model, but most of them are irrelevant in the logistic regression setting. The residuals shouldn’t follow a standard Normal distribution, and they will not show constant variance over the range of the predictor variables, so plots looking into those issues aren’t helpful.</p>
<p>The only plot from the standard set that we’ll look at in many settings is plot 5, which helps us assess influence (via Cook’s distance contours), and a measure related to leverage (how unusual an observation is in terms of the predictors) and standardized Pearson residuals.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(res_modA, <span class="dt">which =</span> <span class="dv">5</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-178-1.png" width="672" /></p>
<p>In this case, I don’t see any highly influential points, as no points fall outside of the Cook’s distance (0.5 or 1) contours.</p>
</div>
<div id="model-b-a-kitchen-sink-logistic-regression-model" class="section level2">
<h2><span class="header-section-number">13.10</span> Model B: A “Kitchen Sink” Logistic Regression Model</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_modB &lt;-<span class="st"> </span><span class="kw">glm</span>(died <span class="op">~</span><span class="st"> </span>resection <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>prior <span class="op">+</span><span class="st"> </span>intubated,
               <span class="dt">data =</span> resect, <span class="dt">family =</span> binomial)

res_modB</code></pre></div>
<pre><code>
Call:  glm(formula = died ~ resection + age + prior + intubated, family = binomial, 
    data = resect)

Coefficients:
(Intercept)    resection          age        prior    intubated  
  -5.152886     0.612211     0.001173     0.814691     2.810797  

Degrees of Freedom: 133 Total (i.e. Null);  129 Residual
Null Deviance:      101.9 
Residual Deviance: 67.36    AIC: 77.36</code></pre>
<div id="comparing-model-a-to-model-b" class="section level3">
<h3><span class="header-section-number">13.10.1</span> Comparing Model A to Model B</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(res_modA, res_modB)</code></pre></div>
<pre><code>Analysis of Deviance Table

Model 1: died ~ resection
Model 2: died ~ resection + age + prior + intubated
  Resid. Df Resid. Dev Df Deviance
1       132     89.493            
2       129     67.359  3   22.134</code></pre>
<p>The addition of <code>age</code>, <code>prior</code> and <code>intubated</code> reduces the lack of fit by 22.134 points, at a cost of 3 degrees of freedom.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(res_modA)</code></pre></div>
<pre><code>  null.deviance df.null    logLik      AIC     BIC deviance df.residual
1      101.9431     133 -44.74646 93.49292 99.2886 89.49292         132</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(res_modB)</code></pre></div>
<pre><code>  null.deviance df.null   logLik     AIC     BIC deviance df.residual
1      101.9431     133 -33.6793 77.3586 91.8478  67.3586         129</code></pre>
<p>By either AIC or BIC, the larger model (<code>res_modB</code>) looks more effective.</p>
</div>
<div id="interpreting-model-b" class="section level3">
<h3><span class="header-section-number">13.10.2</span> Interpreting Model B</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(res_modB)</code></pre></div>
<pre><code>
Call:
glm(formula = died ~ resection + age + prior + intubated, family = binomial, 
    data = resect)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.7831  -0.3741  -0.2386  -0.2014   2.5228  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -5.152886   1.469453  -3.507 0.000454 ***
resection    0.612211   0.282807   2.165 0.030406 *  
age          0.001173   0.020646   0.057 0.954700    
prior        0.814691   0.704785   1.156 0.247705    
intubated    2.810797   0.658395   4.269 1.96e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 101.943  on 133  degrees of freedom
Residual deviance:  67.359  on 129  degrees of freedom
AIC: 77.359

Number of Fisher Scoring iterations: 6</code></pre>
<p>It appears that the <code>intubated</code> predictor adds significant value to the model, by the Wald test.</p>
<p>Let’s focus on the impact of these variables through odds ratios.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(res_modB))</code></pre></div>
<pre><code> (Intercept)    resection          age        prior    intubated 
 0.005782692  1.844504859  1.001173503  2.258476846 16.623153519 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">confint</span>(res_modB))</code></pre></div>
<pre><code>Waiting for profiling to be done...</code></pre>
<pre><code>                   2.5 %     97.5 %
(Intercept) 0.0002408626  0.0837263
resection   1.0804548590  3.3495636
age         0.9618416869  1.0442885
prior       0.5485116610  9.1679931
intubated   4.7473282453 64.6456919</code></pre>
<p>At a 5% significance level, we might conclude that:</p>
<ul>
<li>larger sized <code>resection</code>s are associated with a meaningful rise (est OR: 1.84, 95% CI 1.08, 3.35) in the odds of death, holding all other predictors constant,</li>
<li>the need for <code>intubation</code> at the end of surgery is associated with a substantial rise (est OR: 16.6, 95% CI 4.7, 64.7) in the odds of death, holding all other predictors constant, but that</li>
<li>older <code>age</code> as well as having a <code>prior</code> tracheal surgery appears to be associated with an increase in death risk, but not to an extent that we can declare statistically significant.</li>
</ul>
</div>
</div>
<div id="plotting-model-b" class="section level2">
<h2><span class="header-section-number">13.11</span> Plotting Model B</h2>
<p>Let’s think about plotting the fitted values from our model, in terms of probabilities.</p>
<div id="using-augment-to-capture-the-fitted-probabilities-1" class="section level3">
<h3><span class="header-section-number">13.11.1</span> Using <code>augment</code> to capture the fitted probabilities</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_B_aug &lt;-<span class="st"> </span><span class="kw">augment</span>(res_modB, resect, 
                     <span class="dt">type.predict =</span> <span class="st">&quot;response&quot;</span>)
<span class="kw">head</span>(res_B_aug)</code></pre></div>
<pre><code>  id age prior resection intubated died    .fitted    .se.fit     .resid
1  1  34     1       2.5         0    0 0.05908963 0.03851118 -0.3490198
2  2  57     0       5.0         0    0 0.11660492 0.06253774 -0.4979613
3  3  60     1       4.0         1    1 0.72944600 0.15010423  0.7943172
4  4  62     1       4.2         0    0 0.15522494 0.09607978 -0.5808354
5  5  28     0       6.0         1    1 0.79641141 0.14588554  0.6747435
6  6  52     0       3.0         0    0 0.03713809 0.01933270 -0.2751191
        .hat    .sigma      .cooksd .std.resid
1 0.02667562 0.7247491 0.0003536652 -0.3537702
2 0.03796756 0.7240341 0.0010829917 -0.5076925
3 0.11416656 0.7215778 0.0107925872  0.8439524
4 0.07039819 0.7234665 0.0029937671 -0.6024273
5 0.13126049 0.7225958 0.0088920280  0.7239256
6 0.01045207 0.7250114 0.0000823406 -0.2765683</code></pre>
</div>
<div id="plotting-model-b-fits-by-observed-mortality" class="section level3">
<h3><span class="header-section-number">13.11.2</span> Plotting Model B Fits by Observed Mortality</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(res_B_aug, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(died), <span class="dt">y =</span> .fitted, <span class="dt">col =</span> <span class="kw">factor</span>(died))) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_boxplot</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">0.1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">guides</span>(<span class="dt">col =</span> <span class="ot">FALSE</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-185-1.png" width="672" /></p>
<p>Certainly it appears as though most of our predicted probabilities (of death) for the subjects who actually survived are quite small, but not all of them. We also have at least 6 big “misses” among the 17 subjects who actually died.</p>
</div>
<div id="the-roc-curve-for-model-b" class="section level3">
<h3><span class="header-section-number">13.11.3</span> The ROC curve for Model B</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## requires ROCR package
prob &lt;-<span class="st"> </span><span class="kw">predict</span>(res_modB, resect, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
pred &lt;-<span class="st"> </span><span class="kw">prediction</span>(prob, resect<span class="op">$</span>died)
perf &lt;-<span class="st"> </span><span class="kw">performance</span>(pred, <span class="dt">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)
auc &lt;-<span class="st"> </span><span class="kw">performance</span>(pred, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)

auc &lt;-<span class="st"> </span><span class="kw">round</span>(auc<span class="op">@</span>y.values[[<span class="dv">1</span>]],<span class="dv">3</span>)
roc.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fpr=</span><span class="kw">unlist</span>(perf<span class="op">@</span>x.values),
                       <span class="dt">tpr=</span><span class="kw">unlist</span>(perf<span class="op">@</span>y.values),
                       <span class="dt">model=</span><span class="st">&quot;GLM&quot;</span>)

<span class="kw">ggplot</span>(roc.data, <span class="kw">aes</span>(<span class="dt">x=</span>fpr, <span class="dt">ymin=</span><span class="dv">0</span>, <span class="dt">ymax=</span>tpr)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>tpr), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;Model B: ROC Curve w/ AUC=&quot;</span>, auc)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-186-1.png" width="672" /></p>
<p>The area under the curve (C-statistic) is 0.86, which certainly looks like a more discriminating fit than model A with resection alone.</p>
</div>
<div id="residuals-leverage-and-influence" class="section level3">
<h3><span class="header-section-number">13.11.4</span> Residuals, Leverage and Influence</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(res_modB, <span class="dt">which =</span> <span class="dv">5</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-187-1.png" width="672" /></p>
<p>Again, we see no signs of deeply influential points in this model.</p>
</div>
</div>
<div id="logistic-regression-using-lrm" class="section level2">
<h2><span class="header-section-number">13.12</span> Logistic Regression using <code>lrm</code></h2>
<p>To obtain the Nagelkerke <span class="math inline">\(R^2\)</span> and the C statistic, as well as some other summaries, I’ll now demonstrate the use of <code>lrm</code> from the <code>rms</code> package to fit a logistic regression model.</p>
<p>We’ll return to the original model, predicting death using resection size alone.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dd &lt;-<span class="st"> </span><span class="kw">datadist</span>(resect)
<span class="kw">options</span>(<span class="dt">datadist=</span><span class="st">&quot;dd&quot;</span>)

res_modC &lt;-<span class="st"> </span><span class="kw">lrm</span>(died <span class="op">~</span><span class="st"> </span>resection, <span class="dt">data=</span>resect, <span class="dt">x=</span><span class="ot">TRUE</span>, <span class="dt">y=</span><span class="ot">TRUE</span>)
res_modC</code></pre></div>
<pre><code>Logistic Regression Model
 
 lrm(formula = died ~ resection, data = resect, x = TRUE, y = TRUE)
 
                      Model Likelihood     Discrimination    Rank Discrim.    
                         Ratio Test           Indexes           Indexes       
 Obs           134    LR chi2     12.45    R2       0.167    C       0.771    
  0            117    d.f.            1    g        1.037    Dxy     0.541    
  1             17    Pr(&gt; chi2) 0.0004    gr       2.820    gamma   0.582    
 max |deriv| 2e-06                         gp       0.110    tau-a   0.121    
                                           Brier    0.103                     
 
           Coef    S.E.   Wald Z Pr(&gt;|Z|)
 Intercept -4.4337 0.8799 -5.04  &lt;0.0001 
 resection  0.7417 0.2230  3.33  0.0009  
 </code></pre>
<p>This output specifies the following:</p>
<ul>
<li><code>Obs</code> = The number of observations used to fit the model, with <code>0</code> = the number of zeros and <code>1</code> = the number of ones in our outcome, <code>died</code>. Also specified is the maximum absolute value of the derivative at the point where the maximum likelihood function was estimated. I wouldn’t worry about that practically, as all you will care about is whether the iterative function-fitting process converged, and R will warn you in other ways if it doesn’t.</li>
<li>A likelihood ratio test (drop in deviance test) subtracting the residual deviance from the null deviance obtain the Likelihood Ratio <span class="math inline">\(\chi^2\)</span> statistic, subtracting residual df from null df to obtain degrees of freedom, and comparing the resulting test statistic to a <span class="math inline">\(\chi^2\)</span> distribution with the appropriate degrees of freedom to determine a <em>p</em> value.</li>
<li>A series of discrimination indexes, including the Nagelkerke R<sup>2</sup>, symbolized R2, and several others we’ll discuss shortly.</li>
<li>A series of rank discrimination indexes, including the C statistic (area under the ROC curve) and Somers’ D (Dxy), and several others.</li>
<li>A table of coefficients, standard errors, Wald Z statistics and <em>p</em> values based on those Wald statistics.</li>
</ul>
<p>The C statistic is estimated to be 0.771, with an associated (Nagelkerke) <span class="math inline">\(R^2\)</span> = 0.167, both indicating at best mediocre performance for this model, as it turns out.</p>
<div id="interpreting-nagelkerke-r2" class="section level3">
<h3><span class="header-section-number">13.12.1</span> Interpreting Nagelkerke R<sup>2</sup></h3>
<p>There are many ways to calculate <span class="math inline">\(R^2\)</span> for logistic regression.</p>
<ul>
<li>At the unfortunate <a href="http://www.ats.ucla.edu/stat/mult_pkg/faq/general/Psuedo_RSquareds.htm">URL linked here</a> (unfortunate because the term “pseudo” is misspelled) there is a nice summary of the key issue, which is that there are at least three different ways to think about <span class="math inline">\(R^2\)</span> in linear regression that are equivalent in that context, but when you move to a categorical outcome, which interpretation you use leads you down a different path for extension to the new type of outcome.</li>
<li>Paul Allison, for instance, describes several at <a href="http://statisticalhorizons.com/r2logistic">this link</a> in a post entitled “What’s the Best R-Squared for Logistic Regression?”</li>
<li>Jonathan Bartlett looks at McFadden’s pseudo <span class="math inline">\(R^2\)</span> in some detail (including some R code) at <a href="http://thestatsgeek.com/2014/02/08/r-squared-in-logistic-regression/">this link</a>, in a post entitled “R squared in logistic regression”</li>
</ul>
<p>The Nagelkerke approach that is presented as <code>R2</code> in the <code>lrm</code> output is as good as most of the available approaches, and has the positive feature that it does reach 1 if the fitted model shows as much improvement as possible over the null model (which predicts the mean response for all subjects, and has R<sup>2</sup> = 0). The greater the improvement, the higher the Nagelkerke R<sup>2</sup>.</p>
<p>For model A, our Nagelkerke R<sup>2</sup> = 0.167, which is pretty poor. It doesn’t technically mean that 16.7% of any sort of variation has been explained, though.</p>
</div>
<div id="interpreting-the-c-statistic-and-plotting-the-roc-curve" class="section level3">
<h3><span class="header-section-number">13.12.2</span> Interpreting the C statistic and Plotting the ROC Curve</h3>
<p>The C statistic is a measure of the area under the receiver operating characteristic curve. <a href="http://blog.yhat.com/posts/roc-curves.html">This link</a> has some nice material that provides some insight into the C statistic and ROC curve.</p>
<ul>
<li>Recall that C ranges from 0 to 1. 0 = BAD, 1 = GOOD.
<ul>
<li>values of C less than 0.5 indicate that your prediction model is not even as good as simple random guessing of “yes” or “no” for your response.</li>
<li>C = 0.5 for random guessing</li>
<li>C = 1 indicates a perfect classification scheme - one that correctly guesses “yes” for all “yes” patients, and for none of the “no” patients.</li>
</ul></li>
<li>The closer C is to 1, the happier we’ll be, most of the time.
<ul>
<li>Often we’ll call models with 0.5 &lt; C &lt; 0.8 poor or weak in terms of predictive ability by this measure</li>
<li>0.8 <span class="math inline">\(\leq\)</span> C &lt; 0.9 are moderately strong in terms of predictive power (indicate good discrimination)</li>
<li>C <span class="math inline">\(\geq\)</span> 0.9 usually indicates a very strong model in this regard (indicate excellent discrimination)</li>
</ul></li>
</ul>
<p>We’ve seen the ROC curve for this model before, when we looked at model <code>res_modA</code> fitted using <code>glm</code> in the previous chapter. But, just for completeness, I’ll include it.</p>
<p><strong>Note.</strong> I change the initial <code>predict</code> call from <code>type = &quot;response&quot;</code> for a <code>glm</code> fit to <code>type = &quot;fitted&quot;</code> in a <code>lrm</code> fit. Otherwise, this is the same approach.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## requires ROCR package
prob &lt;-<span class="st"> </span><span class="kw">predict</span>(res_modC, resect, <span class="dt">type=</span><span class="st">&quot;fitted&quot;</span>)
pred &lt;-<span class="st"> </span><span class="kw">prediction</span>(prob, resect<span class="op">$</span>died)
perf &lt;-<span class="st"> </span><span class="kw">performance</span>(pred, <span class="dt">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)
auc &lt;-<span class="st"> </span><span class="kw">performance</span>(pred, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)

auc &lt;-<span class="st"> </span><span class="kw">round</span>(auc<span class="op">@</span>y.values[[<span class="dv">1</span>]],<span class="dv">3</span>)
roc.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fpr=</span><span class="kw">unlist</span>(perf<span class="op">@</span>x.values),
                       <span class="dt">tpr=</span><span class="kw">unlist</span>(perf<span class="op">@</span>y.values),
                       <span class="dt">model=</span><span class="st">&quot;GLM&quot;</span>)

<span class="kw">ggplot</span>(roc.data, <span class="kw">aes</span>(<span class="dt">x=</span>fpr, <span class="dt">ymin=</span><span class="dv">0</span>, <span class="dt">ymax=</span>tpr)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>tpr), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;Model C: ROC Curve w/ AUC=&quot;</span>, auc)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-189-1.png" width="672" /></p>
</div>
<div id="the-c-statistic-and-somers-d" class="section level3">
<h3><span class="header-section-number">13.12.3</span> The C statistic and Somers’ D</h3>
<ul>
<li>The C statistic is directly related to <strong>Somers’ D statistic</strong>, abbreviated <span class="math inline">\(D_{xy}\)</span>, by the equation C = 0.5 + (D/2).
<ul>
<li>Somers’ D and the ROC area only measure how well predicted values from the model can rank-order the responses. For example, predicted probabilities of 0.01 and 0.99 for a pair of subjects are no better than probabilities of 0.2 and 0.8 using rank measures, if the first subject had a lower response value than the second.</li>
<li>Thus, the C statistic (or <span class="math inline">\(D_{xy}\)</span>) may not be very sensitive ways to choose between models, even though they provide reasonable summaries of the models individually.</li>
<li>This is especially true when the models are strong. The Nagelkerke R<sup>2</sup> may be more sensitive.</li>
</ul></li>
<li>But as it turns out, we sometimes have to look at the ROC shapes, as the summary statistic alone isn’t enough.</li>
</ul>
<p>In our case, Somers D (Dxy) = .541, so the C statistic is 0.771.</p>
</div>
<div id="validating-the-logistic-regression-model-summary-statistics" class="section level3">
<h3><span class="header-section-number">13.12.4</span> Validating the Logistic Regression Model Summary Statistics</h3>
<p>Like other regression-fitting tools in <code>rms</code>, the <code>lrm</code> function has a special <code>validate</code> tool to help perform resampling validation of a model, with or without backwards step-wise variable selection. Here, we’ll validate our model’s summary statistics using 100 bootstrap replications.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">432001</span>) 
<span class="kw">validate</span>(res_modC, <span class="dt">B =</span> <span class="dv">100</span>)</code></pre></div>
<pre><code>          index.orig training    test optimism index.corrected   n
Dxy           0.5415   0.5325  0.5415  -0.0090          0.5505 100
R2            0.1666   0.1664  0.1666  -0.0002          0.1668 100
Intercept     0.0000   0.0000  0.1425  -0.1425          0.1425 100
Slope         1.0000   1.0000  1.0742  -0.0742          1.0742 100
Emax          0.0000   0.0000  0.0416   0.0416          0.0416 100
D             0.0854   0.0872  0.0854   0.0017          0.0837 100
U            -0.0149  -0.0149 -0.0004  -0.0145         -0.0004 100
Q             0.1004   0.1021  0.0859   0.0162          0.0841 100
B             0.1025   0.1032  0.1046  -0.0014          0.1039 100
g             1.0369   1.0247  1.0369  -0.0122          1.0491 100
gp            0.1101   0.1082  0.1101  -0.0019          0.1119 100</code></pre>
<p>Recall that our area under the curve (C statistic) = <code>0.5 + (Dxy/2)</code>, so that we can also use the first row of statistics to validate the C statistic. Accounting for optimism in this manner, our corrected estimates are Dxy = 0.551, so C = 0.776, and Nagelkerke R<sup>2</sup> = 0.167.</p>
</div>
<div id="plotting-the-summary-of-the-lrm-approach" class="section level3">
<h3><span class="header-section-number">13.12.5</span> Plotting the Summary of the <code>lrm</code> approach</h3>
<p>The <code>summary</code> function applied to an <code>lrm</code> fit shows the effect size comparing the 25<sup>th</sup> to the 75<sup>th</sup> percentile of resection.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">summary</span>(res_modC))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-191-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(res_modC)</code></pre></div>
<pre><code>             Effects              Response : died 

 Factor      Low High Diff. Effect S.E.    Lower 0.95 Upper 0.95
 resection   2   4    2     1.4834 0.44591 0.6094      2.3574   
  Odds Ratio 2   4    2     4.4078      NA 1.8393     10.5630   </code></pre>
<p>So, a move from a resection of 2 cm to a resection of 4 cm is associated with an estimated effect on the log odds of death of 1.48 (with standard error 0.45), or with an estimated effect on the odds ratio for death of 4.41, with 95% CI (1.84, 10.56).</p>
</div>
<div id="plot-in-sample-predictions-for-model-c" class="section level3">
<h3><span class="header-section-number">13.12.6</span> Plot In-Sample Predictions for Model C</h3>
<p>Here we plot the effect of <code>resection</code> (and 95% confidence intervals) across the range of observed values of <code>resection</code> on the log odds of death. Note the linear effect of <code>resection</code> size on the log odds scale.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">Predict</span>(res_modC))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-192-1.png" width="672" /></p>
<p>By applying the <code>plogis</code> function within the <code>Predict</code> command, we can plot the effect of <code>resection</code> on the estimated probability of death. Note the non-linear effect on this probability in this logistic regression model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">Predict</span>(res_modC, <span class="dt">fun =</span> plogis)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Predicted probability from Model C&quot;</span>,
         <span class="dt">title =</span> <span class="st">&quot;Model C with the resect data&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-193-1.png" width="672" /></p>
<p>The <code>Predict</code> function itself provides the raw material being captured in this plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">Predict</span>(res_modC, <span class="dt">fun =</span> plogis))</code></pre></div>
<pre><code>            resection       yhat       lower      upper .predictor.
resection.1  1.000000 0.02431476 0.006636502 0.08505223   resection
resection.2  1.020101 0.02467096 0.006789313 0.08559056   resection
resection.3  1.040201 0.02503224 0.006945549 0.08613277   resection
resection.4  1.060302 0.02539867 0.007105283 0.08667889   resection
resection.5  1.080402 0.02577033 0.007268589 0.08722896   resection
resection.6  1.100503 0.02614728 0.007435542 0.08778304   resection

Response variable (y):  

Limits are 0.95 confidence limits</code></pre>
</div>
<div id="anova-from-the-lrm-approach" class="section level3">
<h3><span class="header-section-number">13.12.7</span> ANOVA from the <code>lrm</code> approach</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(res_modC)</code></pre></div>
<pre><code>                Wald Statistics          Response: died 

 Factor     Chi-Square d.f. P    
 resection  11.07      1    9e-04
 TOTAL      11.07      1    9e-04</code></pre>
<p>The ANOVA approach applied to a <code>lrm</code> fit provides a Wald test for the model as a whole. Here, the use of <code>resection</code> is a significant improvement over a null (intercept-only) model. The <em>p</em> value is 9 x 10<sup>-4</sup>.</p>
</div>
<div id="are-any-points-particularly-influential" class="section level3">
<h3><span class="header-section-number">13.12.8</span> Are any points particularly influential?</h3>
<p>I’ll use a cutoff for <code>dfbeta</code> here of 0.3, instead of the default 0.2, because I want to focus on truly influential points. Note that we have to use the data frame version of <code>resect</code> as <code>show.influence</code> isn’t tibble-friendly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">inf.C &lt;-<span class="st"> </span><span class="kw">which.influence</span>(res_modC, <span class="dt">cutoff=</span><span class="fl">0.3</span>)
inf.C</code></pre></div>
<pre><code>$Intercept
[1] &quot;84&quot;  &quot;128&quot;

$resection
[1] &quot;84&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">show.influence</span>(<span class="dt">object =</span> inf.C, <span class="dt">dframe =</span> <span class="kw">data.frame</span>(resect))</code></pre></div>
<pre><code>    Count resection
84      2      *2.0
128     1       2.5</code></pre>
<p>It appears that observation 84 may have a meaningful effect on both the intercept and the coefficient for <code>resection</code>.</p>
</div>
<div id="a-nomogram-for-model-c" class="section level3">
<h3><span class="header-section-number">13.12.9</span> A Nomogram for Model C</h3>
<p>We use the <code>plogis</code> function within a nomogram call to get R to produce fitted probabilities (of our outcome, <code>died</code>) in this case.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">nomogram</span>(res_modC, <span class="dt">fun=</span>plogis, 
              <span class="dt">fun.at=</span><span class="kw">c</span>(<span class="fl">0.05</span>, <span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="dt">by =</span> <span class="fl">0.1</span>), <span class="fl">0.95</span>), 
              <span class="dt">funlabel=</span><span class="st">&quot;Pr(died)&quot;</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-197-1.png" width="672" /></p>
<p>Since there’s no non-linearity in the right hand side of our simple logistic regression model, the nomogram is straightforward. We calculate the points based on the resection by traveling up, and then travel down in a straight vertical line from total points through the linear (log odds) predictor straight to a fitted probability. Note that fitted probabilities above 0.5 are not possible within the range of observed <code>resection</code> values in this case.</p>
</div>
</div>
<div id="model-d-an-augmented-kitchen-sink-model" class="section level2">
<h2><span class="header-section-number">13.13</span> Model D: An Augmented Kitchen Sink Model</h2>
<p>Can we predict survival from the patient’s age, whether the patient had prior tracheal surgery or not, the extent of the resection, and whether intubation was required at the end of surgery?</p>
<div id="spearman-rho2-plot" class="section level3">
<h3><span class="header-section-number">13.13.1</span> Spearman <span class="math inline">\(\rho^2\)</span> Plot</h3>
<p>Let’s start by considering the limited use of non-linear terms for predictors that look important in a Spearman <span class="math inline">\(\rho^2\)</span> plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">spearman2</span>(died <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>prior <span class="op">+</span><span class="st"> </span>resection <span class="op">+</span><span class="st"> </span>intubated, <span class="dt">data=</span>resect))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-198-1.png" width="672" /></p>
<p>The most important variable appears to be whether intubation was required, so I’ll include <code>intubated</code>’s interaction with the linear effect of the next most (apparently) important variable, <code>resection</code>, and also a cubic spline for <code>resection</code>, with three knots. Since <code>prior</code> and <code>age</code> look less important, I’ll simply add them as linear terms.</p>
</div>
<div id="fitting-model-d-using-lrm" class="section level3">
<h3><span class="header-section-number">13.13.2</span> Fitting Model D using <code>lrm</code></h3>
<p>Note the use of <code>%ia%</code> here. This insures that only the linear part of the <code>resection</code> term will be used in the interaction with <code>intubated</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dd &lt;-<span class="st"> </span><span class="kw">datadist</span>(resect)
<span class="kw">options</span>(<span class="dt">datadist=</span><span class="st">&quot;dd&quot;</span>)

res_modD &lt;-<span class="st"> </span><span class="kw">lrm</span>(died <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>prior <span class="op">+</span><span class="st"> </span><span class="kw">rcs</span>(resection, <span class="dv">3</span>) <span class="op">+</span>
<span class="st">                 </span>intubated <span class="op">+</span><span class="st"> </span>intubated <span class="op">%ia%</span><span class="st"> </span>resection, 
               <span class="dt">data=</span>resect, <span class="dt">x=</span><span class="ot">TRUE</span>, <span class="dt">y=</span><span class="ot">TRUE</span>)</code></pre></div>
</div>
<div id="assessing-model-d-using-lrms-tools" class="section level3">
<h3><span class="header-section-number">13.13.3</span> Assessing Model D using <code>lrm</code>’s tools</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_modD</code></pre></div>
<pre><code>Logistic Regression Model
 
 lrm(formula = died ~ age + prior + rcs(resection, 3) + intubated + 
     intubated %ia% resection, data = resect, x = TRUE, y = TRUE)
 
                       Model Likelihood     Discrimination    Rank Discrim.    
                          Ratio Test           Indexes           Indexes       
 Obs           134    LR chi2      38.08    R2       0.464    C       0.880    
  0            117    d.f.             6    g        2.382    Dxy     0.759    
  1             17    Pr(&gt; chi2) &lt;0.0001    gr      10.825    gamma   0.770    
 max |deriv| 9e-08                          gp       0.172    tau-a   0.169    
                                            Brier    0.067                     
 
                       Coef     S.E.   Wald Z Pr(&gt;|Z|)
 Intercept             -11.3636 4.9099 -2.31  0.0206  
 age                     0.0000 0.0210  0.00  0.9988  
 prior                   0.6269 0.7367  0.85  0.3947  
 resection               3.3799 1.9700  1.72  0.0862  
 resection&#39;             -4.2104 2.7035 -1.56  0.1194  
 intubated               0.4576 2.7848  0.16  0.8695  
 intubated * resection   0.6188 0.7306  0.85  0.3970  
 </code></pre>
<ul>
<li>The model likelihood ratio test suggests that at least some of these predictors are helpful.</li>
<li>The Nagelkerke R<sup>2</sup> of 0.46, and the C statistic of 0.88 indicate a meaningful improvement in discrimination over our model with <code>resection</code> alone.</li>
<li>The Wald Z tests see some potential need to prune the model, as none of the elements reaches statistical significance without the others. The product term between <code>intubated</code> and <code>resection</code>, in particular, doesn’t appear to have helped much, once we already had the main effects.</li>
</ul>
</div>
<div id="anova-and-wald-tests-for-model-d" class="section level3">
<h3><span class="header-section-number">13.13.4</span> ANOVA and Wald Tests for Model D</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(res_modD)</code></pre></div>
<pre><code>                Wald Statistics          Response: died 

 Factor                                               Chi-Square d.f.
 age                                                   0.00      1   
 prior                                                 0.72      1   
 resection  (Factor+Higher Order Factors)              4.95      3   
  All Interactions                                     0.72      1   
  Nonlinear                                            2.43      1   
 intubated  (Factor+Higher Order Factors)             16.45      2   
  All Interactions                                     0.72      1   
 intubated * resection  (Factor+Higher Order Factors)  0.72      1   
 TOTAL NONLINEAR + INTERACTION                         2.56      2   
 TOTAL                                                23.90      6   
 P     
 0.9988
 0.3947
 0.1753
 0.3970
 0.1194
 0.0003
 0.3970
 0.3970
 0.2783
 0.0005</code></pre>
<p>Neither the interaction term nor the non-linearity from the cubic spline appears to be statistically significant, based on the Wald tests via ANOVA. However it is clear that <code>intubated</code> has a significant impact as a main effect.</p>
</div>
<div id="effect-sizes-in-model-d" class="section level3">
<h3><span class="header-section-number">13.13.5</span> Effect Sizes in Model D</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">summary</span>(res_modD))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-202-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(res_modD)</code></pre></div>
<pre><code>             Effects              Response : died 

 Factor      Low High Diff. Effect      S.E.    Lower 0.95 Upper 0.95
 age         36  61   25    -0.00080933 0.52409 -1.02800     1.0264  
  Odds Ratio 36  61   25     0.99919000      NA  0.35772     2.7910  
 prior        0   1    1     0.62693000 0.73665 -0.81688     2.0707  
  Odds Ratio  0   1    1     1.87190000      NA  0.44181     7.9307  
 resection    2   4    2     2.42930000 1.43510 -0.38342     5.2419  
  Odds Ratio  2   4    2    11.35000000      NA  0.68153   189.0400  
 intubated    0   1    1     2.00470000 1.11220 -0.17513     4.1845  
  Odds Ratio  0   1    1     7.42380000      NA  0.83934    65.6610  

Adjusted to: resection=2.5 intubated=0  </code></pre>
<p>The effect sizes are perhaps best described in terms of odds ratios. The odds ratio for death isn’t significantly different from 1 for any variable, but the impact of <code>resection</code> and <code>intubated</code>, though not strong enough to be significant, look more substantial (if poorly estimated) than the effects of <code>age</code> and <code>prior</code>.</p>
</div>
<div id="plot-in-sample-predictions-for-model-d" class="section level3">
<h3><span class="header-section-number">13.13.6</span> Plot In-Sample Predictions for Model D</h3>
<p>Here are plots of the effects across the range of each predictor (holding the others constant) on the log odds scale. Note the non-linear effect of resection implied by the use of a spline there.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">Predict</span>(res_modD))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-203-1.png" width="672" /></p>
<p>We can also capture and plot these results on the probability scale, as follows<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">Predict</span>(res_modD, <span class="dt">fun =</span> plogis))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-204-1.png" width="672" /></p>
</div>
<div id="plotting-the-roc-curve-for-model-d" class="section level3">
<h3><span class="header-section-number">13.13.7</span> Plotting the ROC curve for Model D</h3>
<p>Again, remember to use <code>type = &quot;fitted&quot;</code> with a <code>lrm</code> fit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## requires ROCR package
prob &lt;-<span class="st"> </span><span class="kw">predict</span>(res_modD, resect, <span class="dt">type=</span><span class="st">&quot;fitted&quot;</span>)
pred &lt;-<span class="st"> </span><span class="kw">prediction</span>(prob, resect<span class="op">$</span>died)
perf &lt;-<span class="st"> </span><span class="kw">performance</span>(pred, <span class="dt">measure =</span> <span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure =</span> <span class="st">&quot;fpr&quot;</span>)
auc &lt;-<span class="st"> </span><span class="kw">performance</span>(pred, <span class="dt">measure=</span><span class="st">&quot;auc&quot;</span>)

auc &lt;-<span class="st"> </span><span class="kw">round</span>(auc<span class="op">@</span>y.values[[<span class="dv">1</span>]],<span class="dv">3</span>)
roc.data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">fpr=</span><span class="kw">unlist</span>(perf<span class="op">@</span>x.values),
                       <span class="dt">tpr=</span><span class="kw">unlist</span>(perf<span class="op">@</span>y.values),
                       <span class="dt">model=</span><span class="st">&quot;GLM&quot;</span>)

<span class="kw">ggplot</span>(roc.data, <span class="kw">aes</span>(<span class="dt">x=</span>fpr, <span class="dt">ymin=</span><span class="dv">0</span>, <span class="dt">ymax=</span>tpr)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_ribbon</span>(<span class="dt">alpha=</span><span class="fl">0.2</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y=</span>tpr), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>, <span class="dt">lty =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;ROC Curve w/ AUC=&quot;</span>, auc)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-205-1.png" width="672" /></p>
<p>The AUC fitted with <code>ROCR</code> (0.883) is slightly different than what <code>lrm</code> has told us (0.880), and this also happens if we use the <code>pROC</code> approach, demonstrated below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## requires pROC package
roc.modD &lt;-<span class="st"> </span>
<span class="st">    </span><span class="kw">roc</span>(resect<span class="op">$</span>died <span class="op">~</span><span class="st"> </span><span class="kw">predict</span>(res_modD, <span class="dt">type=</span><span class="st">&quot;fitted&quot;</span>),
        <span class="dt">ci =</span> <span class="ot">TRUE</span>)

roc.modD</code></pre></div>
<pre><code>
Call:
roc.formula(formula = resect$died ~ predict(res_modD, type = &quot;fitted&quot;),     ci = TRUE)

Data: predict(res_modD, type = &quot;fitted&quot;) in 117 controls (resect$died 0) &lt; 17 cases (resect$died 1).
Area under the curve: 0.8826
95% CI: 0.7952-0.97 (DeLong)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(roc.modD)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-206-1.png" width="672" /></p>
</div>
<div id="validation-of-model-d-summaries" class="section level3">
<h3><span class="header-section-number">13.13.8</span> Validation of Model D summaries</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">432002</span>)
<span class="kw">validate</span>(res_modD, <span class="dt">B =</span> <span class="dv">100</span>)</code></pre></div>
<pre><code>
Divergence or singularity in 6 samples</code></pre>
<pre><code>          index.orig training    test optimism index.corrected  n
Dxy           0.7652   0.8162  0.7142   0.1020          0.6632 94
R2            0.4643   0.5382  0.3991   0.1391          0.3252 94
Intercept     0.0000   0.0000 -0.3919   0.3919         -0.3919 94
Slope         1.0000   1.0000  0.7201   0.2799          0.7201 94
Emax          0.0000   0.0000  0.1530   0.1530          0.1530 94
D             0.2767   0.3258  0.2322   0.0936          0.1831 94
U            -0.0149  -0.0149  0.1998  -0.2147          0.1998 94
Q             0.2916   0.3407  0.0324   0.3083         -0.0167 94
B             0.0673   0.0595  0.0739  -0.0144          0.0817 94
g             2.3819   4.2214  2.2024   2.0190          0.3629 94
gp            0.1720   0.1777  0.1591   0.0186          0.1534 94</code></pre>
<p>The C statistic indicates fairly strong discrimination, at C = 0.88, although after validation, this looks much weaker (based on Dxy = 0.6632, we would have C = 0.5 + 0.6632/2 = 0.83) and the Nagelkerke <span class="math inline">\(R^2\)</span> is also reasonably good, at 0.46, although this, too, is overly optimistic, and we bias-correct through our validation study to 0.33.</p>
</div>
</div>
<div id="model-e-fitting-a-reduced-model-in-light-of-model-d" class="section level2">
<h2><span class="header-section-number">13.14</span> Model E: Fitting a Reduced Model in light of Model D</h2>
<p>Can you suggest a reduced model (using a subset of the independent variables in model D) that adequately predicts survival?</p>
<p>Based on the anova for model D and the Spearman rho-squared plot, it appears that a two-predictor model using intubation and resection may be sufficient. Neither of the other potential predictors shows a statistically detectable effect in its Wald test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_modE &lt;-<span class="st"> </span><span class="kw">lrm</span>(died <span class="op">~</span><span class="st"> </span>intubated <span class="op">+</span><span class="st"> </span>resection, <span class="dt">data=</span>resect, 
                <span class="dt">x=</span><span class="ot">TRUE</span>, <span class="dt">y=</span><span class="ot">TRUE</span>)
res_modE</code></pre></div>
<pre><code>Logistic Regression Model
 
 lrm(formula = died ~ intubated + resection, data = resect, x = TRUE, 
     y = TRUE)
 
                       Model Likelihood     Discrimination    Rank Discrim.    
                          Ratio Test           Indexes           Indexes       
 Obs           134    LR chi2      33.27    R2       0.413    C       0.867    
  0            117    d.f.             2    g        1.397    Dxy     0.734    
  1             17    Pr(&gt; chi2) &lt;0.0001    gr       4.043    gamma   0.757    
 max |deriv| 5e-10                          gp       0.160    tau-a   0.164    
                                            Brier    0.073                     
 
           Coef    S.E.   Wald Z Pr(&gt;|Z|)
 Intercept -4.6370 1.0430 -4.45  &lt;0.0001 
 intubated  2.8640 0.6479  4.42  &lt;0.0001 
 resection  0.5475 0.2689  2.04  0.0418  
 </code></pre>
<p>The model equation is that the log odds of death is -4.637 + 2.864 <code>intubated</code> + 0.548 <code>resection</code>.</p>
<p>This implies that:</p>
<ul>
<li>for intubated patients, the equation is -1.773 + 0.548 <code>resection</code>, while</li>
<li>for non-intubated patients, the equation is -4.637 + 0.548 <code>resection</code>.</li>
</ul>
<p>We can use the <code>ilogit</code> function within the <code>faraway</code> package to help plot this.</p>
<div id="a-plot-comparing-the-two-intubation-groups" class="section level3">
<h3><span class="header-section-number">13.14.1</span> A Plot comparing the two intubation groups</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(resect, <span class="kw">aes</span>(<span class="dt">x =</span> resection, <span class="dt">y =</span> died, 
                   <span class="dt">col =</span> <span class="kw">factor</span>(intubated))) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_jitter</span>(<span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">height =</span> <span class="fl">0.1</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> resection, 
                  <span class="dt">y =</span> faraway<span class="op">::</span><span class="kw">ilogit</span>(<span class="op">-</span><span class="fl">4.637</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.548</span><span class="op">*</span>resection)),
              <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> resection,
                  <span class="dt">y =</span> faraway<span class="op">::</span><span class="kw">ilogit</span>(<span class="op">-</span><span class="fl">1.773</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.548</span><span class="op">*</span>resection)),
              <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_text</span>(<span class="dt">x =</span> <span class="dv">4</span>, <span class="dt">y =</span> <span class="fl">0.2</span>, <span class="dt">label =</span> <span class="st">&quot;Not Intubated&quot;</span>, 
              <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_text</span>(<span class="dt">x =</span> <span class="fl">2.5</span>, <span class="dt">y =</span> <span class="fl">0.6</span>, <span class="dt">label =</span> <span class="st">&quot;Intubated Patients&quot;</span>, 
              <span class="dt">col=</span><span class="st">&quot;red&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Extent of Resection (in cm.)&quot;</span>,
         <span class="dt">y =</span> <span class="st">&quot;Death (1,0) and estimated probability of death&quot;</span>,
         <span class="dt">title =</span> <span class="st">&quot;resect data, Model E&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-209-1.png" width="672" /></p>
<p>The effect of <code>intubation</code> appears to be very large, compared to the resection size effect.</p>
</div>
<div id="nomogram-for-model-e" class="section level3">
<h3><span class="header-section-number">13.14.2</span> Nomogram for Model E</h3>
<p>A nomogram of the model would help, too.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">nomogram</span>(res_modE, <span class="dt">fun=</span>plogis, 
              <span class="dt">fun.at=</span><span class="kw">c</span>(<span class="fl">0.05</span>, <span class="kw">seq</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="dt">by=</span><span class="fl">0.1</span>), <span class="fl">0.95</span>), 
              <span class="dt">funlabel=</span><span class="st">&quot;Pr(died)&quot;</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-210-1.png" width="672" /></p>
<p>Again, we see that the effect of intubation is enormous, compared to the effect of resection. Another way to see this is to plot the effect sizes directly.</p>
</div>
<div id="effect-sizes-from-model-e" class="section level3">
<h3><span class="header-section-number">13.14.3</span> Effect Sizes from Model E</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">summary</span>(res_modE))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/model%20c%20effect%20plot-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(res_modE)</code></pre></div>
<pre><code>             Effects              Response : died 

 Factor      Low High Diff. Effect  S.E.    Lower 0.95 Upper 0.95
 intubated   0   1    1      2.8640 0.64790 1.59410     4.1338   
  Odds Ratio 0   1    1     17.5310      NA 4.92390    62.4160   
 resection   2   4    2      1.0949 0.53783 0.04082     2.1491   
  Odds Ratio 2   4    2      2.9890      NA 1.04170     8.5769   </code></pre>
</div>
<div id="plot-in-sample-predictions-for-model-e" class="section level3">
<h3><span class="header-section-number">13.14.4</span> Plot In-Sample Predictions for Model E</h3>
<p>Here are plots of the effects across the range of each predictor (holding the other constant) on the log odds scale.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">Predict</span>(res_modE))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-211-1.png" width="672" /></p>
<p>We can also capture and plot these results on the probability scale, as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="kw">Predict</span>(res_modE, <span class="dt">fun =</span> plogis))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-212-1.png" width="672" /></p>
</div>
<div id="anova-for-model-e" class="section level3">
<h3><span class="header-section-number">13.14.5</span> ANOVA for Model E</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(res_modE)</code></pre></div>
<pre><code>                Wald Statistics          Response: died 

 Factor     Chi-Square d.f. P     
 intubated  19.54      1    &lt;.0001
 resection   4.14      1    0.0418
 TOTAL      25.47      2    &lt;.0001</code></pre>
</div>
<div id="validation-of-model-e" class="section level3">
<h3><span class="header-section-number">13.14.6</span> Validation of Model E</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">validate</span>(res_modE, <span class="dt">method=</span><span class="st">&quot;boot&quot;</span>, <span class="dt">B=</span><span class="dv">40</span>)</code></pre></div>
<pre><code>          index.orig training   test optimism index.corrected  n
Dxy           0.7340   0.7113 0.7327  -0.0213          0.7554 40
R2            0.4128   0.4072 0.4039   0.0033          0.4095 40
Intercept     0.0000   0.0000 0.0346  -0.0346          0.0346 40
Slope         1.0000   1.0000 1.0128  -0.0128          1.0128 40
Emax          0.0000   0.0000 0.0096   0.0096          0.0096 40
D             0.2408   0.2444 0.2348   0.0096          0.2313 40
U            -0.0149  -0.0149 0.0023  -0.0173          0.0023 40
Q             0.2558   0.2593 0.2325   0.0269          0.2289 40
B             0.0727   0.0737 0.0762  -0.0025          0.0751 40
g             1.3970   1.4016 1.3642   0.0374          1.3596 40
gp            0.1597   0.1590 0.1568   0.0022          0.1575 40</code></pre>
<p>Our bootstrap validated assessments of discrimination and goodness of fit look somewhat more reasonable now.</p>
</div>
<div id="do-any-points-seem-particularly-influential" class="section level3">
<h3><span class="header-section-number">13.14.7</span> Do any points seem particularly influential?</h3>
<p>As a last step, I’ll look at influence, and residuals, associated with model E.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">inf.E &lt;-<span class="st"> </span><span class="kw">which.influence</span>(res_modE, <span class="dt">cutoff=</span><span class="fl">0.3</span>)

inf.E</code></pre></div>
<pre><code>$Intercept
[1] &quot;84&quot; &quot;94&quot;

$resection
[1] &quot;84&quot; &quot;94&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">show.influence</span>(inf.E, <span class="dt">dframe =</span> <span class="kw">data.frame</span>(resect))</code></pre></div>
<pre><code>   Count resection
84     2        *2
94     2        *6</code></pre>
</div>
<div id="fitting-model-e-using-glm-to-get-plots-about-influence" class="section level3">
<h3><span class="header-section-number">13.14.8</span> Fitting Model E using <code>glm</code> to get plots about influence</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_modEglm &lt;-<span class="st"> </span><span class="kw">glm</span>(died <span class="op">~</span><span class="st"> </span>intubated <span class="op">+</span><span class="st"> </span>resection, 
                  <span class="dt">data=</span>resect, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(res_modEglm, <span class="dt">which=</span><span class="kw">c</span>(<span class="dv">4</span><span class="op">:</span><span class="dv">5</span>))</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-216-1.png" width="672" /></p>
<p>Using this <code>glm</code> residuals approach, we again see that points 84 and 94 have the largest influence on our model E.</p>
</div>
</div>
<div id="concordance-comparing-model-c-d-and-es-predictions" class="section level2">
<h2><span class="header-section-number">13.15</span> Concordance: Comparing Model C, D and E’s predictions</h2>
<p>To start, we’ll gather the predictions fomade by each model (C, D and E) on the probability scale, in one place. Sadly, <code>augment</code> from <code>broom</code> doesn’t work well with <code>lrm</code> fits, so we have to do this on our own.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">resect_preds &lt;-<span class="st"> </span>resect <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">C =</span> <span class="kw">predict</span>(res_modC, <span class="dt">type =</span> <span class="st">&quot;fitted&quot;</span>),
           <span class="dt">D =</span> <span class="kw">predict</span>(res_modD, <span class="dt">type =</span> <span class="st">&quot;fitted&quot;</span>),
           <span class="dt">E =</span> <span class="kw">predict</span>(res_modE, <span class="dt">type =</span> <span class="st">&quot;fitted&quot;</span>))

<span class="kw">head</span>(resect_preds)</code></pre></div>
<pre><code># A tibble: 6 x 9
     id   age prior resection intubated  died      C      D      E
  &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
1     1    34     1      2.50         0     0 0.0705 0.0632 0.0367
2     2    57     0      5.00         0     0 0.326  0.0620 0.130 
3     3    60     1      4.00         1     1 0.187  0.791  0.603 
4     4    62     1      4.20         0     0 0.211  0.158  0.0881
5     5    28     0      6.00         1     1 0.504  0.711  0.819 
6     6    52     0      3.00         0     0 0.0990 0.0737 0.0477</code></pre>
<p>And now, we’ll use the <code>gather</code> command to arrange the models and predicted probabilities in a more useful manner for plotting.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_p &lt;-<span class="st"> </span>resect_preds <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">gather</span>(<span class="st">&quot;model&quot;</span>, <span class="st">&quot;prediction&quot;</span>, <span class="dv">7</span><span class="op">:</span><span class="dv">9</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">select</span>(id, died, model, prediction)

<span class="kw">head</span>(res_p)</code></pre></div>
<pre><code># A tibble: 6 x 4
     id  died model prediction
  &lt;int&gt; &lt;int&gt; &lt;chr&gt;      &lt;dbl&gt;
1     1     0 C         0.0705
2     2     0 C         0.326 
3     3     1 C         0.187 
4     4     0 C         0.211 
5     5     1 C         0.504 
6     6     0 C         0.0990</code></pre>
<p>Here’s the resulting plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(res_p, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(died), <span class="dt">y =</span> prediction, 
                  <span class="dt">group =</span> model, <span class="dt">col =</span> model)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">0.25</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="fl">0.5</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">facet_wrap</span>( <span class="op">~</span><span class="st"> </span>model) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">guides</span>(<span class="dt">color =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Comparing Predictions for our Three Models&quot;</span>,
         <span class="dt">subtitle =</span> <span class="st">&quot;A graphical view of concordance&quot;</span>,
         <span class="dt">x =</span> <span class="st">&quot;Actual mortality status (1 = died)&quot;</span>,
         <span class="dt">y =</span> <span class="st">&quot;Predicted probability of death&quot;</span>)</code></pre></div>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-219-1.png" width="672" /></p>
<p>We could specify a particular rule, for example: if the predicted probability of death is 0.5 or greater, then predict “Died”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res_p<span class="op">$</span>rule.<span class="dv">5</span> &lt;-<span class="st"> </span><span class="kw">ifelse</span>(res_p<span class="op">$</span>prediction <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>, 
                       <span class="st">&quot;Predict Died&quot;</span>, <span class="st">&quot;Predict Alive&quot;</span>)

<span class="kw">ftable</span>(<span class="kw">table</span>(res_p<span class="op">$</span>model, res_p<span class="op">$</span>rule.<span class="dv">5</span>, res_p<span class="op">$</span>died))</code></pre></div>
<pre><code>                   0   1
                        
C Predict Alive  114  16
  Predict Died     3   1
D Predict Alive  113   7
  Predict Died     4  10
E Predict Alive  114   8
  Predict Died     3   9</code></pre>
<p>And perhaps build the linked table of row probabilities…</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="dv">100</span><span class="op">*</span><span class="kw">prop.table</span>(
    <span class="kw">ftable</span>(<span class="kw">table</span>(res_p<span class="op">$</span>model, res_p<span class="op">$</span>rule.<span class="dv">5</span>, res_p<span class="op">$</span>died))
    ,<span class="dv">1</span>),<span class="dv">2</span>)</code></pre></div>
<pre><code>                     0     1
                            
C Predict Alive  87.69 12.31
  Predict Died   75.00 25.00
D Predict Alive  94.17  5.83
  Predict Died   28.57 71.43
E Predict Alive  93.44  6.56
  Predict Died   25.00 75.00</code></pre>
<p>For example, in model E, 93.44% of those predicted to be alive actually survived, and 75% of those predicted to die actually died.</p>
<ul>
<li>Model D does a little better in one direction (94.17% of those predicted by Model D to be alive actually survived) but worse in the other (71.43% of those predicted by Model D to die actually died.)</li>
<li>Model C does worse than each of the others in both predicting those who survive and those who die.</li>
</ul>
<p>Note that the approaches discussed here would be useful if we had a new sample to predict on, as well. We could then compare the errors for that new data made by this sort of classification scheme either graphically or in a table.</p>
</div>
<div id="conclusions" class="section level2">
<h2><span class="header-section-number">13.16</span> Conclusions</h2>
<p>It appears that <code>intubated</code> status and, to a lesser degree, the extent of the <code>resection</code> both play a meaningful role in predicting death associated with tracheal carina resection surgery. Patients who are intubated are associated with worse outcomes (greater risk of death) and more extensive resections are also associated with worse outcomes.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Riffenburgh2006">
<p>Riffenburgh, Robert H. 2006. <em>Statistics in Medicine</em>. Second Edition. Burlington, MA: Elsevier Academic Press.</p>
</div>
<div id="ref-Peduzzi1996">
<p>Peduzzi, Peter, John Concato, Elizabeth Kemper, Theodore R. Holford, and Alvan R. Feinstein. 1996. “A Simulation Study of the Number of Events Per Variable in Logistic Regression Analysis.” <em>Journal of Clinical Epidemiology</em> 49 (12): 1373–9.</p>
</div>
<div id="ref-Long1997">
<p>Long, J. Scott. 1997. <em>Regression Models for Categorical and Limited Dependent Variables</em>. Thousand Oaks, CA: Sage Publications.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="9">
<li id="fn9"><p>Although I’ve yet to figure out how to get the y axis relabeled properly without simply dumping the Predict results into a new tibble and starting over with creating the plots.<a href="logistic-regression-and-the-resect-data.html#fnref9">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression-the-foundations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logistic-regression-and-the-smartcle1-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/13_logistic1.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
